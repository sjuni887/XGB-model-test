{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required packages\n",
    "\n",
    "# tabular data\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tabulate import tabulate\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# metrics \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# classification models \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# statistical models \n",
    "import statsmodels.api as sm\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "\n",
    "# time - test\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. HR Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load and Sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hr = pd.read_csv('./hr_csv_transformed_stan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "      <th>...</th>\n",
       "      <th>department_R&amp;D</th>\n",
       "      <th>department_Procurement</th>\n",
       "      <th>department_Finance</th>\n",
       "      <th>department_HR</th>\n",
       "      <th>department_Legal</th>\n",
       "      <th>gender_f</th>\n",
       "      <th>gender_m</th>\n",
       "      <th>recruitment_channel_sourcing</th>\n",
       "      <th>recruitment_channel_other</th>\n",
       "      <th>recruitment_channel_referred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6108</td>\n",
       "      <td>1</td>\n",
       "      <td>2.842558</td>\n",
       "      <td>-0.326748</td>\n",
       "      <td>-0.257911</td>\n",
       "      <td>-0.660489</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.498370</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>785</td>\n",
       "      <td>1</td>\n",
       "      <td>1.212457</td>\n",
       "      <td>-1.152946</td>\n",
       "      <td>-1.903583</td>\n",
       "      <td>-0.270179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.682447</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.417644</td>\n",
       "      <td>-0.640591</td>\n",
       "      <td>0.564925</td>\n",
       "      <td>-1.167709</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.099974</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6108</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.417644</td>\n",
       "      <td>-0.805450</td>\n",
       "      <td>0.564925</td>\n",
       "      <td>-1.167709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.423169</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1701</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.417644</td>\n",
       "      <td>0.878448</td>\n",
       "      <td>-1.903583</td>\n",
       "      <td>1.087391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.648771</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   region  education  no_of_trainings       age  previous_year_rating  \\\n",
       "0    6108          1         2.842558 -0.326748             -0.257911   \n",
       "1     785          1         1.212457 -1.152946             -1.903583   \n",
       "2    1234          2        -0.417644 -0.640591              0.564925   \n",
       "3    6108          1        -0.417644 -0.805450              0.564925   \n",
       "4    1701          2        -0.417644  0.878448             -1.903583   \n",
       "\n",
       "   length_of_service  KPIs_met >80%  awards_won?  avg_training_score  \\\n",
       "0          -0.660489              0            0           -0.498370   \n",
       "1          -0.270179              0            0            1.682447   \n",
       "2          -1.167709              1            0           -1.099974   \n",
       "3          -1.167709              0            0           -0.423169   \n",
       "4           1.087391              0            0           -0.648771   \n",
       "\n",
       "   is_promoted  ...  department_R&D  department_Procurement  \\\n",
       "0            0  ...               0                       0   \n",
       "1            0  ...               0                       0   \n",
       "2            0  ...               0                       0   \n",
       "3            0  ...               0                       0   \n",
       "4            0  ...               0                       0   \n",
       "\n",
       "   department_Finance  department_HR  department_Legal  gender_f  gender_m  \\\n",
       "0                   0              0                 0         0         1   \n",
       "1                   0              0                 0         0         1   \n",
       "2                   0              0                 0         0         1   \n",
       "3                   1              0                 0         0         1   \n",
       "4                   0              0                 0         1         0   \n",
       "\n",
       "   recruitment_channel_sourcing  recruitment_channel_other  \\\n",
       "0                             0                          1   \n",
       "1                             0                          1   \n",
       "2                             0                          1   \n",
       "3                             1                          0   \n",
       "4                             1                          0   \n",
       "\n",
       "   recruitment_channel_referred  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             0  \n",
       "4                             0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9092 entries, 0 to 9091\n",
      "Data columns (total 24 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   region                        9092 non-null   int64  \n",
      " 1   education                     9092 non-null   int64  \n",
      " 2   no_of_trainings               9092 non-null   float64\n",
      " 3   age                           9092 non-null   float64\n",
      " 4   previous_year_rating          9092 non-null   float64\n",
      " 5   length_of_service             9092 non-null   float64\n",
      " 6   KPIs_met >80%                 9092 non-null   int64  \n",
      " 7   awards_won?                   9092 non-null   int64  \n",
      " 8   avg_training_score            9092 non-null   float64\n",
      " 9   is_promoted                   9092 non-null   int64  \n",
      " 10  department_Sales & Marketing  9092 non-null   int64  \n",
      " 11  department_Operations         9092 non-null   int64  \n",
      " 12  department_Technology         9092 non-null   int64  \n",
      " 13  department_Analytics          9092 non-null   int64  \n",
      " 14  department_R&D                9092 non-null   int64  \n",
      " 15  department_Procurement        9092 non-null   int64  \n",
      " 16  department_Finance            9092 non-null   int64  \n",
      " 17  department_HR                 9092 non-null   int64  \n",
      " 18  department_Legal              9092 non-null   int64  \n",
      " 19  gender_f                      9092 non-null   int64  \n",
      " 20  gender_m                      9092 non-null   int64  \n",
      " 21  recruitment_channel_sourcing  9092 non-null   int64  \n",
      " 22  recruitment_channel_other     9092 non-null   int64  \n",
      " 23  recruitment_channel_referred  9092 non-null   int64  \n",
      "dtypes: float64(5), int64(19)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_hr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "      <th>...</th>\n",
       "      <th>department_R&amp;D</th>\n",
       "      <th>department_Procurement</th>\n",
       "      <th>department_Finance</th>\n",
       "      <th>department_HR</th>\n",
       "      <th>department_Legal</th>\n",
       "      <th>gender_f</th>\n",
       "      <th>gender_m</th>\n",
       "      <th>recruitment_channel_sourcing</th>\n",
       "      <th>recruitment_channel_other</th>\n",
       "      <th>recruitment_channel_referred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4584.995381</td>\n",
       "      <td>1.290805</td>\n",
       "      <td>-0.040239</td>\n",
       "      <td>-0.021676</td>\n",
       "      <td>0.221926</td>\n",
       "      <td>-0.014536</td>\n",
       "      <td>0.512868</td>\n",
       "      <td>0.064452</td>\n",
       "      <td>0.260848</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015178</td>\n",
       "      <td>0.140013</td>\n",
       "      <td>0.044435</td>\n",
       "      <td>0.036846</td>\n",
       "      <td>0.017268</td>\n",
       "      <td>0.315662</td>\n",
       "      <td>0.684338</td>\n",
       "      <td>0.429059</td>\n",
       "      <td>0.545535</td>\n",
       "      <td>0.025407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4079.802512</td>\n",
       "      <td>0.483942</td>\n",
       "      <td>0.911368</td>\n",
       "      <td>0.966744</td>\n",
       "      <td>0.973085</td>\n",
       "      <td>0.982900</td>\n",
       "      <td>0.499862</td>\n",
       "      <td>0.245570</td>\n",
       "      <td>1.090369</td>\n",
       "      <td>0.500027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122268</td>\n",
       "      <td>0.347020</td>\n",
       "      <td>0.206070</td>\n",
       "      <td>0.188393</td>\n",
       "      <td>0.130275</td>\n",
       "      <td>0.464805</td>\n",
       "      <td>0.464805</td>\n",
       "      <td>0.494969</td>\n",
       "      <td>0.497950</td>\n",
       "      <td>0.157366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.417644</td>\n",
       "      <td>-2.612318</td>\n",
       "      <td>-1.903583</td>\n",
       "      <td>-1.890367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.701579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1234.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.417644</td>\n",
       "      <td>-0.805450</td>\n",
       "      <td>-0.257911</td>\n",
       "      <td>-0.660489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.723971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2617.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.417644</td>\n",
       "      <td>-0.177110</td>\n",
       "      <td>-0.257911</td>\n",
       "      <td>0.046716</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028034</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6108.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.417644</td>\n",
       "      <td>0.508938</td>\n",
       "      <td>1.387762</td>\n",
       "      <td>0.745036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.250044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11497.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.993062</td>\n",
       "      <td>2.730098</td>\n",
       "      <td>1.387762</td>\n",
       "      <td>3.020797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.660054</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             region    education  no_of_trainings          age  \\\n",
       "count   9092.000000  9092.000000      9092.000000  9092.000000   \n",
       "mean    4584.995381     1.290805        -0.040239    -0.021676   \n",
       "std     4079.802512     0.483942         0.911368     0.966744   \n",
       "min       31.000000     0.000000        -0.417644    -2.612318   \n",
       "25%     1234.000000     1.000000        -0.417644    -0.805450   \n",
       "50%     2617.000000     1.000000        -0.417644    -0.177110   \n",
       "75%     6108.000000     2.000000        -0.417644     0.508938   \n",
       "max    11497.000000     2.000000        10.993062     2.730098   \n",
       "\n",
       "       previous_year_rating  length_of_service  KPIs_met >80%  awards_won?  \\\n",
       "count           9092.000000        9092.000000    9092.000000  9092.000000   \n",
       "mean               0.221926          -0.014536       0.512868     0.064452   \n",
       "std                0.973085           0.982900       0.499862     0.245570   \n",
       "min               -1.903583          -1.890367       0.000000     0.000000   \n",
       "25%               -0.257911          -0.660489       0.000000     0.000000   \n",
       "50%               -0.257911           0.046716       1.000000     0.000000   \n",
       "75%                1.387762           0.745036       1.000000     0.000000   \n",
       "max                1.387762           3.020797       1.000000     1.000000   \n",
       "\n",
       "       avg_training_score  is_promoted  ...  department_R&D  \\\n",
       "count         9092.000000  9092.000000  ...     9092.000000   \n",
       "mean             0.260848     0.500000  ...        0.015178   \n",
       "std              1.090369     0.500027  ...        0.122268   \n",
       "min             -1.701579     0.000000  ...        0.000000   \n",
       "25%             -0.723971     0.000000  ...        0.000000   \n",
       "50%              0.028034     0.500000  ...        0.000000   \n",
       "75%              1.250044     1.000000  ...        0.000000   \n",
       "max              2.660054     1.000000  ...        1.000000   \n",
       "\n",
       "       department_Procurement  department_Finance  department_HR  \\\n",
       "count             9092.000000         9092.000000    9092.000000   \n",
       "mean                 0.140013            0.044435       0.036846   \n",
       "std                  0.347020            0.206070       0.188393   \n",
       "min                  0.000000            0.000000       0.000000   \n",
       "25%                  0.000000            0.000000       0.000000   \n",
       "50%                  0.000000            0.000000       0.000000   \n",
       "75%                  0.000000            0.000000       0.000000   \n",
       "max                  1.000000            1.000000       1.000000   \n",
       "\n",
       "       department_Legal     gender_f     gender_m  \\\n",
       "count       9092.000000  9092.000000  9092.000000   \n",
       "mean           0.017268     0.315662     0.684338   \n",
       "std            0.130275     0.464805     0.464805   \n",
       "min            0.000000     0.000000     0.000000   \n",
       "25%            0.000000     0.000000     0.000000   \n",
       "50%            0.000000     0.000000     1.000000   \n",
       "75%            0.000000     1.000000     1.000000   \n",
       "max            1.000000     1.000000     1.000000   \n",
       "\n",
       "       recruitment_channel_sourcing  recruitment_channel_other  \\\n",
       "count                   9092.000000                9092.000000   \n",
       "mean                       0.429059                   0.545535   \n",
       "std                        0.494969                   0.497950   \n",
       "min                        0.000000                   0.000000   \n",
       "25%                        0.000000                   0.000000   \n",
       "50%                        0.000000                   1.000000   \n",
       "75%                        1.000000                   1.000000   \n",
       "max                        1.000000                   1.000000   \n",
       "\n",
       "       recruitment_channel_referred  \n",
       "count                   9092.000000  \n",
       "mean                       0.025407  \n",
       "std                        0.157366  \n",
       "min                        0.000000  \n",
       "25%                        0.000000  \n",
       "50%                        0.000000  \n",
       "75%                        0.000000  \n",
       "max                        1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region                          0\n",
       "education                       0\n",
       "no_of_trainings                 0\n",
       "age                             0\n",
       "previous_year_rating            0\n",
       "length_of_service               0\n",
       "KPIs_met >80%                   0\n",
       "awards_won?                     0\n",
       "avg_training_score              0\n",
       "is_promoted                     0\n",
       "department_Sales & Marketing    0\n",
       "department_Operations           0\n",
       "department_Technology           0\n",
       "department_Analytics            0\n",
       "department_R&D                  0\n",
       "department_Procurement          0\n",
       "department_Finance              0\n",
       "department_HR                   0\n",
       "department_Legal                0\n",
       "gender_f                        0\n",
       "gender_m                        0\n",
       "recruitment_channel_sourcing    0\n",
       "recruitment_channel_other       0\n",
       "recruitment_channel_referred    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hr.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4546\n",
       "1    4546\n",
       "Name: is_promoted, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the target class distribution \n",
    "df_hr['is_promoted'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_hr.drop(['is_promoted'], axis =1)\n",
    "y = df_hr['is_promoted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Build the Model(s)\n",
    "\n",
    "- building baseline models, then 2 models will be chosen to focus on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "model_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# no hyperparams except random state for consistency in results \n",
    "lg = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "models.append(lg)\n",
    "model_names.append(\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(random_state=42).fit(X_train,y_train)\n",
    "\n",
    "models.append(dtree)\n",
    "model_names.append(\"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42).fit(X_train,y_train)\n",
    "\n",
    "models.append(rf)\n",
    "model_names.append(\"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(random_state = 42).fit(X_train,y_train)\n",
    "\n",
    "models.append(svc)\n",
    "model_names.append(\"SVC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state = 42).fit(X_train, y_train)\n",
    "\n",
    "models.append(mlp)\n",
    "model_names.append(\"Multi Layer Perceptron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADA Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(random_state = 42).fit(X_train,y_train)\n",
    "\n",
    "models.append(ada)\n",
    "model_names.append(\"ADA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(random_state = 42).fit(X_train, y_train)\n",
    "\n",
    "models.append(xgb)\n",
    "model_names.append(\"XGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Evaluate and Improve the Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_scores_classification(model):\n",
    "    print(f\"Model: {model}\")\n",
    "    \n",
    "    train_pred = model.predict(X_train)\n",
    "    print(f'\\nTraining score: {model.score(X_train, y_train)}')\n",
    "\n",
    "    test_pred = model.predict(X_test)\n",
    "    print(f'Testing score: {model.score(X_test, y_test)}')\n",
    "    \n",
    "    print('\\nTest Report:')\n",
    "    print(classification_report(y_test, test_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, test_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix - Testing')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Consolidated View of Baseline Model Accuracies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.735229</td>\n",
       "      <td>0.723240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.747801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.792522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.533941</td>\n",
       "      <td>0.537023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multi Layer Perceptron</td>\n",
       "      <td>0.693589</td>\n",
       "      <td>0.694282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADA</td>\n",
       "      <td>0.782055</td>\n",
       "      <td>0.769428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.933532</td>\n",
       "      <td>0.799487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Train Score  Test Score\n",
       "0     Logistic Regression     0.735229    0.723240\n",
       "1           Decision Tree     1.000000    0.747801\n",
       "2           Random Forest     1.000000    0.792522\n",
       "3                     SVC     0.533941    0.537023\n",
       "4  Multi Layer Perceptron     0.693589    0.694282\n",
       "5                     ADA     0.782055    0.769428\n",
       "6                     XGB     0.933532    0.799487"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_table = []\n",
    "for model, name in zip(models, model_names):\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    scores_table.append([name, train_score, test_score])\n",
    "\n",
    "df_scores = pd.DataFrame(scores_table, columns=[\"Model\", \"Train Score\", \"Test Score\"])\n",
    "\n",
    "df_scores\n",
    "\n",
    "# we just see how models perform differently "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Choosing Models \n",
    "These models will be chosen for further evaluation : <mark>Logistic Regression (Simple Model)</mark>, <mark>Multi Layer Perceptron (Artificial Neural Network)</mark>,<mark>ADA Boost (Ensemble Model)</mark>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2.1 Statistical Models \n",
    "- use statistical models to evaluate coeffients and understanding relationships between features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.429350\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "# using logit\n",
    "lgsm = sm.Logit(y_train, X_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>is_promoted</td>   <th>  No. Observations:  </th>  <td>  6364</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  6343</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    20</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 26 Jan 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.3806</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>21:40:54</td>     <th>  Log-Likelihood:    </th> <td> -2732.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -4411.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                  <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region</th>                       <td> 6.851e-06</td> <td> 8.88e-06</td> <td>    0.772</td> <td> 0.440</td> <td>-1.06e-05</td> <td> 2.43e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education</th>                    <td>    0.1445</td> <td>    0.079</td> <td>    1.818</td> <td> 0.069</td> <td>   -0.011</td> <td>    0.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_of_trainings</th>              <td>   -0.0248</td> <td>    0.038</td> <td>   -0.655</td> <td> 0.513</td> <td>   -0.099</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                          <td>   -0.2641</td> <td>    0.051</td> <td>   -5.199</td> <td> 0.000</td> <td>   -0.364</td> <td>   -0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_year_rating</th>         <td>    0.3026</td> <td>    0.037</td> <td>    8.137</td> <td> 0.000</td> <td>    0.230</td> <td>    0.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>length_of_service</th>            <td>    0.1385</td> <td>    0.045</td> <td>    3.086</td> <td> 0.002</td> <td>    0.051</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>KPIs_met >80%</th>                <td>    2.6255</td> <td>    0.084</td> <td>   31.276</td> <td> 0.000</td> <td>    2.461</td> <td>    2.790</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>awards_won?</th>                  <td>    1.9333</td> <td>    0.210</td> <td>    9.198</td> <td> 0.000</td> <td>    1.521</td> <td>    2.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_training_score</th>           <td>    3.8776</td> <td>    0.124</td> <td>   31.287</td> <td> 0.000</td> <td>    3.635</td> <td>    4.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Sales & Marketing</th> <td>    4.3356</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Operations</th>        <td>    1.4617</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Technology</th>        <td>   -3.7091</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Analytics</th>         <td>   -5.1873</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_R&D</th>               <td>   -5.5118</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Procurement</th>       <td>   -1.2128</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Finance</th>           <td>    1.4265</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_HR</th>                <td>    3.9180</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Legal</th>             <td>    1.1341</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender_f</th>                     <td>   -1.6846</td> <td> 1.22e+06</td> <td>-1.38e-06</td> <td> 1.000</td> <td>-2.39e+06</td> <td> 2.39e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender_m</th>                     <td>   -1.6606</td> <td> 1.22e+06</td> <td>-1.36e-06</td> <td> 1.000</td> <td>-2.39e+06</td> <td> 2.39e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recruitment_channel_sourcing</th> <td>   -1.2136</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recruitment_channel_other</th>    <td>   -1.0958</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recruitment_channel_referred</th> <td>   -1.0357</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            is_promoted   No. Observations:                 6364\n",
       "Model:                          Logit   Df Residuals:                     6343\n",
       "Method:                           MLE   Df Model:                           20\n",
       "Date:                Fri, 26 Jan 2024   Pseudo R-squ.:                  0.3806\n",
       "Time:                        21:40:54   Log-Likelihood:                -2732.4\n",
       "converged:                       True   LL-Null:                       -4411.0\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "================================================================================================\n",
       "                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------\n",
       "region                        6.851e-06   8.88e-06      0.772      0.440   -1.06e-05    2.43e-05\n",
       "education                        0.1445      0.079      1.818      0.069      -0.011       0.300\n",
       "no_of_trainings                 -0.0248      0.038     -0.655      0.513      -0.099       0.049\n",
       "age                             -0.2641      0.051     -5.199      0.000      -0.364      -0.165\n",
       "previous_year_rating             0.3026      0.037      8.137      0.000       0.230       0.375\n",
       "length_of_service                0.1385      0.045      3.086      0.002       0.051       0.226\n",
       "KPIs_met >80%                    2.6255      0.084     31.276      0.000       2.461       2.790\n",
       "awards_won?                      1.9333      0.210      9.198      0.000       1.521       2.345\n",
       "avg_training_score               3.8776      0.124     31.287      0.000       3.635       4.120\n",
       "department_Sales & Marketing     4.3356        nan        nan        nan         nan         nan\n",
       "department_Operations            1.4617        nan        nan        nan         nan         nan\n",
       "department_Technology           -3.7091        nan        nan        nan         nan         nan\n",
       "department_Analytics            -5.1873        nan        nan        nan         nan         nan\n",
       "department_R&D                  -5.5118        nan        nan        nan         nan         nan\n",
       "department_Procurement          -1.2128        nan        nan        nan         nan         nan\n",
       "department_Finance               1.4265        nan        nan        nan         nan         nan\n",
       "department_HR                    3.9180        nan        nan        nan         nan         nan\n",
       "department_Legal                 1.1341        nan        nan        nan         nan         nan\n",
       "gender_f                        -1.6846   1.22e+06  -1.38e-06      1.000   -2.39e+06    2.39e+06\n",
       "gender_m                        -1.6606   1.22e+06  -1.36e-06      1.000   -2.39e+06    2.39e+06\n",
       "recruitment_channel_sourcing    -1.2136        nan        nan        nan         nan         nan\n",
       "recruitment_channel_other       -1.0958        nan        nan        nan         nan         nan\n",
       "recruitment_channel_referred    -1.0357        nan        nan        nan         nan         nan\n",
       "================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgsm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Evaluate Chosen Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression(random_state=42)\n",
      "\n",
      "Training score: 0.7352294154619736\n",
      "Testing score: 0.7232404692082112\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72      1389\n",
      "           1       0.70      0.76      0.73      1339\n",
      "\n",
      "    accuracy                           0.72      2728\n",
      "   macro avg       0.72      0.72      0.72      2728\n",
      "weighted avg       0.73      0.72      0.72      2728\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_scores_classification(lg)\n",
    "\n",
    "# both train and tests do not have significant differences - it is neither overfitting nor underfitting\n",
    "# model accuracy can still be improved "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MLPClassifier(random_state=42)\n",
      "\n",
      "Training score: 0.6935889377749843\n",
      "Testing score: 0.6942815249266863\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.81      0.73      1389\n",
      "           1       0.75      0.57      0.65      1339\n",
      "\n",
      "    accuracy                           0.69      2728\n",
      "   macro avg       0.70      0.69      0.69      2728\n",
      "weighted avg       0.70      0.69      0.69      2728\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_scores_classification(mlp)\n",
    "\n",
    "# model accuracy can be improved\n",
    "# not much difference between train and test - neither overfitting or underfit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADA Boost \n",
    "- currently no base estimators added into the boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AdaBoostClassifier(random_state=42)\n",
      "\n",
      "Training score: 0.7820553111250785\n",
      "Testing score: 0.7694281524926686\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1389\n",
      "           1       0.75      0.79      0.77      1339\n",
      "\n",
      "    accuracy                           0.77      2728\n",
      "   macro avg       0.77      0.77      0.77      2728\n",
      "weighted avg       0.77      0.77      0.77      2728\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_scores_classification(ada)\n",
    "\n",
    "# higher scores than the other models \n",
    "# base estimators (the previous models can be added)\n",
    "# # might be lightly overfitted, there is higher bias against the variance  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Model Improvements "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression \n",
    "Hyperparameters that can be tweaked : \n",
    "- <mark>C</mark>  : regularisation parameter, higher C may lead to overfiting and lower C may lead to underfitting \n",
    "- <mark>penalty</mark> : regularisation term to prevent overfitting \n",
    "- <mark>solver</mark> : choice of solver \n",
    "- <mark>max_iter</mark> : number of iterations for the solver to converge, low iterations can lead to underfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C vs. accuracies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Train Accuracy: 0.742 at C = 0.4\n",
      "Highest Test Accuracy: 0.734 at C = 0.4\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have X_train, X_test, y_train, and y_test\n",
    "# Replace these with your actual training and testing data\n",
    "\n",
    "# Define a range of values for C\n",
    "C_values = [0.2, 0.4, 0.6, 0.8, 1]\n",
    "\n",
    "# Initialize lists to store training and testing accuracies\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Iterate over different values of C\n",
    "for C_val in C_values:\n",
    "    # Train a logistic regression model\n",
    "    lg = LogisticRegression(C=C_val, random_state=42).fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the training and testing sets\n",
    "    y_train_pred = lg.predict(X_train)\n",
    "    y_test_pred = lg.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy and store in lists\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(C_values, train_accuracies, label='Train Accuracy', marker='o')\n",
    "plt.semilogx(C_values, test_accuracies, label='Test Accuracy', marker='o')\n",
    "plt.title('Effect of Regularization Strength (C) on Accuracy (C <= 1)')\n",
    "plt.xlabel('C (Regularization Strength)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(C_values, [f\"{val:.2f}\" for val in C_values])  # Set x-axis ticks to actual values\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find the index of the maximum train accuracy\n",
    "max_train_accuracy_index = train_accuracies.index(max(train_accuracies))\n",
    "# Find the corresponding C value for the maximum train accuracy\n",
    "max_train_accuracy_C = C_values[max_train_accuracy_index]\n",
    "\n",
    "# Find the index of the maximum test accuracy\n",
    "max_test_accuracy_index = test_accuracies.index(max(test_accuracies))\n",
    "# Find the corresponding C value for the maximum test accuracy\n",
    "max_test_accuracy_C = C_values[max_test_accuracy_index]\n",
    "\n",
    "# Print the results\n",
    "print(f'Highest Train Accuracy: {max(train_accuracies):.3f} at C = {max_train_accuracy_C}')\n",
    "print(f'Highest Test Accuracy: {max(test_accuracies):.3f} at C = {max_test_accuracy_C}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Train Accuracy: 0.738 at C = 8\n",
      "Highest Test Accuracy: 0.730 at C = 6\n"
     ]
    }
   ],
   "source": [
    "# Define a range of values for C from 1 to 10\n",
    "C_values = list(range(1, 11))\n",
    "\n",
    "# Initialize lists to store training and testing accuracies\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Iterate over different values of C\n",
    "for C_val in C_values:\n",
    "    # Train a logistic regression model\n",
    "    lg = LogisticRegression(C=C_val, random_state=42).fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the training and testing sets\n",
    "    y_train_pred = lg.predict(X_train)\n",
    "    y_test_pred = lg.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy and store in lists\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(C_values, train_accuracies, label='Train Accuracy', marker='o')\n",
    "plt.plot(C_values, test_accuracies, label='Test Accuracy', marker='o')\n",
    "plt.title('Effect of Regularization Strength (C) on Accuracy (1 <= C <= 10)')\n",
    "plt.xlabel('C (Regularization Strength)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find the index of the maximum train accuracy\n",
    "max_train_accuracy_index = train_accuracies.index(max(train_accuracies))\n",
    "# Find the corresponding C value for the maximum train accuracy\n",
    "max_train_accuracy_C = C_values[max_train_accuracy_index]\n",
    "\n",
    "# Find the index of the maximum test accuracy\n",
    "max_test_accuracy_index = test_accuracies.index(max(test_accuracies))\n",
    "# Find the corresponding C value for the maximum test accuracy\n",
    "max_test_accuracy_C = C_values[max_test_accuracy_index]\n",
    "\n",
    "# Print the results\n",
    "print(f'Highest Train Accuracy: {max(train_accuracies):.3f} at C = {max_train_accuracy_C}')\n",
    "print(f'Highest Test Accuracy: {max(test_accuracies):.3f} at C = {max_test_accuracy_C}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_iter vs. accuracies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a range of values for max_iter\n",
    "max_iter_values = np.arange(100, 10000, 100)\n",
    "\n",
    "# Initialize lists to store training and testing accuracies\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Iterate over different values of max_iter\n",
    "for max_iter_val in max_iter_values:\n",
    "    # Train a logistic regression model\n",
    "    lg = LogisticRegression(max_iter=max_iter_val, random_state=42).fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the training and testing sets\n",
    "    y_train_pred = lg.predict(X_train)\n",
    "    y_test_pred = lg.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy and store in lists\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_iter_values, train_accuracies, label='Train Accuracy', marker='o')\n",
    "plt.plot(max_iter_values, test_accuracies, label='Test Accuracy', marker='o')\n",
    "plt.title('Effect of Maximum Iterations (max_iter) on Accuracy')\n",
    "plt.xlabel('max_iter (Maximum Iterations)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# important to note that this is subject to different solvers as well \n",
    "# the accuracy tends to plateau after 500 iterations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning using GridSearchCV \n",
    "- uses cross validation \n",
    "- goes through different combinations of parameters \n",
    "- from the seeing how the model performs based on individual parameters, it can be used as a gauge on what to values to input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty' : ['l1','l2','elasticnet'], # type of penalty? \n",
    "              'C' : [0.2,0.5,0.8,1], # lower C - underfit, higher C - overfit \n",
    "              'solver' : ['lbfgs','saga','sag','liblinear','newton-cg','newton-cholesky'], # different solvers \n",
    "              'max_iter' : [400,500,600]} # using the range where it was optimal but we want lower "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "[CV 1/5] END C=0.2, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=400, penalty=l1, solver=saga;, score=0.573 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=400, penalty=l1, solver=saga;, score=0.583 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=400, penalty=l1, solver=saga;, score=0.577 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=400, penalty=l1, solver=saga;, score=0.535 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=400, penalty=l1, solver=saga;, score=0.577 total time=   1.2s\n",
      "[CV 1/5] END C=0.2, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=400, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=400, penalty=l1, solver=liblinear;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=400, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=400, penalty=l1, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=400, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=400, penalty=l2, solver=lbfgs;, score=0.769 total time=   0.1s\n",
      "[CV 2/5] END C=0.2, max_iter=400, penalty=l2, solver=lbfgs;, score=0.731 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=400, penalty=l2, solver=lbfgs;, score=0.786 total time=   0.1s\n",
      "[CV 4/5] END C=0.2, max_iter=400, penalty=l2, solver=lbfgs;, score=0.737 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=400, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=400, penalty=l2, solver=saga;, score=0.573 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=400, penalty=l2, solver=saga;, score=0.584 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=400, penalty=l2, solver=saga;, score=0.536 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=400, penalty=l2, solver=sag;, score=0.613 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=400, penalty=l2, solver=sag;, score=0.608 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=400, penalty=l2, solver=sag;, score=0.606 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=400, penalty=l2, solver=sag;, score=0.561 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=400, penalty=l2, solver=sag;, score=0.595 total time=   0.7s\n",
      "[CV 1/5] END C=0.2, max_iter=400, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=400, penalty=l2, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=400, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=400, penalty=l2, solver=liblinear;, score=0.775 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=400, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=400, penalty=l2, solver=newton-cg;, score=0.778 total time=   0.2s\n",
      "[CV 2/5] END C=0.2, max_iter=400, penalty=l2, solver=newton-cg;, score=0.777 total time=   0.2s\n",
      "[CV 3/5] END C=0.2, max_iter=400, penalty=l2, solver=newton-cg;, score=0.789 total time=   0.1s\n",
      "[CV 4/5] END C=0.2, max_iter=400, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.2s\n",
      "[CV 5/5] END C=0.2, max_iter=400, penalty=l2, solver=newton-cg;, score=0.792 total time=   0.2s\n",
      "[CV 1/5] END C=0.2, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=500, penalty=l1, solver=saga;, score=0.584 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=500, penalty=l1, solver=saga;, score=0.592 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=500, penalty=l1, solver=saga;, score=0.579 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=500, penalty=l1, solver=saga;, score=0.544 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=500, penalty=l1, solver=saga;, score=0.583 total time=   1.4s\n",
      "[CV 1/5] END C=0.2, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=500, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=500, penalty=l1, solver=liblinear;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=500, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=500, penalty=l1, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=500, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=500, penalty=l2, solver=lbfgs;, score=0.769 total time=   0.1s\n",
      "[CV 2/5] END C=0.2, max_iter=500, penalty=l2, solver=lbfgs;, score=0.731 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=500, penalty=l2, solver=lbfgs;, score=0.786 total time=   0.1s\n",
      "[CV 4/5] END C=0.2, max_iter=500, penalty=l2, solver=lbfgs;, score=0.737 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=500, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=500, penalty=l2, solver=saga;, score=0.594 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=500, penalty=l2, solver=saga;, score=0.544 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=500, penalty=l2, solver=saga;, score=0.583 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=500, penalty=l2, solver=sag;, score=0.625 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=500, penalty=l2, solver=sag;, score=0.623 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=500, penalty=l2, solver=sag;, score=0.617 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=500, penalty=l2, solver=sag;, score=0.576 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=500, penalty=l2, solver=sag;, score=0.606 total time=   0.9s\n",
      "[CV 1/5] END C=0.2, max_iter=500, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=500, penalty=l2, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=500, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=500, penalty=l2, solver=liblinear;, score=0.775 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=500, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=500, penalty=l2, solver=newton-cg;, score=0.778 total time=   0.2s\n",
      "[CV 2/5] END C=0.2, max_iter=500, penalty=l2, solver=newton-cg;, score=0.777 total time=   0.2s\n",
      "[CV 3/5] END C=0.2, max_iter=500, penalty=l2, solver=newton-cg;, score=0.789 total time=   0.2s\n",
      "[CV 4/5] END C=0.2, max_iter=500, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.2s\n",
      "[CV 5/5] END C=0.2, max_iter=500, penalty=l2, solver=newton-cg;, score=0.792 total time=   0.2s\n",
      "[CV 1/5] END C=0.2, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=600, penalty=l1, solver=saga;, score=0.593 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=600, penalty=l1, solver=saga;, score=0.596 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=600, penalty=l1, solver=saga;, score=0.589 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=600, penalty=l1, solver=saga;, score=0.551 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=600, penalty=l1, solver=saga;, score=0.588 total time=   2.1s\n",
      "[CV 1/5] END C=0.2, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=600, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=600, penalty=l1, solver=liblinear;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=600, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=600, penalty=l1, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=600, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=600, penalty=l2, solver=lbfgs;, score=0.769 total time=   0.1s\n",
      "[CV 2/5] END C=0.2, max_iter=600, penalty=l2, solver=lbfgs;, score=0.731 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=600, penalty=l2, solver=lbfgs;, score=0.786 total time=   0.1s\n",
      "[CV 4/5] END C=0.2, max_iter=600, penalty=l2, solver=lbfgs;, score=0.737 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=600, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=600, penalty=l2, solver=saga;, score=0.592 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=600, penalty=l2, solver=saga;, score=0.596 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=600, penalty=l2, solver=saga;, score=0.590 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=600, penalty=l2, solver=saga;, score=0.551 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=600, penalty=l2, solver=saga;, score=0.588 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=600, penalty=l2, solver=sag;, score=0.638 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=600, penalty=l2, solver=sag;, score=0.626 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=600, penalty=l2, solver=sag;, score=0.625 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=600, penalty=l2, solver=sag;, score=0.578 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=600, penalty=l2, solver=sag;, score=0.612 total time=   1.3s\n",
      "[CV 1/5] END C=0.2, max_iter=600, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=600, penalty=l2, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=600, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=600, penalty=l2, solver=liblinear;, score=0.775 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=600, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=600, penalty=l2, solver=newton-cg;, score=0.778 total time=   0.2s\n",
      "[CV 2/5] END C=0.2, max_iter=600, penalty=l2, solver=newton-cg;, score=0.777 total time=   0.2s\n",
      "[CV 3/5] END C=0.2, max_iter=600, penalty=l2, solver=newton-cg;, score=0.789 total time=   0.1s\n",
      "[CV 4/5] END C=0.2, max_iter=600, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.2s\n",
      "[CV 5/5] END C=0.2, max_iter=600, penalty=l2, solver=newton-cg;, score=0.792 total time=   0.2s\n",
      "[CV 1/5] END C=0.2, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=400, penalty=l1, solver=saga;, score=0.573 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=400, penalty=l1, solver=saga;, score=0.584 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=400, penalty=l1, solver=saga;, score=0.577 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=400, penalty=l1, solver=saga;, score=0.536 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=400, penalty=l1, solver=saga;, score=0.578 total time=   1.1s\n",
      "[CV 1/5] END C=0.5, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=400, penalty=l1, solver=liblinear;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=400, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=400, penalty=l1, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=400, penalty=l1, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=400, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=400, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=400, penalty=l2, solver=lbfgs;, score=0.776 total time=   0.1s\n",
      "[CV 3/5] END C=0.5, max_iter=400, penalty=l2, solver=lbfgs;, score=0.790 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=400, penalty=l2, solver=lbfgs;, score=0.768 total time=   0.1s\n",
      "[CV 5/5] END C=0.5, max_iter=400, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=400, penalty=l2, solver=saga;, score=0.573 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=400, penalty=l2, solver=saga;, score=0.584 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=400, penalty=l2, solver=saga;, score=0.536 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=400, penalty=l2, solver=sag;, score=0.613 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=400, penalty=l2, solver=sag;, score=0.608 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=400, penalty=l2, solver=sag;, score=0.606 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=400, penalty=l2, solver=sag;, score=0.561 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=400, penalty=l2, solver=sag;, score=0.595 total time=   0.8s\n",
      "[CV 1/5] END C=0.5, max_iter=400, penalty=l2, solver=liblinear;, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=400, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=400, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=400, penalty=l2, solver=liblinear;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=400, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=400, penalty=l2, solver=newton-cg;, score=0.783 total time=   0.2s\n",
      "[CV 2/5] END C=0.5, max_iter=400, penalty=l2, solver=newton-cg;, score=0.778 total time=   0.2s\n",
      "[CV 3/5] END C=0.5, max_iter=400, penalty=l2, solver=newton-cg;, score=0.798 total time=   0.2s\n",
      "[CV 4/5] END C=0.5, max_iter=400, penalty=l2, solver=newton-cg;, score=0.782 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=400, penalty=l2, solver=newton-cg;, score=0.793 total time=   0.2s\n",
      "[CV 1/5] END C=0.5, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=500, penalty=l1, solver=saga;, score=0.584 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=500, penalty=l1, solver=saga;, score=0.594 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=500, penalty=l1, solver=saga;, score=0.581 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=500, penalty=l1, solver=saga;, score=0.544 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=500, penalty=l1, solver=saga;, score=0.583 total time=   1.5s\n",
      "[CV 1/5] END C=0.5, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=500, penalty=l1, solver=liblinear;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=500, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=500, penalty=l1, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=500, penalty=l1, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=500, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=500, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n",
      "[CV 2/5] END C=0.5, max_iter=500, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.2s\n",
      "[CV 3/5] END C=0.5, max_iter=500, penalty=l2, solver=lbfgs;, score=0.790 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=500, penalty=l2, solver=lbfgs;, score=0.768 total time=   0.1s\n",
      "[CV 5/5] END C=0.5, max_iter=500, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=500, penalty=l2, solver=saga;, score=0.594 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=500, penalty=l2, solver=saga;, score=0.544 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=500, penalty=l2, solver=saga;, score=0.583 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=500, penalty=l2, solver=sag;, score=0.625 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=500, penalty=l2, solver=sag;, score=0.623 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=500, penalty=l2, solver=sag;, score=0.617 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=500, penalty=l2, solver=sag;, score=0.576 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=500, penalty=l2, solver=sag;, score=0.606 total time=   1.1s\n",
      "[CV 1/5] END C=0.5, max_iter=500, penalty=l2, solver=liblinear;, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=500, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=500, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=500, penalty=l2, solver=liblinear;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=500, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=500, penalty=l2, solver=newton-cg;, score=0.783 total time=   0.2s\n",
      "[CV 2/5] END C=0.5, max_iter=500, penalty=l2, solver=newton-cg;, score=0.778 total time=   0.1s\n",
      "[CV 3/5] END C=0.5, max_iter=500, penalty=l2, solver=newton-cg;, score=0.798 total time=   0.2s\n",
      "[CV 4/5] END C=0.5, max_iter=500, penalty=l2, solver=newton-cg;, score=0.782 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=500, penalty=l2, solver=newton-cg;, score=0.793 total time=   0.2s\n",
      "[CV 1/5] END C=0.5, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=600, penalty=l1, solver=saga;, score=0.592 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=600, penalty=l1, solver=saga;, score=0.596 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=600, penalty=l1, solver=saga;, score=0.589 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=600, penalty=l1, solver=saga;, score=0.551 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=600, penalty=l1, solver=saga;, score=0.588 total time=   2.0s\n",
      "[CV 1/5] END C=0.5, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=600, penalty=l1, solver=liblinear;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=600, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=600, penalty=l1, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=600, penalty=l1, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=600, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=600, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n",
      "[CV 2/5] END C=0.5, max_iter=600, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.2s\n",
      "[CV 3/5] END C=0.5, max_iter=600, penalty=l2, solver=lbfgs;, score=0.790 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=600, penalty=l2, solver=lbfgs;, score=0.768 total time=   0.2s\n",
      "[CV 5/5] END C=0.5, max_iter=600, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=600, penalty=l2, solver=saga;, score=0.592 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=600, penalty=l2, solver=saga;, score=0.596 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=600, penalty=l2, solver=saga;, score=0.590 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=600, penalty=l2, solver=saga;, score=0.551 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=600, penalty=l2, solver=saga;, score=0.588 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=600, penalty=l2, solver=sag;, score=0.638 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=600, penalty=l2, solver=sag;, score=0.626 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=600, penalty=l2, solver=sag;, score=0.625 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=600, penalty=l2, solver=sag;, score=0.578 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=600, penalty=l2, solver=sag;, score=0.612 total time=   1.3s\n",
      "[CV 1/5] END C=0.5, max_iter=600, penalty=l2, solver=liblinear;, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=600, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=600, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=600, penalty=l2, solver=liblinear;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=600, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=600, penalty=l2, solver=newton-cg;, score=0.783 total time=   0.2s\n",
      "[CV 2/5] END C=0.5, max_iter=600, penalty=l2, solver=newton-cg;, score=0.778 total time=   0.1s\n",
      "[CV 3/5] END C=0.5, max_iter=600, penalty=l2, solver=newton-cg;, score=0.798 total time=   0.2s\n",
      "[CV 4/5] END C=0.5, max_iter=600, penalty=l2, solver=newton-cg;, score=0.782 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=600, penalty=l2, solver=newton-cg;, score=0.793 total time=   0.2s\n",
      "[CV 1/5] END C=0.5, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=400, penalty=l1, solver=saga;, score=0.573 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=400, penalty=l1, solver=saga;, score=0.584 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=400, penalty=l1, solver=saga;, score=0.577 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=400, penalty=l1, solver=saga;, score=0.536 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=400, penalty=l1, solver=saga;, score=0.578 total time=   1.2s\n",
      "[CV 1/5] END C=0.8, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=400, penalty=l1, solver=liblinear;, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=400, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=400, penalty=l1, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=400, penalty=l1, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=400, penalty=l1, solver=liblinear;, score=0.797 total time=   0.1s\n",
      "[CV 1/5] END C=0.8, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=400, penalty=l2, solver=lbfgs;, score=0.717 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=400, penalty=l2, solver=lbfgs;, score=0.769 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=400, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.2s\n",
      "[CV 4/5] END C=0.8, max_iter=400, penalty=l2, solver=lbfgs;, score=0.766 total time=   0.1s\n",
      "[CV 5/5] END C=0.8, max_iter=400, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=400, penalty=l2, solver=saga;, score=0.573 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=400, penalty=l2, solver=saga;, score=0.584 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=400, penalty=l2, solver=saga;, score=0.536 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=400, penalty=l2, solver=sag;, score=0.613 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=400, penalty=l2, solver=sag;, score=0.608 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=400, penalty=l2, solver=sag;, score=0.606 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=400, penalty=l2, solver=sag;, score=0.561 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=400, penalty=l2, solver=sag;, score=0.595 total time=   0.8s\n",
      "[CV 1/5] END C=0.8, max_iter=400, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=400, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=400, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=400, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=400, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=400, penalty=l2, solver=newton-cg;, score=0.782 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=400, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END C=0.8, max_iter=400, penalty=l2, solver=newton-cg;, score=0.795 total time=   0.1s\n",
      "[CV 4/5] END C=0.8, max_iter=400, penalty=l2, solver=newton-cg;, score=0.780 total time=   0.2s\n",
      "[CV 5/5] END C=0.8, max_iter=400, penalty=l2, solver=newton-cg;, score=0.797 total time=   0.1s\n",
      "[CV 1/5] END C=0.8, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=500, penalty=l1, solver=saga;, score=0.584 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=500, penalty=l1, solver=saga;, score=0.594 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=500, penalty=l1, solver=saga;, score=0.581 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=500, penalty=l1, solver=saga;, score=0.544 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=500, penalty=l1, solver=saga;, score=0.583 total time=   1.3s\n",
      "[CV 1/5] END C=0.8, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=500, penalty=l1, solver=liblinear;, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=500, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=500, penalty=l1, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=500, penalty=l1, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=500, penalty=l1, solver=liblinear;, score=0.797 total time=   0.1s\n",
      "[CV 1/5] END C=0.8, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=500, penalty=l2, solver=lbfgs;, score=0.717 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=500, penalty=l2, solver=lbfgs;, score=0.769 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=500, penalty=l2, solver=lbfgs;, score=0.786 total time=   0.2s\n",
      "[CV 4/5] END C=0.8, max_iter=500, penalty=l2, solver=lbfgs;, score=0.766 total time=   0.1s\n",
      "[CV 5/5] END C=0.8, max_iter=500, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=500, penalty=l2, solver=saga;, score=0.594 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=500, penalty=l2, solver=saga;, score=0.544 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=500, penalty=l2, solver=saga;, score=0.583 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=500, penalty=l2, solver=sag;, score=0.625 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=500, penalty=l2, solver=sag;, score=0.623 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=500, penalty=l2, solver=sag;, score=0.617 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=500, penalty=l2, solver=sag;, score=0.576 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=500, penalty=l2, solver=sag;, score=0.606 total time=   1.0s\n",
      "[CV 1/5] END C=0.8, max_iter=500, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=500, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=500, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=500, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=500, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=500, penalty=l2, solver=newton-cg;, score=0.782 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=500, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END C=0.8, max_iter=500, penalty=l2, solver=newton-cg;, score=0.795 total time=   0.1s\n",
      "[CV 4/5] END C=0.8, max_iter=500, penalty=l2, solver=newton-cg;, score=0.780 total time=   0.2s\n",
      "[CV 5/5] END C=0.8, max_iter=500, penalty=l2, solver=newton-cg;, score=0.797 total time=   0.2s\n",
      "[CV 1/5] END C=0.8, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=600, penalty=l1, solver=saga;, score=0.592 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=600, penalty=l1, solver=saga;, score=0.597 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=600, penalty=l1, solver=saga;, score=0.590 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=600, penalty=l1, solver=saga;, score=0.551 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=600, penalty=l1, solver=saga;, score=0.588 total time=   1.9s\n",
      "[CV 1/5] END C=0.8, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=600, penalty=l1, solver=liblinear;, score=0.785 total time=   0.1s\n",
      "[CV 2/5] END C=0.8, max_iter=600, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=600, penalty=l1, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=600, penalty=l1, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=600, penalty=l1, solver=liblinear;, score=0.797 total time=   0.1s\n",
      "[CV 1/5] END C=0.8, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=600, penalty=l2, solver=lbfgs;, score=0.717 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=600, penalty=l2, solver=lbfgs;, score=0.769 total time=   0.1s\n",
      "[CV 3/5] END C=0.8, max_iter=600, penalty=l2, solver=lbfgs;, score=0.793 total time=   0.3s\n",
      "[CV 4/5] END C=0.8, max_iter=600, penalty=l2, solver=lbfgs;, score=0.766 total time=   0.1s\n",
      "[CV 5/5] END C=0.8, max_iter=600, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=600, penalty=l2, solver=saga;, score=0.592 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=600, penalty=l2, solver=saga;, score=0.596 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=600, penalty=l2, solver=saga;, score=0.590 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=600, penalty=l2, solver=saga;, score=0.551 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=600, penalty=l2, solver=saga;, score=0.588 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=600, penalty=l2, solver=sag;, score=0.638 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=600, penalty=l2, solver=sag;, score=0.626 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=600, penalty=l2, solver=sag;, score=0.625 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=600, penalty=l2, solver=sag;, score=0.578 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=600, penalty=l2, solver=sag;, score=0.612 total time=   1.2s\n",
      "[CV 1/5] END C=0.8, max_iter=600, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=600, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=600, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=600, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=600, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=600, penalty=l2, solver=newton-cg;, score=0.782 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=600, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.1s\n",
      "[CV 3/5] END C=0.8, max_iter=600, penalty=l2, solver=newton-cg;, score=0.795 total time=   0.1s\n",
      "[CV 4/5] END C=0.8, max_iter=600, penalty=l2, solver=newton-cg;, score=0.780 total time=   0.2s\n",
      "[CV 5/5] END C=0.8, max_iter=600, penalty=l2, solver=newton-cg;, score=0.797 total time=   0.1s\n",
      "[CV 1/5] END C=0.8, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=400, penalty=l1, solver=saga;, score=0.573 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=400, penalty=l1, solver=saga;, score=0.584 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=400, penalty=l1, solver=saga;, score=0.577 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=400, penalty=l1, solver=saga;, score=0.536 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=400, penalty=l1, solver=saga;, score=0.578 total time=   1.3s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l1, solver=liblinear;, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l1, solver=liblinear;, score=0.777 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=l1, solver=liblinear;, score=0.795 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l1, solver=liblinear;, score=0.782 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.777 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.782 total time=   0.2s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=400, penalty=l2, solver=saga;, score=0.573 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=400, penalty=l2, solver=saga;, score=0.584 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=400, penalty=l2, solver=saga;, score=0.536 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=400, penalty=l2, solver=sag;, score=0.613 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=400, penalty=l2, solver=sag;, score=0.608 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=400, penalty=l2, solver=sag;, score=0.606 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=400, penalty=l2, solver=sag;, score=0.561 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=400, penalty=l2, solver=sag;, score=0.595 total time=   0.7s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l2, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l2, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=l2, solver=liblinear;, score=0.799 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.786 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.794 total time=   0.2s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.780 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.798 total time=   0.2s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=500, penalty=l1, solver=saga;, score=0.582 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=500, penalty=l1, solver=saga;, score=0.594 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=500, penalty=l1, solver=saga;, score=0.581 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=500, penalty=l1, solver=saga;, score=0.544 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=500, penalty=l1, solver=saga;, score=0.583 total time=   1.5s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l1, solver=liblinear;, score=0.785 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l1, solver=liblinear;, score=0.777 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=l1, solver=liblinear;, score=0.795 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l1, solver=liblinear;, score=0.782 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.777 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.788 total time=   0.3s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=500, penalty=l2, solver=saga;, score=0.594 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=500, penalty=l2, solver=saga;, score=0.544 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=500, penalty=l2, solver=saga;, score=0.583 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=500, penalty=l2, solver=sag;, score=0.625 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=500, penalty=l2, solver=sag;, score=0.623 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=500, penalty=l2, solver=sag;, score=0.617 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=500, penalty=l2, solver=sag;, score=0.576 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=500, penalty=l2, solver=sag;, score=0.606 total time=   1.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l2, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l2, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=l2, solver=liblinear;, score=0.799 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.786 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.794 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.780 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.798 total time=   0.2s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=600, penalty=l1, solver=saga;, score=0.592 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=600, penalty=l1, solver=saga;, score=0.597 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=600, penalty=l1, solver=saga;, score=0.590 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=600, penalty=l1, solver=saga;, score=0.551 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=600, penalty=l1, solver=saga;, score=0.588 total time=   1.8s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l1, solver=liblinear;, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l1, solver=liblinear;, score=0.777 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=l1, solver=liblinear;, score=0.795 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l1, solver=liblinear;, score=0.782 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.777 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.789 total time=   0.3s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=600, penalty=l2, solver=saga;, score=0.592 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=600, penalty=l2, solver=saga;, score=0.596 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=600, penalty=l2, solver=saga;, score=0.590 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=600, penalty=l2, solver=saga;, score=0.551 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=600, penalty=l2, solver=saga;, score=0.588 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=600, penalty=l2, solver=sag;, score=0.638 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=600, penalty=l2, solver=sag;, score=0.626 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=600, penalty=l2, solver=sag;, score=0.625 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=600, penalty=l2, solver=sag;, score=0.578 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=600, penalty=l2, solver=sag;, score=0.612 total time=   1.2s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l2, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l2, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=l2, solver=liblinear;, score=0.799 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.786 total time=   0.2s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.794 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.780 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "660 fits failed out of a total of 1080.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 434, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got newton-cholesky.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.56898304        nan 0.78551359        nan        nan\n",
      " 0.76053089 0.56945437 0.59647999 0.78252815 0.78268538        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.57636804        nan 0.78551359        nan        nan\n",
      " 0.76053089 0.57652514 0.60920756 0.78252815 0.78268538        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.58343881        nan 0.78551359        nan        nan\n",
      " 0.76053089 0.58343881 0.61580701 0.78252815 0.78268538        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.5696116         nan 0.78724179        nan        nan\n",
      " 0.77859844 0.56945437 0.59647999 0.78645625 0.78677034        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.57715371        nan 0.78724179        nan        nan\n",
      " 0.77891266 0.57652514 0.60920756 0.78645625 0.78677034        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.5832817         nan 0.78724179        nan        nan\n",
      " 0.77891266 0.58343881 0.61580701 0.78645625 0.78677034        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.5696116         nan 0.7873994         nan        nan\n",
      " 0.76304537 0.56945437 0.59647999 0.7861424  0.78614252        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.57715358        nan 0.7873994         nan        nan\n",
      " 0.76445936 0.57652514 0.60920756 0.7861424  0.78614252        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.58359592        nan 0.7873994         nan        nan\n",
      " 0.76571623 0.58343881 0.61580701 0.7861424  0.78614252        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.5696116         nan 0.78692795        nan        nan\n",
      " 0.77749843 0.56945437 0.59647999 0.78755675 0.78677108        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.57683936        nan 0.78692795        nan        nan\n",
      " 0.7787553  0.57652514 0.60920756 0.78755675 0.78677108        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.58359592        nan 0.78692795        nan        nan\n",
      " 0.77906952 0.58343881 0.61580701 0.78755675 0.78677108        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.798 total time=   0.2s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "grid = GridSearchCV(estimator=lg, param_grid=param_grid, scoring='accuracy',verbose = 3,refit=True).fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787556754460073\n",
      "{'C': 1, 'max_iter': 400, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Elapsed Time: 04:37\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "formatted_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "print(\"Elapsed Time: {}\".format(formatted_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# improved model from GS - lg2 \n",
    "lg2 = LogisticRegression(C = 0.8,max_iter=400,penalty='l1',solver='liblinear',random_state=42).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression(C=0.8, max_iter=400, penalty='l1', random_state=42,\n",
      "                   solver='liblinear')\n",
      "\n",
      "Training score: 0.7906976744186046\n",
      "Testing score: 0.7741935483870968\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1389\n",
      "           1       0.75      0.81      0.78      1339\n",
      "\n",
      "    accuracy                           0.77      2728\n",
      "   macro avg       0.78      0.77      0.77      2728\n",
      "weighted avg       0.78      0.77      0.77      2728\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate \n",
    "model_scores_classification(lg2)\n",
    "# can see that the model score increased but it overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd iteration - higher C range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty' : ['l1','l2','elasticnet'], # type of penalty? \n",
    "              'C' : [1,3,5,7,9], # lower C - underfit, higher C - overfit \n",
    "              'solver' : ['lbfgs','saga','sag','liblinear','newton-cg','newton-cholesky'], # different solvers \n",
    "              'max_iter' : [400,500,600]} # we want to achieve a model that can perform well at lower iterations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=400, penalty=l1, solver=saga;, score=0.573 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=400, penalty=l1, solver=saga;, score=0.584 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=400, penalty=l1, solver=saga;, score=0.577 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=400, penalty=l1, solver=saga;, score=0.536 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=400, penalty=l1, solver=saga;, score=0.578 total time=   1.3s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l1, solver=liblinear;, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l1, solver=liblinear;, score=0.777 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=l1, solver=liblinear;, score=0.795 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l1, solver=liblinear;, score=0.782 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.777 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.782 total time=   0.2s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=400, penalty=l2, solver=saga;, score=0.573 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=400, penalty=l2, solver=saga;, score=0.584 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=400, penalty=l2, solver=saga;, score=0.536 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=400, penalty=l2, solver=sag;, score=0.613 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=400, penalty=l2, solver=sag;, score=0.608 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=400, penalty=l2, solver=sag;, score=0.606 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=400, penalty=l2, solver=sag;, score=0.561 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=400, penalty=l2, solver=sag;, score=0.595 total time=   0.7s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l2, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l2, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=l2, solver=liblinear;, score=0.799 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.786 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.794 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.780 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.798 total time=   0.2s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=500, penalty=l1, solver=saga;, score=0.582 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=500, penalty=l1, solver=saga;, score=0.594 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=500, penalty=l1, solver=saga;, score=0.581 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=500, penalty=l1, solver=saga;, score=0.544 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=500, penalty=l1, solver=saga;, score=0.583 total time=   1.5s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l1, solver=liblinear;, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l1, solver=liblinear;, score=0.777 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=l1, solver=liblinear;, score=0.795 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l1, solver=liblinear;, score=0.782 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.777 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.788 total time=   0.3s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=500, penalty=l2, solver=saga;, score=0.594 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=500, penalty=l2, solver=saga;, score=0.544 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=500, penalty=l2, solver=saga;, score=0.583 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=500, penalty=l2, solver=sag;, score=0.625 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=500, penalty=l2, solver=sag;, score=0.623 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=500, penalty=l2, solver=sag;, score=0.617 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=500, penalty=l2, solver=sag;, score=0.576 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=500, penalty=l2, solver=sag;, score=0.606 total time=   1.1s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l2, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l2, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=l2, solver=liblinear;, score=0.799 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.786 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.794 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.780 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.798 total time=   0.2s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=600, penalty=l1, solver=saga;, score=0.592 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=600, penalty=l1, solver=saga;, score=0.597 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=600, penalty=l1, solver=saga;, score=0.590 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=600, penalty=l1, solver=saga;, score=0.551 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=600, penalty=l1, solver=saga;, score=0.588 total time=   1.9s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l1, solver=liblinear;, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l1, solver=liblinear;, score=0.777 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=l1, solver=liblinear;, score=0.795 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l1, solver=liblinear;, score=0.782 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.777 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.789 total time=   0.3s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=600, penalty=l2, solver=saga;, score=0.592 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=600, penalty=l2, solver=saga;, score=0.596 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=600, penalty=l2, solver=saga;, score=0.590 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=600, penalty=l2, solver=saga;, score=0.551 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=600, penalty=l2, solver=saga;, score=0.588 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=600, penalty=l2, solver=sag;, score=0.638 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=600, penalty=l2, solver=sag;, score=0.626 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=600, penalty=l2, solver=sag;, score=0.625 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=600, penalty=l2, solver=sag;, score=0.578 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=600, penalty=l2, solver=sag;, score=0.612 total time=   1.3s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l2, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l2, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=l2, solver=liblinear;, score=0.799 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.786 total time=   0.2s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.794 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.780 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.798 total time=   0.2s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3, max_iter=400, penalty=l1, solver=saga;, score=0.573 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3, max_iter=400, penalty=l1, solver=saga;, score=0.584 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3, max_iter=400, penalty=l1, solver=saga;, score=0.577 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3, max_iter=400, penalty=l1, solver=saga;, score=0.536 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3, max_iter=400, penalty=l1, solver=saga;, score=0.577 total time=   1.2s\n",
      "[CV 1/5] END C=3, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=400, penalty=l1, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=400, penalty=l1, solver=liblinear;, score=0.774 total time=   0.1s\n",
      "[CV 3/5] END C=3, max_iter=400, penalty=l1, solver=liblinear;, score=0.795 total time=   0.1s\n",
      "[CV 4/5] END C=3, max_iter=400, penalty=l1, solver=liblinear;, score=0.782 total time=   0.2s\n",
      "[CV 5/5] END C=3, max_iter=400, penalty=l1, solver=liblinear;, score=0.796 total time=   0.4s\n",
      "[CV 1/5] END C=3, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=400, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n",
      "[CV 2/5] END C=3, max_iter=400, penalty=l2, solver=lbfgs;, score=0.770 total time=   0.1s\n",
      "[CV 3/5] END C=3, max_iter=400, penalty=l2, solver=lbfgs;, score=0.776 total time=   0.1s\n",
      "[CV 4/5] END C=3, max_iter=400, penalty=l2, solver=lbfgs;, score=0.773 total time=   0.1s\n",
      "[CV 5/5] END C=3, max_iter=400, penalty=l2, solver=lbfgs;, score=0.777 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3, max_iter=400, penalty=l2, solver=saga;, score=0.573 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3, max_iter=400, penalty=l2, solver=saga;, score=0.584 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3, max_iter=400, penalty=l2, solver=saga;, score=0.536 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3, max_iter=400, penalty=l2, solver=sag;, score=0.613 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3, max_iter=400, penalty=l2, solver=sag;, score=0.608 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3, max_iter=400, penalty=l2, solver=sag;, score=0.606 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3, max_iter=400, penalty=l2, solver=sag;, score=0.561 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3, max_iter=400, penalty=l2, solver=sag;, score=0.595 total time=   0.8s\n",
      "[CV 1/5] END C=3, max_iter=400, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=400, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=400, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=400, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=400, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3, max_iter=400, penalty=l2, solver=newton-cg;, score=0.784 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3, max_iter=400, penalty=l2, solver=newton-cg;, score=0.777 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3, max_iter=400, penalty=l2, solver=newton-cg;, score=0.796 total time=   0.1s\n",
      "[CV 4/5] END C=3, max_iter=400, penalty=l2, solver=newton-cg;, score=0.782 total time=   0.2s\n",
      "[CV 5/5] END C=3, max_iter=400, penalty=l2, solver=newton-cg;, score=0.796 total time=   0.1s\n",
      "[CV 1/5] END C=3, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3, max_iter=500, penalty=l1, solver=saga;, score=0.581 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3, max_iter=500, penalty=l1, solver=saga;, score=0.594 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3, max_iter=500, penalty=l1, solver=saga;, score=0.581 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3, max_iter=500, penalty=l1, solver=saga;, score=0.544 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3, max_iter=500, penalty=l1, solver=saga;, score=0.583 total time=   1.4s\n",
      "[CV 1/5] END C=3, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=500, penalty=l1, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=500, penalty=l1, solver=liblinear;, score=0.774 total time=   0.1s\n",
      "[CV 3/5] END C=3, max_iter=500, penalty=l1, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=500, penalty=l1, solver=liblinear;, score=0.782 total time=   0.2s\n",
      "[CV 5/5] END C=3, max_iter=500, penalty=l1, solver=liblinear;, score=0.796 total time=   0.4s\n",
      "[CV 1/5] END C=3, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=500, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n",
      "[CV 2/5] END C=3, max_iter=500, penalty=l2, solver=lbfgs;, score=0.770 total time=   0.1s\n",
      "[CV 3/5] END C=3, max_iter=500, penalty=l2, solver=lbfgs;, score=0.776 total time=   0.1s\n",
      "[CV 4/5] END C=3, max_iter=500, penalty=l2, solver=lbfgs;, score=0.773 total time=   0.1s\n",
      "[CV 5/5] END C=3, max_iter=500, penalty=l2, solver=lbfgs;, score=0.777 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3, max_iter=500, penalty=l2, solver=saga;, score=0.594 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3, max_iter=500, penalty=l2, solver=saga;, score=0.544 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3, max_iter=500, penalty=l2, solver=saga;, score=0.583 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3, max_iter=500, penalty=l2, solver=sag;, score=0.625 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3, max_iter=500, penalty=l2, solver=sag;, score=0.623 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3, max_iter=500, penalty=l2, solver=sag;, score=0.617 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3, max_iter=500, penalty=l2, solver=sag;, score=0.576 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3, max_iter=500, penalty=l2, solver=sag;, score=0.606 total time=   1.0s\n",
      "[CV 1/5] END C=3, max_iter=500, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=500, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=500, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=500, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=500, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3, max_iter=500, penalty=l2, solver=newton-cg;, score=0.784 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3, max_iter=500, penalty=l2, solver=newton-cg;, score=0.777 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3, max_iter=500, penalty=l2, solver=newton-cg;, score=0.796 total time=   0.1s\n",
      "[CV 4/5] END C=3, max_iter=500, penalty=l2, solver=newton-cg;, score=0.782 total time=   0.2s\n",
      "[CV 5/5] END C=3, max_iter=500, penalty=l2, solver=newton-cg;, score=0.796 total time=   0.1s\n",
      "[CV 1/5] END C=3, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3, max_iter=600, penalty=l1, solver=saga;, score=0.592 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3, max_iter=600, penalty=l1, solver=saga;, score=0.596 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3, max_iter=600, penalty=l1, solver=saga;, score=0.590 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3, max_iter=600, penalty=l1, solver=saga;, score=0.551 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3, max_iter=600, penalty=l1, solver=saga;, score=0.588 total time=   2.4s\n",
      "[CV 1/5] END C=3, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=600, penalty=l1, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=600, penalty=l1, solver=liblinear;, score=0.774 total time=   0.1s\n",
      "[CV 3/5] END C=3, max_iter=600, penalty=l1, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=600, penalty=l1, solver=liblinear;, score=0.782 total time=   0.2s\n",
      "[CV 5/5] END C=3, max_iter=600, penalty=l1, solver=liblinear;, score=0.796 total time=   0.4s\n",
      "[CV 1/5] END C=3, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=600, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n",
      "[CV 2/5] END C=3, max_iter=600, penalty=l2, solver=lbfgs;, score=0.770 total time=   0.1s\n",
      "[CV 3/5] END C=3, max_iter=600, penalty=l2, solver=lbfgs;, score=0.776 total time=   0.1s\n",
      "[CV 4/5] END C=3, max_iter=600, penalty=l2, solver=lbfgs;, score=0.773 total time=   0.1s\n",
      "[CV 5/5] END C=3, max_iter=600, penalty=l2, solver=lbfgs;, score=0.777 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3, max_iter=600, penalty=l2, solver=saga;, score=0.592 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3, max_iter=600, penalty=l2, solver=saga;, score=0.596 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3, max_iter=600, penalty=l2, solver=saga;, score=0.590 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3, max_iter=600, penalty=l2, solver=saga;, score=0.551 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3, max_iter=600, penalty=l2, solver=saga;, score=0.588 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3, max_iter=600, penalty=l2, solver=sag;, score=0.638 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3, max_iter=600, penalty=l2, solver=sag;, score=0.626 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3, max_iter=600, penalty=l2, solver=sag;, score=0.625 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3, max_iter=600, penalty=l2, solver=sag;, score=0.578 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3, max_iter=600, penalty=l2, solver=sag;, score=0.612 total time=   1.1s\n",
      "[CV 1/5] END C=3, max_iter=600, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=600, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=600, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=600, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=600, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3, max_iter=600, penalty=l2, solver=newton-cg;, score=0.784 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3, max_iter=600, penalty=l2, solver=newton-cg;, score=0.777 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3, max_iter=600, penalty=l2, solver=newton-cg;, score=0.796 total time=   0.1s\n",
      "[CV 4/5] END C=3, max_iter=600, penalty=l2, solver=newton-cg;, score=0.782 total time=   0.3s\n",
      "[CV 5/5] END C=3, max_iter=600, penalty=l2, solver=newton-cg;, score=0.796 total time=   0.2s\n",
      "[CV 1/5] END C=3, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5, max_iter=400, penalty=l1, solver=saga;, score=0.573 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5, max_iter=400, penalty=l1, solver=saga;, score=0.584 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5, max_iter=400, penalty=l1, solver=saga;, score=0.577 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5, max_iter=400, penalty=l1, solver=saga;, score=0.536 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5, max_iter=400, penalty=l1, solver=saga;, score=0.577 total time=   1.3s\n",
      "[CV 1/5] END C=5, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=400, penalty=l1, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=400, penalty=l1, solver=liblinear;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=400, penalty=l1, solver=liblinear;, score=0.795 total time=   0.4s\n",
      "[CV 4/5] END C=5, max_iter=400, penalty=l1, solver=liblinear;, score=0.781 total time=   0.2s\n",
      "[CV 5/5] END C=5, max_iter=400, penalty=l1, solver=liblinear;, score=0.796 total time=   0.5s\n",
      "[CV 1/5] END C=5, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=400, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n",
      "[CV 2/5] END C=5, max_iter=400, penalty=l2, solver=lbfgs;, score=0.773 total time=   0.1s\n",
      "[CV 3/5] END C=5, max_iter=400, penalty=l2, solver=lbfgs;, score=0.782 total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=400, penalty=l2, solver=lbfgs;, score=0.772 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5, max_iter=400, penalty=l2, solver=lbfgs;, score=0.791 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5, max_iter=400, penalty=l2, solver=saga;, score=0.573 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5, max_iter=400, penalty=l2, solver=saga;, score=0.584 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5, max_iter=400, penalty=l2, solver=saga;, score=0.536 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5, max_iter=400, penalty=l2, solver=sag;, score=0.613 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5, max_iter=400, penalty=l2, solver=sag;, score=0.608 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5, max_iter=400, penalty=l2, solver=sag;, score=0.606 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5, max_iter=400, penalty=l2, solver=sag;, score=0.561 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5, max_iter=400, penalty=l2, solver=sag;, score=0.595 total time=   0.9s\n",
      "[CV 1/5] END C=5, max_iter=400, penalty=l2, solver=liblinear;, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=400, penalty=l2, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=400, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=400, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=400, penalty=l2, solver=liblinear;, score=0.797 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5, max_iter=400, penalty=l2, solver=newton-cg;, score=0.784 total time=   0.2s\n",
      "[CV 2/5] END C=5, max_iter=400, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5, max_iter=400, penalty=l2, solver=newton-cg;, score=0.795 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5, max_iter=400, penalty=l2, solver=newton-cg;, score=0.781 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5, max_iter=400, penalty=l2, solver=newton-cg;, score=0.796 total time=   0.2s\n",
      "[CV 1/5] END C=5, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5, max_iter=500, penalty=l1, solver=saga;, score=0.581 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5, max_iter=500, penalty=l1, solver=saga;, score=0.594 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5, max_iter=500, penalty=l1, solver=saga;, score=0.581 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5, max_iter=500, penalty=l1, solver=saga;, score=0.544 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5, max_iter=500, penalty=l1, solver=saga;, score=0.583 total time=   1.5s\n",
      "[CV 1/5] END C=5, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=500, penalty=l1, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=500, penalty=l1, solver=liblinear;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=500, penalty=l1, solver=liblinear;, score=0.795 total time=   0.3s\n",
      "[CV 4/5] END C=5, max_iter=500, penalty=l1, solver=liblinear;, score=0.781 total time=   0.2s\n",
      "[CV 5/5] END C=5, max_iter=500, penalty=l1, solver=liblinear;, score=0.796 total time=   0.4s\n",
      "[CV 1/5] END C=5, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=500, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n",
      "[CV 2/5] END C=5, max_iter=500, penalty=l2, solver=lbfgs;, score=0.773 total time=   0.1s\n",
      "[CV 3/5] END C=5, max_iter=500, penalty=l2, solver=lbfgs;, score=0.782 total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=500, penalty=l2, solver=lbfgs;, score=0.772 total time=   0.1s\n",
      "[CV 5/5] END C=5, max_iter=500, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5, max_iter=500, penalty=l2, solver=saga;, score=0.594 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5, max_iter=500, penalty=l2, solver=saga;, score=0.544 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5, max_iter=500, penalty=l2, solver=saga;, score=0.583 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5, max_iter=500, penalty=l2, solver=sag;, score=0.625 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5, max_iter=500, penalty=l2, solver=sag;, score=0.623 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5, max_iter=500, penalty=l2, solver=sag;, score=0.617 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5, max_iter=500, penalty=l2, solver=sag;, score=0.576 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5, max_iter=500, penalty=l2, solver=sag;, score=0.606 total time=   0.9s\n",
      "[CV 1/5] END C=5, max_iter=500, penalty=l2, solver=liblinear;, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=500, penalty=l2, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=500, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=500, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=500, penalty=l2, solver=liblinear;, score=0.797 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5, max_iter=500, penalty=l2, solver=newton-cg;, score=0.784 total time=   0.1s\n",
      "[CV 2/5] END C=5, max_iter=500, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5, max_iter=500, penalty=l2, solver=newton-cg;, score=0.795 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5, max_iter=500, penalty=l2, solver=newton-cg;, score=0.781 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5, max_iter=500, penalty=l2, solver=newton-cg;, score=0.796 total time=   0.2s\n",
      "[CV 1/5] END C=5, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5, max_iter=600, penalty=l1, solver=saga;, score=0.592 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5, max_iter=600, penalty=l1, solver=saga;, score=0.596 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5, max_iter=600, penalty=l1, solver=saga;, score=0.590 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5, max_iter=600, penalty=l1, solver=saga;, score=0.551 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5, max_iter=600, penalty=l1, solver=saga;, score=0.588 total time=   1.9s\n",
      "[CV 1/5] END C=5, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=600, penalty=l1, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=600, penalty=l1, solver=liblinear;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=600, penalty=l1, solver=liblinear;, score=0.795 total time=   0.3s\n",
      "[CV 4/5] END C=5, max_iter=600, penalty=l1, solver=liblinear;, score=0.781 total time=   0.2s\n",
      "[CV 5/5] END C=5, max_iter=600, penalty=l1, solver=liblinear;, score=0.796 total time=   0.6s\n",
      "[CV 1/5] END C=5, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=600, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n",
      "[CV 2/5] END C=5, max_iter=600, penalty=l2, solver=lbfgs;, score=0.773 total time=   0.1s\n",
      "[CV 3/5] END C=5, max_iter=600, penalty=l2, solver=lbfgs;, score=0.782 total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=600, penalty=l2, solver=lbfgs;, score=0.772 total time=   0.1s\n",
      "[CV 5/5] END C=5, max_iter=600, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5, max_iter=600, penalty=l2, solver=saga;, score=0.592 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5, max_iter=600, penalty=l2, solver=saga;, score=0.596 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5, max_iter=600, penalty=l2, solver=saga;, score=0.590 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5, max_iter=600, penalty=l2, solver=saga;, score=0.551 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5, max_iter=600, penalty=l2, solver=saga;, score=0.588 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5, max_iter=600, penalty=l2, solver=sag;, score=0.638 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5, max_iter=600, penalty=l2, solver=sag;, score=0.626 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5, max_iter=600, penalty=l2, solver=sag;, score=0.625 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5, max_iter=600, penalty=l2, solver=sag;, score=0.578 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5, max_iter=600, penalty=l2, solver=sag;, score=0.612 total time=   1.3s\n",
      "[CV 1/5] END C=5, max_iter=600, penalty=l2, solver=liblinear;, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=600, penalty=l2, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=600, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=600, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=600, penalty=l2, solver=liblinear;, score=0.797 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5, max_iter=600, penalty=l2, solver=newton-cg;, score=0.784 total time=   0.1s\n",
      "[CV 2/5] END C=5, max_iter=600, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5, max_iter=600, penalty=l2, solver=newton-cg;, score=0.795 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5, max_iter=600, penalty=l2, solver=newton-cg;, score=0.781 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5, max_iter=600, penalty=l2, solver=newton-cg;, score=0.796 total time=   0.2s\n",
      "[CV 1/5] END C=5, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=7, max_iter=400, penalty=l1, solver=saga;, score=0.573 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=7, max_iter=400, penalty=l1, solver=saga;, score=0.584 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=7, max_iter=400, penalty=l1, solver=saga;, score=0.577 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=7, max_iter=400, penalty=l1, solver=saga;, score=0.536 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=7, max_iter=400, penalty=l1, solver=saga;, score=0.577 total time=   1.1s\n",
      "[CV 1/5] END C=7, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=400, penalty=l1, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=400, penalty=l1, solver=liblinear;, score=0.774 total time=   0.8s\n",
      "[CV 3/5] END C=7, max_iter=400, penalty=l1, solver=liblinear;, score=0.794 total time=   0.6s\n",
      "[CV 4/5] END C=7, max_iter=400, penalty=l1, solver=liblinear;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=400, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=400, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=400, penalty=l2, solver=lbfgs;, score=0.767 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=7, max_iter=400, penalty=l2, solver=lbfgs;, score=0.789 total time=   0.2s\n",
      "[CV 4/5] END C=7, max_iter=400, penalty=l2, solver=lbfgs;, score=0.768 total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=400, penalty=l2, solver=lbfgs;, score=0.780 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=7, max_iter=400, penalty=l2, solver=saga;, score=0.573 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=7, max_iter=400, penalty=l2, solver=saga;, score=0.584 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=7, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=7, max_iter=400, penalty=l2, solver=saga;, score=0.536 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=7, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=7, max_iter=400, penalty=l2, solver=sag;, score=0.613 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=7, max_iter=400, penalty=l2, solver=sag;, score=0.608 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=7, max_iter=400, penalty=l2, solver=sag;, score=0.606 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=7, max_iter=400, penalty=l2, solver=sag;, score=0.561 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=7, max_iter=400, penalty=l2, solver=sag;, score=0.595 total time=   0.8s\n",
      "[CV 1/5] END C=7, max_iter=400, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=400, penalty=l2, solver=liblinear;, score=0.775 total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=400, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=400, penalty=l2, solver=liblinear;, score=0.785 total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=400, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=400, penalty=l2, solver=newton-cg;, score=0.784 total time=   0.2s\n",
      "[CV 2/5] END C=7, max_iter=400, penalty=l2, solver=newton-cg;, score=0.775 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=7, max_iter=400, penalty=l2, solver=newton-cg;, score=0.794 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=7, max_iter=400, penalty=l2, solver=newton-cg;, score=0.781 total time=   0.2s\n",
      "[CV 5/5] END C=7, max_iter=400, penalty=l2, solver=newton-cg;, score=0.796 total time=   0.3s\n",
      "[CV 1/5] END C=7, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=7, max_iter=500, penalty=l1, solver=saga;, score=0.581 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=7, max_iter=500, penalty=l1, solver=saga;, score=0.594 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=7, max_iter=500, penalty=l1, solver=saga;, score=0.581 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=7, max_iter=500, penalty=l1, solver=saga;, score=0.544 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=7, max_iter=500, penalty=l1, solver=saga;, score=0.583 total time=   1.6s\n",
      "[CV 1/5] END C=7, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=500, penalty=l1, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=500, penalty=l1, solver=liblinear;, score=0.774 total time=   0.7s\n",
      "[CV 3/5] END C=7, max_iter=500, penalty=l1, solver=liblinear;, score=0.794 total time=   0.5s\n",
      "[CV 4/5] END C=7, max_iter=500, penalty=l1, solver=liblinear;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=500, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=500, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=500, penalty=l2, solver=lbfgs;, score=0.767 total time=   0.1s\n",
      "[CV 3/5] END C=7, max_iter=500, penalty=l2, solver=lbfgs;, score=0.788 total time=   0.2s\n",
      "[CV 4/5] END C=7, max_iter=500, penalty=l2, solver=lbfgs;, score=0.768 total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=500, penalty=l2, solver=lbfgs;, score=0.780 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=7, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=7, max_iter=500, penalty=l2, solver=saga;, score=0.594 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=7, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=7, max_iter=500, penalty=l2, solver=saga;, score=0.544 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=7, max_iter=500, penalty=l2, solver=saga;, score=0.583 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=7, max_iter=500, penalty=l2, solver=sag;, score=0.625 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=7, max_iter=500, penalty=l2, solver=sag;, score=0.623 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=7, max_iter=500, penalty=l2, solver=sag;, score=0.617 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=7, max_iter=500, penalty=l2, solver=sag;, score=0.576 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=7, max_iter=500, penalty=l2, solver=sag;, score=0.606 total time=   1.1s\n",
      "[CV 1/5] END C=7, max_iter=500, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=500, penalty=l2, solver=liblinear;, score=0.775 total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=500, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=500, penalty=l2, solver=liblinear;, score=0.785 total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=500, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=500, penalty=l2, solver=newton-cg;, score=0.784 total time=   0.2s\n",
      "[CV 2/5] END C=7, max_iter=500, penalty=l2, solver=newton-cg;, score=0.775 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=7, max_iter=500, penalty=l2, solver=newton-cg;, score=0.794 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=7, max_iter=500, penalty=l2, solver=newton-cg;, score=0.781 total time=   0.2s\n",
      "[CV 5/5] END C=7, max_iter=500, penalty=l2, solver=newton-cg;, score=0.796 total time=   0.2s\n",
      "[CV 1/5] END C=7, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=7, max_iter=600, penalty=l1, solver=saga;, score=0.592 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=7, max_iter=600, penalty=l1, solver=saga;, score=0.596 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=7, max_iter=600, penalty=l1, solver=saga;, score=0.590 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=7, max_iter=600, penalty=l1, solver=saga;, score=0.551 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=7, max_iter=600, penalty=l1, solver=saga;, score=0.588 total time=   1.8s\n",
      "[CV 1/5] END C=7, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=600, penalty=l1, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=600, penalty=l1, solver=liblinear;, score=0.774 total time=   0.8s\n",
      "[CV 3/5] END C=7, max_iter=600, penalty=l1, solver=liblinear;, score=0.794 total time=   0.6s\n",
      "[CV 4/5] END C=7, max_iter=600, penalty=l1, solver=liblinear;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=600, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=600, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=600, penalty=l2, solver=lbfgs;, score=0.767 total time=   0.1s\n",
      "[CV 3/5] END C=7, max_iter=600, penalty=l2, solver=lbfgs;, score=0.788 total time=   0.2s\n",
      "[CV 4/5] END C=7, max_iter=600, penalty=l2, solver=lbfgs;, score=0.768 total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=600, penalty=l2, solver=lbfgs;, score=0.780 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=7, max_iter=600, penalty=l2, solver=saga;, score=0.592 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=7, max_iter=600, penalty=l2, solver=saga;, score=0.596 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=7, max_iter=600, penalty=l2, solver=saga;, score=0.590 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=7, max_iter=600, penalty=l2, solver=saga;, score=0.551 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=7, max_iter=600, penalty=l2, solver=saga;, score=0.588 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=7, max_iter=600, penalty=l2, solver=sag;, score=0.638 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=7, max_iter=600, penalty=l2, solver=sag;, score=0.626 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=7, max_iter=600, penalty=l2, solver=sag;, score=0.625 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=7, max_iter=600, penalty=l2, solver=sag;, score=0.578 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=7, max_iter=600, penalty=l2, solver=sag;, score=0.612 total time=   1.2s\n",
      "[CV 1/5] END C=7, max_iter=600, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=600, penalty=l2, solver=liblinear;, score=0.775 total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=600, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=600, penalty=l2, solver=liblinear;, score=0.785 total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=600, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=600, penalty=l2, solver=newton-cg;, score=0.784 total time=   0.1s\n",
      "[CV 2/5] END C=7, max_iter=600, penalty=l2, solver=newton-cg;, score=0.775 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=7, max_iter=600, penalty=l2, solver=newton-cg;, score=0.794 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=7, max_iter=600, penalty=l2, solver=newton-cg;, score=0.781 total time=   0.2s\n",
      "[CV 5/5] END C=7, max_iter=600, penalty=l2, solver=newton-cg;, score=0.796 total time=   0.2s\n",
      "[CV 1/5] END C=7, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=9, max_iter=400, penalty=l1, solver=saga;, score=0.573 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=9, max_iter=400, penalty=l1, solver=saga;, score=0.584 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=9, max_iter=400, penalty=l1, solver=saga;, score=0.577 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=9, max_iter=400, penalty=l1, solver=saga;, score=0.536 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=9, max_iter=400, penalty=l1, solver=saga;, score=0.577 total time=   1.2s\n",
      "[CV 1/5] END C=9, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=400, penalty=l1, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=400, penalty=l1, solver=liblinear;, score=0.774 total time=   0.1s\n",
      "[CV 3/5] END C=9, max_iter=400, penalty=l1, solver=liblinear;, score=0.794 total time=   0.1s\n",
      "[CV 4/5] END C=9, max_iter=400, penalty=l1, solver=liblinear;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=400, penalty=l1, solver=liblinear;, score=0.796 total time=   0.1s\n",
      "[CV 1/5] END C=9, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=400, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=400, penalty=l2, solver=lbfgs;, score=0.780 total time=   0.1s\n",
      "[CV 2/5] END C=9, max_iter=400, penalty=l2, solver=lbfgs;, score=0.770 total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=400, penalty=l2, solver=lbfgs;, score=0.788 total time=   0.1s\n",
      "[CV 4/5] END C=9, max_iter=400, penalty=l2, solver=lbfgs;, score=0.771 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=9, max_iter=400, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=9, max_iter=400, penalty=l2, solver=saga;, score=0.573 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=9, max_iter=400, penalty=l2, solver=saga;, score=0.584 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=9, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=9, max_iter=400, penalty=l2, solver=saga;, score=0.536 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=9, max_iter=400, penalty=l2, solver=saga;, score=0.577 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=9, max_iter=400, penalty=l2, solver=sag;, score=0.613 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=9, max_iter=400, penalty=l2, solver=sag;, score=0.608 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=9, max_iter=400, penalty=l2, solver=sag;, score=0.606 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=9, max_iter=400, penalty=l2, solver=sag;, score=0.561 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=9, max_iter=400, penalty=l2, solver=sag;, score=0.595 total time=   0.9s\n",
      "[CV 1/5] END C=9, max_iter=400, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=400, penalty=l2, solver=liblinear;, score=0.773 total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=400, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=400, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=400, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=9, max_iter=400, penalty=l2, solver=newton-cg;, score=0.784 total time=   0.2s\n",
      "[CV 2/5] END C=9, max_iter=400, penalty=l2, solver=newton-cg;, score=0.773 total time=   0.3s\n",
      "[CV 3/5] END C=9, max_iter=400, penalty=l2, solver=newton-cg;, score=0.794 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=9, max_iter=400, penalty=l2, solver=newton-cg;, score=0.782 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=9, max_iter=400, penalty=l2, solver=newton-cg;, score=0.796 total time=   0.2s\n",
      "[CV 1/5] END C=9, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=400, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=400, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=400, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=400, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=400, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=400, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=400, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=9, max_iter=500, penalty=l1, solver=saga;, score=0.581 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=9, max_iter=500, penalty=l1, solver=saga;, score=0.594 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=9, max_iter=500, penalty=l1, solver=saga;, score=0.581 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=9, max_iter=500, penalty=l1, solver=saga;, score=0.544 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=9, max_iter=500, penalty=l1, solver=saga;, score=0.583 total time=   1.7s\n",
      "[CV 1/5] END C=9, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=500, penalty=l1, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=500, penalty=l1, solver=liblinear;, score=0.774 total time=   0.1s\n",
      "[CV 3/5] END C=9, max_iter=500, penalty=l1, solver=liblinear;, score=0.794 total time=   0.1s\n",
      "[CV 4/5] END C=9, max_iter=500, penalty=l1, solver=liblinear;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=500, penalty=l1, solver=liblinear;, score=0.796 total time=   0.1s\n",
      "[CV 1/5] END C=9, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=500, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=500, penalty=l2, solver=lbfgs;, score=0.780 total time=   0.1s\n",
      "[CV 2/5] END C=9, max_iter=500, penalty=l2, solver=lbfgs;, score=0.770 total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=500, penalty=l2, solver=lbfgs;, score=0.788 total time=   0.2s\n",
      "[CV 4/5] END C=9, max_iter=500, penalty=l2, solver=lbfgs;, score=0.771 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=9, max_iter=500, penalty=l2, solver=lbfgs;, score=0.792 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=9, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=9, max_iter=500, penalty=l2, solver=saga;, score=0.594 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=9, max_iter=500, penalty=l2, solver=saga;, score=0.581 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=9, max_iter=500, penalty=l2, solver=saga;, score=0.544 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=9, max_iter=500, penalty=l2, solver=saga;, score=0.583 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=9, max_iter=500, penalty=l2, solver=sag;, score=0.625 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=9, max_iter=500, penalty=l2, solver=sag;, score=0.623 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=9, max_iter=500, penalty=l2, solver=sag;, score=0.617 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=9, max_iter=500, penalty=l2, solver=sag;, score=0.576 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=9, max_iter=500, penalty=l2, solver=sag;, score=0.606 total time=   1.1s\n",
      "[CV 1/5] END C=9, max_iter=500, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=500, penalty=l2, solver=liblinear;, score=0.773 total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=500, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=500, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=500, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=9, max_iter=500, penalty=l2, solver=newton-cg;, score=0.784 total time=   0.3s\n",
      "[CV 2/5] END C=9, max_iter=500, penalty=l2, solver=newton-cg;, score=0.773 total time=   0.3s\n",
      "[CV 3/5] END C=9, max_iter=500, penalty=l2, solver=newton-cg;, score=0.794 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=9, max_iter=500, penalty=l2, solver=newton-cg;, score=0.782 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=9, max_iter=500, penalty=l2, solver=newton-cg;, score=0.796 total time=   0.2s\n",
      "[CV 1/5] END C=9, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=500, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=500, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=9, max_iter=600, penalty=l1, solver=saga;, score=0.592 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=9, max_iter=600, penalty=l1, solver=saga;, score=0.596 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=9, max_iter=600, penalty=l1, solver=saga;, score=0.590 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=9, max_iter=600, penalty=l1, solver=saga;, score=0.551 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=9, max_iter=600, penalty=l1, solver=saga;, score=0.588 total time=   1.9s\n",
      "[CV 1/5] END C=9, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=600, penalty=l1, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=600, penalty=l1, solver=liblinear;, score=0.774 total time=   0.1s\n",
      "[CV 3/5] END C=9, max_iter=600, penalty=l1, solver=liblinear;, score=0.794 total time=   0.1s\n",
      "[CV 4/5] END C=9, max_iter=600, penalty=l1, solver=liblinear;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=600, penalty=l1, solver=liblinear;, score=0.796 total time=   0.1s\n",
      "[CV 1/5] END C=9, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=600, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=600, penalty=l2, solver=lbfgs;, score=0.780 total time=   0.1s\n",
      "[CV 2/5] END C=9, max_iter=600, penalty=l2, solver=lbfgs;, score=0.770 total time=   0.1s\n",
      "[CV 3/5] END C=9, max_iter=600, penalty=l2, solver=lbfgs;, score=0.788 total time=   0.1s\n",
      "[CV 4/5] END C=9, max_iter=600, penalty=l2, solver=lbfgs;, score=0.771 total time=   0.1s\n",
      "[CV 5/5] END C=9, max_iter=600, penalty=l2, solver=lbfgs;, score=0.792 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=9, max_iter=600, penalty=l2, solver=saga;, score=0.592 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=9, max_iter=600, penalty=l2, solver=saga;, score=0.596 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=9, max_iter=600, penalty=l2, solver=saga;, score=0.590 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=9, max_iter=600, penalty=l2, solver=saga;, score=0.551 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=9, max_iter=600, penalty=l2, solver=saga;, score=0.588 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=9, max_iter=600, penalty=l2, solver=sag;, score=0.638 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=9, max_iter=600, penalty=l2, solver=sag;, score=0.626 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=9, max_iter=600, penalty=l2, solver=sag;, score=0.625 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=9, max_iter=600, penalty=l2, solver=sag;, score=0.578 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=9, max_iter=600, penalty=l2, solver=sag;, score=0.612 total time=   1.3s\n",
      "[CV 1/5] END C=9, max_iter=600, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=600, penalty=l2, solver=liblinear;, score=0.773 total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=600, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=600, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=600, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=9, max_iter=600, penalty=l2, solver=newton-cg;, score=0.784 total time=   0.2s\n",
      "[CV 2/5] END C=9, max_iter=600, penalty=l2, solver=newton-cg;, score=0.773 total time=   0.3s\n",
      "[CV 3/5] END C=9, max_iter=600, penalty=l2, solver=newton-cg;, score=0.794 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=9, max_iter=600, penalty=l2, solver=newton-cg;, score=0.782 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "825 fits failed out of a total of 1350.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "225 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 434, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got newton-cholesky.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.5696116         nan 0.78692795        nan        nan\n",
      " 0.77749843 0.56945437 0.59647999 0.78755675 0.78677108        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.57683936        nan 0.78692795        nan        nan\n",
      " 0.7787553  0.57652514 0.60920756 0.78755675 0.78677108        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.58359592        nan 0.78692795        nan        nan\n",
      " 0.77906952 0.58343881 0.61580701 0.78755675 0.78677108        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.56945437        nan 0.78598517        nan        nan\n",
      " 0.77498456 0.56945437 0.59647999 0.78692795 0.78708506        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.57668225        nan 0.78598517        nan        nan\n",
      " 0.77498456 0.57652514 0.60920756 0.78692795 0.78708506        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.58343881        nan 0.78598517        nan        nan\n",
      " 0.77498456 0.58343881 0.61580701 0.78692795 0.78708506        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.56945437        nan 0.78582806        nan        nan\n",
      " 0.77938584 0.56945437 0.59647999 0.78724229 0.78629939        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.57668225        nan 0.78582806        nan        nan\n",
      " 0.77702735 0.57652514 0.60920756 0.78724229 0.78629939        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.58343881        nan 0.78582806        nan        nan\n",
      " 0.77702735 0.58343881 0.61580701 0.78724229 0.78629939        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.56945437        nan 0.78582818        nan        nan\n",
      " 0.77639904 0.56945437 0.59647999 0.78692795 0.7861424         nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.57668225        nan 0.78582818        nan        nan\n",
      " 0.77624193 0.57652514 0.60920756 0.78692795 0.7861424         nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.58343881        nan 0.78582818        nan        nan\n",
      " 0.77624193 0.58343881 0.61580701 0.78692795 0.7861424         nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.56945437        nan 0.78582818        nan        nan\n",
      " 0.77922811 0.56945437 0.59647999 0.78629951 0.78582818        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.57668225        nan 0.78582818        nan        nan\n",
      " 0.78017151 0.57652514 0.60920756 0.78629951 0.78582818        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.58343881        nan 0.78582818        nan        nan\n",
      " 0.78017151 0.58343881 0.61580701 0.78629951 0.78582818        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=9, max_iter=600, penalty=l2, solver=newton-cg;, score=0.796 total time=   0.2s\n",
      "[CV 1/5] END C=9, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=600, penalty=l2, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=600, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=600, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=600, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=600, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=600, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9, max_iter=600, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "grid = GridSearchCV(estimator=lg, param_grid=param_grid, scoring='accuracy',verbose = 3,refit=True).fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787556754460073\n",
      "{'C': 1, 'max_iter': 400, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Elapsed Time: 06:06\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "formatted_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "print(\"Elapsed Time: {}\".format(formatted_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg3 = LogisticRegression(C=7,max_iter=400,penalty='l2',solver='liblinear').fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression(C=7, max_iter=400, solver='liblinear')\n",
      "\n",
      "Training score: 0.7905405405405406\n",
      "Testing score: 0.7741935483870968\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1389\n",
      "           1       0.75      0.81      0.78      1339\n",
      "\n",
      "    accuracy                           0.77      2728\n",
      "   macro avg       0.78      0.77      0.77      2728\n",
      "weighted avg       0.78      0.77      0.77      2728\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_scores_classification(lg3)\n",
    "# similar to model scores but the scores are overfit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron\n",
    "Parameters that can be tweaked: (however, what is the case when some params are specific to another? like solvers, e.g. solver = 'adam, epsilon only applies to that solver?)\n",
    "- <mark>hidden_layer_sizes</mark> : number of neurons in the hidden layer \n",
    "- <mark>activation</mark> : activation or squashing function for the hidden layer \n",
    "- <mark>solver</mark> : solver for weight optimization \n",
    "- <mark>max_iter</mark> : maximum number of iterations \n",
    "- <mark>alpha</mark> : regularisation term "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hidden layer sizes vs. model accuracy (baseline model) \n",
    "- sizes that are too small limits the capacity of learning, but too high layers may make the model fit training data too closely "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_layer_sizes = [(i,) for i in range(100, 610, 100)]\n",
    "\n",
    "train_mean_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for size in hidden_layer_sizes:\n",
    "    model = MLPClassifier(hidden_layer_sizes=size, random_state=42)\n",
    "    \n",
    "    # Perform 5-fold cross-validation on the training set\n",
    "    train_accuracies = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Record the mean accuracy across folds on the training set\n",
    "    train_mean_accuracies.append(np.mean(train_accuracies))\n",
    "    \n",
    "    # Fit the model on the full training set and evaluate on the test set\n",
    "    model.fit(X_train, y_train)\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plotting the graph\n",
    "plt.plot([str(size) for size in hidden_layer_sizes], train_mean_accuracies, marker='o', label='Train Set')\n",
    "plt.plot([str(size) for size in hidden_layer_sizes], test_accuracies, marker='o', label='Test Set')\n",
    "plt.xlabel('Hidden Layer Sizes')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('Hidden Layer Sizes vs Mean Accuracy for MLP Model')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hidden layer sizes vs. model accuracy (baseline model)  - lower number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_layer_sizes = [(i,) for i in range(10, 100, 10)]\n",
    "\n",
    "train_mean_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for size in hidden_layer_sizes:\n",
    "    model = MLPClassifier(hidden_layer_sizes=size, random_state=42)\n",
    "    \n",
    "    # Perform 5-fold cross-validation on the training set\n",
    "    train_accuracies = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Record the mean accuracy across folds on the training set\n",
    "    train_mean_accuracies.append(np.mean(train_accuracies))\n",
    "    \n",
    "    # Fit the model on the full training set and evaluate on the test set\n",
    "    model.fit(X_train, y_train)\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plotting the graph\n",
    "plt.plot([str(size) for size in hidden_layer_sizes], train_mean_accuracies, marker='o', label='Train Set')\n",
    "plt.plot([str(size) for size in hidden_layer_sizes], test_accuracies, marker='o', label='Test Set')\n",
    "plt.xlabel('Hidden Layer Sizes')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('Hidden Layer Sizes vs Mean Accuracy for MLP Model')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_sizes = [(i,) for i in range(1, 11, 1)]\n",
    "\n",
    "train_mean_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for size in hidden_layer_sizes:\n",
    "    model = MLPClassifier(hidden_layer_sizes=size, random_state=42)\n",
    "    \n",
    "    # Perform 5-fold cross-validation on the training set\n",
    "    train_accuracies = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Record the mean accuracy across folds on the training set\n",
    "    train_mean_accuracies.append(np.mean(train_accuracies))\n",
    "    \n",
    "    # Fit the model on the full training set and evaluate on the test set\n",
    "    model.fit(X_train, y_train)\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plotting the graph\n",
    "plt.plot([str(size) for size in hidden_layer_sizes], train_mean_accuracies, marker='o', label='Train Set')\n",
    "plt.plot([str(size) for size in hidden_layer_sizes], test_accuracies, marker='o', label='Test Set')\n",
    "plt.xlabel('Hidden Layer Sizes')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('Hidden Layer Sizes vs Mean Accuracy for MLP Model')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch size vs. model accuracies \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Train MLP models with different batch sizes\n",
    "for batch_size in batch_sizes:\n",
    "    model = MLPClassifier(batch_size=batch_size, random_state=42)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate accuracy on the training set\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    # Evaluate accuracy on the test set\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plotting the graph\n",
    "plt.plot(batch_sizes, train_accuracies, marker='o', label='Train Set')\n",
    "plt.plot(batch_sizes, test_accuracies, marker='o', label='Test Set')\n",
    "plt.xlabel('Batch Sizes')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Batch Sizes vs Accuracy for MLP Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [i for i in range(10, 110, 10)]\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Train MLP models with different batch sizes\n",
    "for batch_size in batch_sizes:\n",
    "    model = MLPClassifier(batch_size=batch_size, random_state=42)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate accuracy on the training set\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    # Evaluate accuracy on the test set\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plotting the graph\n",
    "plt.plot(batch_sizes, train_accuracies, marker='o', label='Train Set')\n",
    "plt.plot(batch_sizes, test_accuracies, marker='o', label='Test Set')\n",
    "plt.xlabel('Batch Sizes')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Batch Sizes vs Accuracy for MLP Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_iter vs. model accuracies (higher iterations) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = [100,200,300,400,500,600,700,800,900,1000]\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Train MLP models with different max_iter values\n",
    "for max_iter in max_iters:\n",
    "    model = MLPClassifier(max_iter=max_iter, random_state=42)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate accuracy on the training set\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    # Evaluate accuracy on the test set\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plotting the graph\n",
    "plt.plot(max_iters, train_accuracies, marker='o', label='Train Set')\n",
    "plt.plot(max_iters, test_accuracies, marker='o', label='Test Set')\n",
    "plt.xlabel('Max Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Max Iterations vs Accuracy for MLP Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max iter against model accuracies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = [i for i in range(10, 110, 10)]\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Train MLP models with different max_iter values\n",
    "for max_iter in max_iters:\n",
    "    model = MLPClassifier(max_iter=max_iter, random_state=42)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate accuracy on the training set\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    # Evaluate accuracy on the test set\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plotting the graph\n",
    "plt.plot(max_iters, train_accuracies, marker='o', label='Train Set')\n",
    "plt.plot(max_iters, test_accuracies, marker='o', label='Test Set')\n",
    "plt.xlabel('Max Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Max Iterations vs Accuracy for MLP Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alpha (regularisation) vs. models accuracies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.001, 0.01, 0.1]\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    mlp, X_train, y_train, param_name=\"alpha\", param_range=alphas, cv=5\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(alphas, np.mean(train_scores, axis=1), label=\"Train Score\", marker='o')\n",
    "plt.plot(alphas, np.mean(test_scores, axis=1), label=\"Test Score\", marker='o')\n",
    "plt.xscale('log')  # Use this line if you still want the x-axis to be log-scaled\n",
    "plt.title(\"Validation Curve for MLPClassifier\")\n",
    "plt.xlabel(\"Alpha (Regularization Term)\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning using GridSearchCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st iteration - lower layer sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'hidden_layer_sizes' : [(1,),(4,),(7,),(10,)], # lower layer sizes prevents overfitting as compared to higher sizes\n",
    "              'activation' : ['identity','logistic','tanh','relu'],\n",
    "              'solver' : ['lbfgs','adam','sgd'],\n",
    "              'max_iter':[30,40,50]} # try a lower set of iterations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "grid = GridSearchCV(estimator=mlp, param_grid=param_grid, scoring='accuracy',verbose = 3,refit=True).fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "formatted_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "print(\"Elapsed Time: {}\".format(formatted_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = MLPClassifier(activation = 'logistic',\n",
    "                     hidden_layer_sizes=(7,),\n",
    "                     max_iter=50,\n",
    "                     solver='lbfgs',\n",
    "                    random_state=42).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores_classification(mlp2)\n",
    "\n",
    "# created mlp2 - the scores are not too overfitted\n",
    "# the score improved, but can stil be improved "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd iteration - higher layer sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'hidden_layer_sizes' : [(10,),(40,),(70,),(100,)], # lower layer sizes prevents overfitting as compared to higher sizes\n",
    "              'activation' : ['identity','logistic','tanh','relu'],\n",
    "              'solver' : ['lbfgs','adam','sgd'],\n",
    "              'max_iter':[30,40,50]} # try a lower set of iterations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "grid = GridSearchCV(estimator=mlp, param_grid=param_grid, scoring='accuracy',verbose = 3,refit=True).fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "formatted_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "print(\"Elapsed Time: {}\".format(formatted_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp3= MLPClassifier(activation = 'relu',\n",
    "                     hidden_layer_sizes=(10,),\n",
    "                     max_iter=50,\n",
    "                     solver='adam',\n",
    "                    random_state=42).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores_classification(mlp3)\n",
    "\n",
    "# scores went lower, and it is more overfit now \n",
    "# issue of overfitting does not exactly relate to layer sizes and iterations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd iteration - higher max_iter, and higher layer sizes \n",
    "- deviating from our previous approach : we use more iterations and higher layer sizes to let the model learn better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'hidden_layer_sizes' : [(100,),(200,),(300,)], \n",
    "              'activation' : ['identity','logistic','tanh','relu'],\n",
    "              'solver' : ['lbfgs','adam','sgd'],\n",
    "              'max_iter':[100,300,500]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# grid = GridSearchCV(estimator=mlp, param_grid=param_grid, scoring='accuracy',verbose = 3,refit=True).fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "formatted_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "print(\"Elapsed Time: {}\".format(formatted_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp4 = MLPClassifier(activation = 'tanh',\n",
    "                     hidden_layer_sizes = (100,),\n",
    "                     max_iter = 500,\n",
    "                     solver='lbfgs',\n",
    "                     random_state=42).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores_classification(mlp4)\n",
    "\n",
    "# model is not overfitted, train and test scores are close\n",
    "# find ways to increase the score? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4th iteration - add regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp5 = MLPClassifier(activation = 'tanh',\n",
    "                     hidden_layer_sizes = (100,),\n",
    "                     max_iter = 10000000,\n",
    "                     solver='lbfgs',\n",
    "                     random_state=42).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores_classification(mlp5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(activation ='logistic', \n",
    "                    hidden_layer_sizes=(10,), \n",
    "                    max_iter= 2000, \n",
    "                    solver = 'sgd', \n",
    "                    random_state=2)\n",
    "# Fit the model to the training set\n",
    "mlp.fit(X_train,y_train)\n",
    "\n",
    "model_scores_classification(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Airbnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load and Sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Build the Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluate and Improve the Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
