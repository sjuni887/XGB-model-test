{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required packages\n",
    "\n",
    "# tabular data\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tabulate import tabulate\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# metrics \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# classification models \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# model opitmization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# time - test\n",
    "import time\n",
    "\n",
    "# math \n",
    "from math import sqrt\n",
    "\n",
    "# statistical models \n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. HR Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load and Sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hr = pd.read_csv('./hr_csv_transformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9092 entries, 0 to 9091\n",
      "Data columns (total 24 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   region                        9092 non-null   int64  \n",
      " 1   education                     9092 non-null   int64  \n",
      " 2   no_of_trainings               9092 non-null   float64\n",
      " 3   age                           9092 non-null   float64\n",
      " 4   previous_year_rating          9092 non-null   float64\n",
      " 5   length_of_service             9092 non-null   float64\n",
      " 6   KPIs_met >80%                 9092 non-null   int64  \n",
      " 7   awards_won?                   9092 non-null   int64  \n",
      " 8   avg_training_score            9092 non-null   float64\n",
      " 9   is_promoted                   9092 non-null   int64  \n",
      " 10  department_Sales & Marketing  9092 non-null   int64  \n",
      " 11  department_Operations         9092 non-null   int64  \n",
      " 12  department_Technology         9092 non-null   int64  \n",
      " 13  department_Analytics          9092 non-null   int64  \n",
      " 14  department_R&D                9092 non-null   int64  \n",
      " 15  department_Procurement        9092 non-null   int64  \n",
      " 16  department_Finance            9092 non-null   int64  \n",
      " 17  department_HR                 9092 non-null   int64  \n",
      " 18  department_Legal              9092 non-null   int64  \n",
      " 19  gender_f                      9092 non-null   int64  \n",
      " 20  gender_m                      9092 non-null   int64  \n",
      " 21  recruitment_channel_sourcing  9092 non-null   int64  \n",
      " 22  recruitment_channel_other     9092 non-null   int64  \n",
      " 23  recruitment_channel_referred  9092 non-null   int64  \n",
      "dtypes: float64(5), int64(19)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_hr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "      <th>...</th>\n",
       "      <th>department_R&amp;D</th>\n",
       "      <th>department_Procurement</th>\n",
       "      <th>department_Finance</th>\n",
       "      <th>department_HR</th>\n",
       "      <th>department_Legal</th>\n",
       "      <th>gender_f</th>\n",
       "      <th>gender_m</th>\n",
       "      <th>recruitment_channel_sourcing</th>\n",
       "      <th>recruitment_channel_other</th>\n",
       "      <th>recruitment_channel_referred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6108</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.103865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.503161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>785</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.677333</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.225465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.321705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.864038</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6108</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.436134</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.864038</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732668</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.740418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   region  education  no_of_trainings       age  previous_year_rating  \\\n",
       "0    6108          1              2.0 -0.103865                   0.0   \n",
       "1     785          1              1.0 -0.677333                  -2.0   \n",
       "2    1234          2              0.0 -0.321705                   1.0   \n",
       "3    6108          1              0.0 -0.436134                   1.0   \n",
       "4    1701          2              0.0  0.732668                  -2.0   \n",
       "\n",
       "   length_of_service  KPIs_met >80%  awards_won?  avg_training_score  \\\n",
       "0          -0.503161              0            0               -0.12   \n",
       "1          -0.225465              0            0                1.04   \n",
       "2          -0.864038              1            0               -0.44   \n",
       "3          -0.864038              0            0               -0.08   \n",
       "4           0.740418              0            0               -0.20   \n",
       "\n",
       "   is_promoted  ...  department_R&D  department_Procurement  \\\n",
       "0            0  ...               0                       0   \n",
       "1            0  ...               0                       0   \n",
       "2            0  ...               0                       0   \n",
       "3            0  ...               0                       0   \n",
       "4            0  ...               0                       0   \n",
       "\n",
       "   department_Finance  department_HR  department_Legal  gender_f  gender_m  \\\n",
       "0                   0              0                 0         0         1   \n",
       "1                   0              0                 0         0         1   \n",
       "2                   0              0                 0         0         1   \n",
       "3                   1              0                 0         0         1   \n",
       "4                   0              0                 0         1         0   \n",
       "\n",
       "   recruitment_channel_sourcing  recruitment_channel_other  \\\n",
       "0                             0                          1   \n",
       "1                             0                          1   \n",
       "2                             0                          1   \n",
       "3                             1                          0   \n",
       "4                             1                          0   \n",
       "\n",
       "   recruitment_channel_referred  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             0  \n",
       "4                             0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "      <th>...</th>\n",
       "      <th>department_R&amp;D</th>\n",
       "      <th>department_Procurement</th>\n",
       "      <th>department_Finance</th>\n",
       "      <th>department_HR</th>\n",
       "      <th>department_Legal</th>\n",
       "      <th>gender_f</th>\n",
       "      <th>gender_m</th>\n",
       "      <th>recruitment_channel_sourcing</th>\n",
       "      <th>recruitment_channel_other</th>\n",
       "      <th>recruitment_channel_referred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4584.995381</td>\n",
       "      <td>1.290805</td>\n",
       "      <td>0.231522</td>\n",
       "      <td>0.107887</td>\n",
       "      <td>0.583150</td>\n",
       "      <td>-0.043580</td>\n",
       "      <td>0.512868</td>\n",
       "      <td>0.064452</td>\n",
       "      <td>0.283836</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015178</td>\n",
       "      <td>0.140013</td>\n",
       "      <td>0.044435</td>\n",
       "      <td>0.036846</td>\n",
       "      <td>0.017268</td>\n",
       "      <td>0.315662</td>\n",
       "      <td>0.684338</td>\n",
       "      <td>0.429059</td>\n",
       "      <td>0.545535</td>\n",
       "      <td>0.025407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4079.802512</td>\n",
       "      <td>0.483942</td>\n",
       "      <td>0.559087</td>\n",
       "      <td>0.671022</td>\n",
       "      <td>1.182599</td>\n",
       "      <td>0.699312</td>\n",
       "      <td>0.499862</td>\n",
       "      <td>0.245570</td>\n",
       "      <td>0.579979</td>\n",
       "      <td>0.500027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122268</td>\n",
       "      <td>0.347020</td>\n",
       "      <td>0.206070</td>\n",
       "      <td>0.188393</td>\n",
       "      <td>0.130275</td>\n",
       "      <td>0.464805</td>\n",
       "      <td>0.464805</td>\n",
       "      <td>0.494969</td>\n",
       "      <td>0.497950</td>\n",
       "      <td>0.157366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.690290</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-1.378193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1234.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.436134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.503161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2617.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6108.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.476189</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.496839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11497.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.017907</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.115994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             region    education  no_of_trainings          age  \\\n",
       "count   9092.000000  9092.000000      9092.000000  9092.000000   \n",
       "mean    4584.995381     1.290805         0.231522     0.107887   \n",
       "std     4079.802512     0.483942         0.559087     0.671022   \n",
       "min       31.000000     0.000000         0.000000    -1.690290   \n",
       "25%     1234.000000     1.000000         0.000000    -0.436134   \n",
       "50%     2617.000000     1.000000         0.000000     0.000000   \n",
       "75%     6108.000000     2.000000         0.000000     0.476189   \n",
       "max    11497.000000     2.000000         7.000000     2.017907   \n",
       "\n",
       "       previous_year_rating  length_of_service  KPIs_met >80%  awards_won?  \\\n",
       "count           9092.000000        9092.000000    9092.000000  9092.000000   \n",
       "mean               0.583150          -0.043580       0.512868     0.064452   \n",
       "std                1.182599           0.699312       0.499862     0.245570   \n",
       "min               -2.000000          -1.378193       0.000000     0.000000   \n",
       "25%                0.000000          -0.503161       0.000000     0.000000   \n",
       "50%                0.000000           0.000000       1.000000     0.000000   \n",
       "75%                2.000000           0.496839       1.000000     0.000000   \n",
       "max                2.000000           2.115994       1.000000     1.000000   \n",
       "\n",
       "       avg_training_score  is_promoted  ...  department_R&D  \\\n",
       "count         9092.000000  9092.000000  ...     9092.000000   \n",
       "mean             0.283836     0.500000  ...        0.015178   \n",
       "std              0.579979     0.500027  ...        0.122268   \n",
       "min             -0.760000     0.000000  ...        0.000000   \n",
       "25%             -0.240000     0.000000  ...        0.000000   \n",
       "50%              0.160000     0.500000  ...        0.000000   \n",
       "75%              0.810000     1.000000  ...        0.000000   \n",
       "max              1.560000     1.000000  ...        1.000000   \n",
       "\n",
       "       department_Procurement  department_Finance  department_HR  \\\n",
       "count             9092.000000         9092.000000    9092.000000   \n",
       "mean                 0.140013            0.044435       0.036846   \n",
       "std                  0.347020            0.206070       0.188393   \n",
       "min                  0.000000            0.000000       0.000000   \n",
       "25%                  0.000000            0.000000       0.000000   \n",
       "50%                  0.000000            0.000000       0.000000   \n",
       "75%                  0.000000            0.000000       0.000000   \n",
       "max                  1.000000            1.000000       1.000000   \n",
       "\n",
       "       department_Legal     gender_f     gender_m  \\\n",
       "count       9092.000000  9092.000000  9092.000000   \n",
       "mean           0.017268     0.315662     0.684338   \n",
       "std            0.130275     0.464805     0.464805   \n",
       "min            0.000000     0.000000     0.000000   \n",
       "25%            0.000000     0.000000     0.000000   \n",
       "50%            0.000000     0.000000     1.000000   \n",
       "75%            0.000000     1.000000     1.000000   \n",
       "max            1.000000     1.000000     1.000000   \n",
       "\n",
       "       recruitment_channel_sourcing  recruitment_channel_other  \\\n",
       "count                   9092.000000                9092.000000   \n",
       "mean                       0.429059                   0.545535   \n",
       "std                        0.494969                   0.497950   \n",
       "min                        0.000000                   0.000000   \n",
       "25%                        0.000000                   0.000000   \n",
       "50%                        0.000000                   1.000000   \n",
       "75%                        1.000000                   1.000000   \n",
       "max                        1.000000                   1.000000   \n",
       "\n",
       "       recruitment_channel_referred  \n",
       "count                   9092.000000  \n",
       "mean                       0.025407  \n",
       "std                        0.157366  \n",
       "min                        0.000000  \n",
       "25%                        0.000000  \n",
       "50%                        0.000000  \n",
       "75%                        0.000000  \n",
       "max                        1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region                          0\n",
       "education                       0\n",
       "no_of_trainings                 0\n",
       "age                             0\n",
       "previous_year_rating            0\n",
       "length_of_service               0\n",
       "KPIs_met >80%                   0\n",
       "awards_won?                     0\n",
       "avg_training_score              0\n",
       "is_promoted                     0\n",
       "department_Sales & Marketing    0\n",
       "department_Operations           0\n",
       "department_Technology           0\n",
       "department_Analytics            0\n",
       "department_R&D                  0\n",
       "department_Procurement          0\n",
       "department_Finance              0\n",
       "department_HR                   0\n",
       "department_Legal                0\n",
       "gender_f                        0\n",
       "gender_m                        0\n",
       "recruitment_channel_sourcing    0\n",
       "recruitment_channel_other       0\n",
       "recruitment_channel_referred    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hr.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4546\n",
       "1    4546\n",
       "Name: is_promoted, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the target class distribution \n",
    "df_hr['is_promoted'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Train and Test splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_hr.drop(['is_promoted'], axis =1)\n",
    "y = df_hr['is_promoted']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Feature Importances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.429350\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "# using logit - for classification \n",
    "lgsm = sm.Logit(y_train, X_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>is_promoted</td>   <th>  No. Observations:  </th>  <td>  6364</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  6343</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    20</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 30 Jan 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.3806</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>23:26:36</td>     <th>  Log-Likelihood:    </th> <td> -2732.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -4411.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                  <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region</th>                       <td> 6.851e-06</td> <td> 8.88e-06</td> <td>    0.772</td> <td> 0.440</td> <td>-1.06e-05</td> <td> 2.43e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education</th>                    <td>    0.1445</td> <td>    0.079</td> <td>    1.818</td> <td> 0.069</td> <td>   -0.011</td> <td>    0.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_of_trainings</th>              <td>   -0.0403</td> <td>    0.062</td> <td>   -0.655</td> <td> 0.513</td> <td>   -0.161</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                          <td>   -0.3805</td> <td>    0.073</td> <td>   -5.199</td> <td> 0.000</td> <td>   -0.524</td> <td>   -0.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_year_rating</th>         <td>    0.2490</td> <td>    0.031</td> <td>    8.137</td> <td> 0.000</td> <td>    0.189</td> <td>    0.309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>length_of_service</th>            <td>    0.1946</td> <td>    0.063</td> <td>    3.086</td> <td> 0.002</td> <td>    0.071</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>KPIs_met >80%</th>                <td>    2.6255</td> <td>    0.084</td> <td>   31.276</td> <td> 0.000</td> <td>    2.461</td> <td>    2.790</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>awards_won?</th>                  <td>    1.9333</td> <td>    0.210</td> <td>    9.198</td> <td> 0.000</td> <td>    1.521</td> <td>    2.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_training_score</th>           <td>    7.2899</td> <td>    0.233</td> <td>   31.287</td> <td> 0.000</td> <td>    6.833</td> <td>    7.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Sales & Marketing</th> <td>    4.2095</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Operations</th>        <td>    1.3355</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Technology</th>        <td>   -3.8352</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Analytics</th>         <td>   -5.3134</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_R&D</th>               <td>   -5.6380</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Procurement</th>       <td>   -1.3390</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Finance</th>           <td>    1.3003</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_HR</th>                <td>    3.7919</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Legal</th>             <td>    1.0080</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender_f</th>                     <td>   -2.2522</td> <td>  1.2e+06</td> <td>-1.87e-06</td> <td> 1.000</td> <td>-2.36e+06</td> <td> 2.36e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender_m</th>                     <td>   -2.2282</td> <td>  1.2e+06</td> <td>-1.85e-06</td> <td> 1.000</td> <td>-2.36e+06</td> <td> 2.36e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recruitment_channel_sourcing</th> <td>   -1.5920</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recruitment_channel_other</th>    <td>   -1.4742</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recruitment_channel_referred</th> <td>   -1.4141</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            is_promoted   No. Observations:                 6364\n",
       "Model:                          Logit   Df Residuals:                     6343\n",
       "Method:                           MLE   Df Model:                           20\n",
       "Date:                Tue, 30 Jan 2024   Pseudo R-squ.:                  0.3806\n",
       "Time:                        23:26:36   Log-Likelihood:                -2732.4\n",
       "converged:                       True   LL-Null:                       -4411.0\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "================================================================================================\n",
       "                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------\n",
       "region                        6.851e-06   8.88e-06      0.772      0.440   -1.06e-05    2.43e-05\n",
       "education                        0.1445      0.079      1.818      0.069      -0.011       0.300\n",
       "no_of_trainings                 -0.0403      0.062     -0.655      0.513      -0.161       0.080\n",
       "age                             -0.3805      0.073     -5.199      0.000      -0.524      -0.237\n",
       "previous_year_rating             0.2490      0.031      8.137      0.000       0.189       0.309\n",
       "length_of_service                0.1946      0.063      3.086      0.002       0.071       0.318\n",
       "KPIs_met >80%                    2.6255      0.084     31.276      0.000       2.461       2.790\n",
       "awards_won?                      1.9333      0.210      9.198      0.000       1.521       2.345\n",
       "avg_training_score               7.2899      0.233     31.287      0.000       6.833       7.747\n",
       "department_Sales & Marketing     4.2095        nan        nan        nan         nan         nan\n",
       "department_Operations            1.3355        nan        nan        nan         nan         nan\n",
       "department_Technology           -3.8352        nan        nan        nan         nan         nan\n",
       "department_Analytics            -5.3134        nan        nan        nan         nan         nan\n",
       "department_R&D                  -5.6380        nan        nan        nan         nan         nan\n",
       "department_Procurement          -1.3390        nan        nan        nan         nan         nan\n",
       "department_Finance               1.3003        nan        nan        nan         nan         nan\n",
       "department_HR                    3.7919        nan        nan        nan         nan         nan\n",
       "department_Legal                 1.0080        nan        nan        nan         nan         nan\n",
       "gender_f                        -2.2522    1.2e+06  -1.87e-06      1.000   -2.36e+06    2.36e+06\n",
       "gender_m                        -2.2282    1.2e+06  -1.85e-06      1.000   -2.36e+06    2.36e+06\n",
       "recruitment_channel_sourcing    -1.5920        nan        nan        nan         nan         nan\n",
       "recruitment_channel_other       -1.4742        nan        nan        nan         nan         nan\n",
       "recruitment_channel_referred    -1.4141        nan        nan        nan         nan         nan\n",
       "================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgsm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Build the Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "model_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# no hyperparams except random state for consistency in results \n",
    "lg = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "models.append(lg)\n",
    "model_names.append(\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier \n",
    "dtree = DecisionTreeClassifier(random_state=42).fit(X_train,y_train)\n",
    "\n",
    "models.append(dtree)\n",
    "model_names.append(\"Decision Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest classifier \n",
    "rf = RandomForestClassifier(random_state=42).fit(X_train,y_train)\n",
    "\n",
    "models.append(rf)\n",
    "model_names.append(\"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector machine \n",
    "svc = SVC(random_state = 42).fit(X_train,y_train)\n",
    "\n",
    "models.append(svc)\n",
    "model_names.append(\"SVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi layer perceptron\n",
    "mlp = MLPClassifier(random_state = 42).fit(X_train, y_train)\n",
    "\n",
    "models.append(mlp)\n",
    "model_names.append(\"Multi Layer Perceptron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive boosting\n",
    "ada = AdaBoostClassifier(random_state = 42).fit(X_train,y_train)\n",
    "\n",
    "models.append(ada)\n",
    "model_names.append(\"ADA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extreme gradient boosting \n",
    "xgb = XGBClassifier(random_state = 42).fit(X_train, y_train)\n",
    "\n",
    "models.append(xgb)\n",
    "model_names.append(\"XGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Consolidated View of Model Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.728787</td>\n",
       "      <td>0.720674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.749267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.793622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.533941</td>\n",
       "      <td>0.537023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multi Layer Perceptron</td>\n",
       "      <td>0.663891</td>\n",
       "      <td>0.668622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADA</td>\n",
       "      <td>0.782055</td>\n",
       "      <td>0.769428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.933532</td>\n",
       "      <td>0.799487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Train Score  Test Score\n",
       "0     Logistic Regression     0.728787    0.720674\n",
       "1           Decision Tree     1.000000    0.749267\n",
       "2           Random Forest     1.000000    0.793622\n",
       "3                     SVC     0.533941    0.537023\n",
       "4  Multi Layer Perceptron     0.663891    0.668622\n",
       "5                     ADA     0.782055    0.769428\n",
       "6                     XGB     0.933532    0.799487"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_table = []\n",
    "for model, name in zip(models, model_names):\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    scores_table.append([name, train_score, test_score])\n",
    "\n",
    "df_scores = pd.DataFrame(scores_table, columns=[\"Model\", \"Train Score\", \"Test Score\"])\n",
    "\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Evaluate and Improve the Model(s)\n",
    "These models will be chosen for further evaluation and tuning  : <mark>Random Forest Classifier</mark>, <mark>Multi Layer Perceptron (Artificial Neural Network)</mark>,<mark>ADA Boost (Ensemble Model)</mark>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_scores_classification(model):\n",
    "    print(f\"Model: {model}\")\n",
    "    \n",
    "    train_pred = model.predict(X_train)\n",
    "    print(f'\\nTraining score: {model.score(X_train, y_train)}')\n",
    "\n",
    "    test_pred = model.predict(X_test)\n",
    "    print(f'Testing score: {model.score(X_test, y_test)}')\n",
    "    \n",
    "    # Training scores and report\n",
    "    train_pred = model.predict(X_train)\n",
    "    print('\\nTraining report:')\n",
    "    print(classification_report(y_train, train_pred))\n",
    "\n",
    "    # Testing scores and report\n",
    "    test_pred = model.predict(X_test)\n",
    "    print('\\nTesting report:')\n",
    "    print(classification_report(y_test, test_pred))\n",
    "\n",
    "    # Confusion matrix for training\n",
    "    print('\\nConfusion Matrix:')\n",
    "    train_cm = confusion_matrix(y_train, train_pred)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(train_cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix - Training')\n",
    "\n",
    "    # Confusion matrix for testing\n",
    "    plt.subplot(1, 2, 2)\n",
    "    test_cm = confusion_matrix(y_test, test_pred)\n",
    "    sns.heatmap(test_cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix - Testing')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Model 1 (random forest classifier) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores_classification(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### comments \n",
    "- the model scores are very overfitted which need to be tuned\n",
    "- high variance and low bias, the model is performing well on training set but not as good on training set, meaning it is putting in close attention to the train set\n",
    "- it is this way due to the 'nature' of random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1.1 Hyperparameter Inspection\n",
    "##### hyperparams to be tweaked or that can be tweaked \n",
    "- <mark>n_estimators</mark> : number of trees\n",
    "- <mark>criterion</mark> : quality of split\n",
    "- <mark>max_depth</mark> : depth of tree, if there are too many details it might lead to overfitting? affected by:min_samples_split samples\n",
    "- <mark>min_samples_split</mark> : number of samples required to split an internal node \n",
    "- <mark>min_samples_leaf</mark> : number of samples required to become a leaf? makes model more generalised (add later on?) \n",
    "- <mark>max_features</mark> : number of features to consider for a best split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1.1 (a)  n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### n_estimators vs. train and test scores  (range : 100-1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_values = np.arange(100,1100,100)\n",
    "\n",
    "# Initialize lists to store training and test scores\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# Iterate over different n_estimators values\n",
    "for n_estimators in n_estimators_values:\n",
    "    # Create and fit the Random Forest Classifier\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on training and testing sets\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy scores and store them\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    train_scores.append(train_accuracy)\n",
    "    test_scores.append(test_accuracy)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_estimators_values, train_scores, label='Train Accuracy', marker='o')\n",
    "plt.plot(n_estimators_values, test_scores, label='Test Accuracy', marker='o')\n",
    "plt.title('Random Forest Classifier: Training and Test Scores vs. n_estimators')\n",
    "plt.xlabel('Number of Estimators (n_estimators)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1.1 (b) max_depth "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### max depth vs accuracy (range: 2-20), we start lower "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = np.arange(2, 21,1)\n",
    "\n",
    "# Initialize lists to store training and testing accuracies\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Loop through different max_depth values\n",
    "for max_depth in max_depths:\n",
    "    # Create and train the Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(max_depth=max_depth, random_state=42)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the training and testing sets\n",
    "    y_train_pred = rf_classifier.predict(X_train)\n",
    "    y_test_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Append accuracies to the lists\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(max_depths, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(max_depths, test_accuracies, label='Testing Accuracy')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Max Depth vs Accuracy for Random Forest Classifier')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = np.arange(10, 100,10)\n",
    "\n",
    "# Initialize lists to store training and testing accuracies\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Loop through different max_depth values\n",
    "for max_depth in max_depths:\n",
    "    # Create and train the Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(max_depth=max_depth, random_state=42)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the training and testing sets\n",
    "    y_train_pred = rf_classifier.predict(X_train)\n",
    "    y_test_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Append accuracies to the lists\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(max_depths, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(max_depths, test_accuracies, label='Testing Accuracy')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Max Depth vs Accuracy for Random Forest Classifier')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1.1 (c) min_samples_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### min samples vs accuracy (range: 2-100), start from default "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_splits = np.arange(2, 100, 1)\n",
    "\n",
    "# Initialize lists to store training and testing accuracies\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Loop through different min_samples_split values\n",
    "for min_samples_split in min_samples_splits:\n",
    "    # Create and train the Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(min_samples_split=min_samples_split, random_state=42)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the training and testing sets\n",
    "    y_train_pred = rf_classifier.predict(X_train)\n",
    "    y_test_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Append accuracies to the lists\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(min_samples_splits, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(min_samples_splits, test_accuracies, label='Testing Accuracy')\n",
    "plt.xlabel('Min Samples Split')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Min Samples Split vs Accuracy for Random Forest Classifier')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# overfitting gets reduced, but test scores typically dont increase\n",
    "# reduced overfitting but it compromises train scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### min samples vs accuracy (range: 100-1000), see higher to see effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_splits = np.arange(100, 1100, 100)\n",
    "\n",
    "# Initialize lists to store training and testing accuracies\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Loop through different min_samples_split values\n",
    "for min_samples_split in min_samples_splits:\n",
    "    # Create and train the Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(min_samples_split=min_samples_split, random_state=42)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the training and testing sets\n",
    "    y_train_pred = rf_classifier.predict(X_train)\n",
    "    y_test_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Append accuracies to the lists\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(min_samples_splits, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(min_samples_splits, test_accuracies, label='Testing Accuracy')\n",
    "plt.xlabel('Min Samples Split')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Min Samples Split vs Accuracy for Random Forest Classifier')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# too many samples makes the model become worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1.1 (d) min_samples_leaf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### min samples leaf vs accuracy (range: 2-20), start from default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leafs = np.arange(1, 21, 1)\n",
    "\n",
    "# Initialize lists to store training and testing accuracies\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Loop through different min_samples_leaf values\n",
    "for min_samples_leaf in min_samples_leafs:\n",
    "    # Create and train the Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(min_samples_leaf=min_samples_leaf, random_state=42)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the training and testing sets\n",
    "    y_train_pred = rf_classifier.predict(X_train)\n",
    "    y_test_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Append accuracies to the lists\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(min_samples_leafs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(min_samples_leafs, test_accuracies, label='Testing Accuracy')\n",
    "plt.xlabel('Min Samples Leaf')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Min Samples Leaf vs Accuracy for Random Forest Classifier')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# doing so reduces overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1.2 Optimizing Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1.2 (a) GridSearchCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1st Iteration  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators' : [40,50,60,70], # this is where the model tends to be at its best, and at lower number of trees \n",
    "              'criterion' : ['gini','entropy'],\n",
    "              'max_depth' : [10,20,30],\n",
    "              'min_samples_split':[60,80,100],\n",
    "              'min_samples_leaf':[10,15,20]}# where the model tends to be the best at lower depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "grid = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy',verbose = 3,refit=True).fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "formatted_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "print(\"Elapsed Time: {}\".format(formatted_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(criterion='entropy',max_depth=30,min_samples_leaf=10\n",
    "                             ,min_samples_split=60,n_estimators=70,random_state=42).fit(X_train,y_train)\n",
    "\n",
    "model_scores_classification(rf2)\n",
    "\n",
    "# reduced overfitting, but the test scores went lower "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2nd iteration - set it at a higher range for all params to try to increase accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators' : [100,200,300], \n",
    "              'criterion' : ['gini','entropy'],\n",
    "              'max_depth' : [30,50,70],\n",
    "              'min_samples_split':[100,200,300],\n",
    "              'min_samples_leaf':[30,50,70]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "grid = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy',verbose = 3,refit=True).fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "formatted_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "print(\"Elapsed Time: {}\".format(formatted_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier(criterion='entropy', max_depth=30, min_samples_leaf=30,\n",
      "                       min_samples_split=100, random_state=42)\n",
      "\n",
      "Training score: 0.7987115021998743\n",
      "Testing score: 0.782624633431085\n",
      "\n",
      "Training report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.67      0.77      3157\n",
      "           1       0.74      0.92      0.82      3207\n",
      "\n",
      "    accuracy                           0.80      6364\n",
      "   macro avg       0.82      0.80      0.80      6364\n",
      "weighted avg       0.82      0.80      0.80      6364\n",
      "\n",
      "\n",
      "Testing report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.65      0.75      1389\n",
      "           1       0.72      0.92      0.81      1339\n",
      "\n",
      "    accuracy                           0.78      2728\n",
      "   macro avg       0.80      0.79      0.78      2728\n",
      "weighted avg       0.81      0.78      0.78      2728\n",
      "\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf3 = RandomForestClassifier(criterion='entropy',max_depth=30,min_samples_leaf=30\n",
    "                             ,min_samples_split=100,n_estimators=100,random_state=42).fit(X_train,y_train)\n",
    "\n",
    "model_scores_classification(rf3)\n",
    "\n",
    "# overfitting is reduced but accuracies slightly decrease\n",
    "# lower params are better accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3rd iteration - added class weights to 1st iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators' : [40,50,60,70], # this is where the model tends to be at its best, and at lower number of trees \n",
    "              'criterion' : ['gini','entropy'],\n",
    "              'max_depth' : [10,20,30],\n",
    "              'min_samples_split':[60,80,100],\n",
    "              'min_samples_leaf':[10,15,20],\n",
    "              'class_Weights' : ['balanced','balanced_subsample']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "formatted_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "print(\"Elapsed Time: {}\".format(formatted_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Model 2 (MLP) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores_classification(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2.1 Hyperparameter Inspection \n",
    "##### hyperparams to be tweaked or that can be tweaked \n",
    "- <mark>hidden_layer_sizes</mark> : number of neurons in the hidden layer \n",
    "- <mark>activation</mark> : activation or squashing function for the hidden layer \n",
    "- <mark>solver</mark> : solver for weight optimization \n",
    "- <mark>max_iter</mark> : maximum number of iterations \n",
    "- <mark>alpha</mark> : regularisation term "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2.1 (a) hidden_layer_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### hidden layer sizes (brain size) against train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes = [(i,) for i in range(100, 610, 100)]\n",
    "\n",
    "train_mean_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for size in hidden_layer_sizes:\n",
    "    model = MLPClassifier(hidden_layer_sizes=size, random_state=42)\n",
    "    \n",
    "    # Perform 5-fold cross-validation on the training set\n",
    "    train_accuracies = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Record the mean accuracy across folds on the training set\n",
    "    train_mean_accuracies.append(np.mean(train_accuracies))\n",
    "    \n",
    "    # Fit the model on the full training set and evaluate on the test set\n",
    "    model.fit(X_train, y_train)\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plotting the graph\n",
    "plt.plot([str(size) for size in hidden_layer_sizes], train_mean_accuracies, marker='o', label='Train Set')\n",
    "plt.plot([str(size) for size in hidden_layer_sizes], test_accuracies, marker='o', label='Test Set')\n",
    "plt.xlabel('Hidden Layer Sizes')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('Hidden Layer Sizes vs Mean Accuracy for MLP Model')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes = [(i,) for i in range(10, 110, 10)]\n",
    "\n",
    "train_mean_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for size in hidden_layer_sizes:\n",
    "    model = MLPClassifier(hidden_layer_sizes=size, random_state=42)\n",
    "    \n",
    "    # Perform 5-fold cross-validation on the training set\n",
    "    train_accuracies = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Record the mean accuracy across folds on the training set\n",
    "    train_mean_accuracies.append(np.mean(train_accuracies))\n",
    "    \n",
    "    # Fit the model on the full training set and evaluate on the test set\n",
    "    model.fit(X_train, y_train)\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plotting the graph\n",
    "plt.plot([str(size) for size in hidden_layer_sizes], train_mean_accuracies, marker='o', label='Train Set')\n",
    "plt.plot([str(size) for size in hidden_layer_sizes], test_accuracies, marker='o', label='Test Set')\n",
    "plt.xlabel('Hidden Layer Sizes')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('Hidden Layer Sizes vs Mean Accuracy for MLP Model')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2.1 (b) max_iter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### max_iter against accuracies (range : 100-1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = [i for i in range(10, 110, 10)]\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Train MLP models with different max_iter values\n",
    "for max_iter in max_iters:\n",
    "    model = MLPClassifier(max_iter=max_iter, random_state=42)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate accuracy on the training set\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    # Evaluate accuracy on the test set\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plotting the graph\n",
    "plt.plot(max_iters, train_accuracies, marker='o', label='Train Set')\n",
    "plt.plot(max_iters, test_accuracies, marker='o', label='Test Set')\n",
    "plt.xlabel('Max Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Max Iterations vs Accuracy for MLP Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = [i for i in range(100, 1000, 10)]\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Train MLP models with different max_iter values\n",
    "for max_iter in max_iters:\n",
    "    model = MLPClassifier(max_iter=max_iter, random_state=42)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate accuracy on the training set\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    # Evaluate accuracy on the test set\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plotting the graph\n",
    "plt.plot(max_iters, train_accuracies, marker='o', label='Train Set')\n",
    "plt.plot(max_iters, test_accuracies, marker='o', label='Test Set')\n",
    "plt.xlabel('Max Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Max Iterations vs Accuracy for MLP Model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# scores tend to plateau at a high number of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### max_iter and solvers vs train score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_iters = [i for i in range(10, 110, 10)]\n",
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "# Create a dictionary to store training scores for each solver\n",
    "train_scores = {solver: [] for solver in solvers}\n",
    "\n",
    "# Train MLP models with different max_iter values and solvers\n",
    "for solver in solvers:\n",
    "    for max_iter in max_iters:\n",
    "        model = MLPClassifier(max_iter=max_iter, solver=solver, random_state=42)\n",
    "        \n",
    "        # Train the model on the training set\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate accuracy on the training set\n",
    "        train_accurbacy = model.score(X_train, y_train)\n",
    "        train_scores[solver].append(train_accuracy)\n",
    "\n",
    "# Plotting the graph for different solvers\n",
    "for solver in solvers:\n",
    "    plt.plot(max_iters, train_scores[solver], marker='o', label=f'Train Set ({solver} solver)')\n",
    "\n",
    "plt.xlabel('Max Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Max Iterations vs Training Accuracy for MLP Model (Different Solvers)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# according to documentation, 'lbfgs' solver is better for smaller and lesser complex datasets\n",
    "# warnings show here that the model is not converging, it might need alot more iterations for it to converge as\n",
    "# compared to other solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_iters = [i for i in range(100, 1100, 100)]\n",
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "# Create a dictionary to store training scores for each solver\n",
    "train_scores = {solver: [] for solver in solvers}\n",
    "\n",
    "# Train MLP models with different max_iter values and solvers\n",
    "for solver in solvers:\n",
    "    for max_iter in max_iters:\n",
    "        model = MLPClassifier(max_iter=max_iter, solver=solver, random_state=42)\n",
    "        \n",
    "        # Train the model on the training set\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate accuracy on the training set\n",
    "        train_accurbacy = model.score(X_train, y_train)\n",
    "        train_scores[solver].append(train_accuracy)\n",
    "\n",
    "# Plotting the graph for different solvers\n",
    "for solver in solvers:\n",
    "    plt.plot(max_iters, train_scores[solver], marker='o', label=f'Train Set ({solver} solver)')\n",
    "\n",
    "plt.xlabel('Max Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Max Iterations vs Training Accuracy for MLP Model (Different Solvers)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# according to documentation, 'lbfgs' solver is better for smaller and lesser complex datasets\n",
    "# warnings show here that the model is not converging, it might need alot more iterations for it to converge as\n",
    "# compared to other solvers\n",
    "# sometimes the model does not converge for other solvers as well "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2.2 Optimizing Hyperparameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2.2 (a) GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_models = [mlp]\n",
    "mlp_names = ['base']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1st iteration - low set of max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'hidden_layer_sizes' : [(50,),(100,),(200,)],\n",
    "              'activation' : ['identity','logistic','tanh','relu'],\n",
    "              'solver' : ['adam','sgd'], # we dont use lbfgs as it is a large dataset \n",
    "              'max_iter' : [40,50,60]} # start with a lower set of iterations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "grid = GridSearchCV(estimator=mlp, param_grid=param_grid, scoring='accuracy',verbose = 3,refit=True).fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "formatted_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "print(\"Elapsed Time: {}\".format(formatted_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = MLPClassifier(activation='relu',hidden_layer_sizes=(100,),max_iter = 50,solver='adam',random_state=42).fit(X_train,y_train)\n",
    "\n",
    "model_scores_classification(mlp2)\n",
    "mlp_models.append(mlp2)\n",
    "mlp_names.append('mlp2 - low iterations')\n",
    "\n",
    "\n",
    "# no change in scores, we need to try to increase it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2nd iteration - higher iterations \n",
    "- in the previous search, we used relatively large number neurons with little iterations, which might be why the scores are not as optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'hidden_layer_sizes' : [(50,),(100,),(200,)],\n",
    "              'activation' : ['identity','logistic','tanh','relu'],\n",
    "              'solver' : ['adam','sgd'], # we dont use lbfgs as it is a large dataset \n",
    "              'max_iter' : [100,200,300]} # more iterations for the model to learn? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "grid = GridSearchCV(estimator=mlp, param_grid=param_grid, scoring='accuracy',verbose = 3,refit=True).fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "formatted_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "print(\"Elapsed Time: {}\".format(formatted_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp3 = MLPClassifier(activation='logistic',hidden_layer_sizes=(200,),max_iter = 200\n",
    "                     ,solver='adam',random_state=42).fit(X_train,y_train)\n",
    "\n",
    "model_scores_classification(mlp3)\n",
    "mlp_models.append(mlp3)\n",
    "mlp_names.append('mlp3 - higher iterations')\n",
    "\n",
    "# scores increase with close f1 scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3rd iteration - trying higher layers and higher iterations \n",
    "- for the model to learn better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'hidden_layer_sizes' : [(100,),(200,),(300,),(400,)],\n",
    "              'activation' : ['identity','logistic','tanh','relu'],\n",
    "              'solver' : ['adam','sgd'], # we dont use lbfgs as it is a large dataset \n",
    "              'max_iter' : [500,700,1000]} # more iterations for the model to learn? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "grid = GridSearchCV(estimator=mlp, param_grid=param_grid, scoring='accuracy',verbose = 3,refit=True).fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "formatted_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "print(\"Elapsed Time: {}\".format(formatted_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp4 = MLPClassifier(activation='logistic',hidden_layer_sizes=(300,),max_iter = 500\n",
    "                     ,solver='adam',random_state=42).fit(X_train,y_train)\n",
    "\n",
    "model_scores_classification(mlp4)\n",
    "mlp_models.append(mlp4)\n",
    "mlp_names.append('mlp4 - higher iterations,layers')\n",
    "\n",
    "# train score remained the same \n",
    "# test score decreased\n",
    "# how to improve test score?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4th iteration - add regularisation parameter \n",
    "- to reduce overfitting, we try to implement regularization (alpha) \n",
    "- instead of using gridsearch, we see the effect of regularization for the specific model mlp2 (previously optimized) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-6, 3, 10)\n",
    "\n",
    "# Calculate training and test scores at different alpha values\n",
    "train_scores, test_scores = validation_curve(\n",
    "    mlp4, X_train, y_train, param_name='alpha', param_range=alphas, cv=5, scoring='accuracy'\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(alphas, np.mean(train_scores, axis=1), label='Training score', marker='o')\n",
    "plt.semilogx(alphas, np.mean(test_scores, axis=1), label='Cross-validation score', marker='o')\n",
    "plt.title('Validation Curve for MLPClassifier')\n",
    "plt.xlabel('Regularization Strength (alpha)')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp5 = MLPClassifier(activation='logistic',hidden_layer_sizes=(200,),max_iter = 200\n",
    "                     ,solver='adam',alpha=0.0001,random_state=42).fit(X_train,y_train)\n",
    "\n",
    "model_scores_classification(mlp5)\n",
    "mlp_models.append(mlp5)\n",
    "mlp_names.append('mlp5 - regularisation added')\n",
    "\n",
    "# no change in scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3.3 'optimized' models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_table = []\n",
    "for model, name in zip(mlp_models, mlp_names):\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    scores_table.append([name, train_score, test_score])\n",
    "\n",
    "df_scores_mlp = pd.DataFrame(scores_table, columns=[\"Model\", \"Train Score\", \"Test Score\"])\n",
    "\n",
    "df_scores_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Model 3 (ADA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3.1 Hyperparameter Inspection \n",
    "##### hyperparams to be tweaked or that can be tweaked \n",
    "- <mark>estimator</mark> : we can use the previous models\n",
    "- <mark>n_estimators</mark> : number of estimators \n",
    "- <mark>learning_rate</mark> : learning rate, weight applied at each iteration \n",
    "- <mark>algorithm</mark> : algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3.1 (a) n_estimators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### n_estimators against model accuracies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [i for i in range(100, 1100, 10)]\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Train AdaBoost models with different n_estimators values\n",
    "for n_estimators in estimators:\n",
    "    model = AdaBoostClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate accuracy on the training set\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    # Evaluate accuracy on the test set\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plotting the graph\n",
    "plt.plot(estimators, train_accuracies,label='Train Set')\n",
    "plt.plot(estimators, test_accuracies,label='Test Set')\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Number of Estimators vs Accuracy for AdaBoost Classifier')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# scores tend to see increases for the train set, but for the test set it is inconsistent \n",
    "# we can try to strike a balance for it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3.1 (b) learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### learning rate against model accuracies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.1, 0.5, 1.0]\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Train AdaBoost models with different learning rates\n",
    "for learning_rate in learning_rates:\n",
    "    model = AdaBoostClassifier(learning_rate=learning_rate, n_estimators=500, random_state=42)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate accuracy on the training set\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    # Evaluate accuracy on the test set\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plotting the graph\n",
    "plt.plot(learning_rates, train_accuracies, marker='o', label='Train Set')\n",
    "plt.plot(learning_rates, test_accuracies, marker='o', label='Test Set')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Learning Rate vs Accuracy for AdaBoost Classifier')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3.2 Optimizing Hyperparameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3.2 (a) GridSearchCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1st iteration - lower estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators' : [200,300,400],\n",
    "              'learning_rate' : [0.6,0.8,1],\n",
    "              'algorithm' : ['SAMME.R','SAMME']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "grid = GridSearchCV(estimator=ada, param_grid=param_grid, scoring='accuracy',verbose = 3,refit=True).fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "formatted_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "print(\"Elapsed Time: {}\".format(formatted_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada2 = AdaBoostClassifier(algorithm='SAMME.R',learning_rate=1,n_estimators=300,random_state=42).fit(X_train,y_train)\n",
    "\n",
    "model_scores_classification(ada2)\n",
    "\n",
    "# train and test scores increase but is slightly overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2nd iteration - lower learning rate \n",
    "- high learning rates tend to lead to overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators' : [200,300,400],\n",
    "              'learning_rate' : [0.2,0.4,0.6],\n",
    "              'algorithm' : ['SAMME.R','SAMME']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "grid = GridSearchCV(estimator=ada, param_grid=param_grid, scoring='accuracy',verbose = 3,refit=True).fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "formatted_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "print(\"Elapsed Time: {}\".format(formatted_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada3  = AdaBoostClassifier(algorithm='SAMME.R',learning_rate=0.6,n_estimators=400,random_state=42).fit(X_train,y_train)\n",
    "\n",
    "model_scores_classification(ada3)\n",
    "\n",
    "# overfitting is reduced "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3rd iteration - use lower number of estimators \n",
    "- higher estimators leads to overfitting due to complexity? (confirm this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators' : [50,100,200],\n",
    "              'learning_rate' : [0.2,0.4,0.6],\n",
    "              'algorithm' : ['SAMME.R','SAMME']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "grid = GridSearchCV(estimator=ada, param_grid=param_grid, scoring='accuracy',verbose = 3,refit=True).fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "formatted_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "print(\"Elapsed Time: {}\".format(formatted_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada4  = AdaBoostClassifier(algorithm='SAMME.R',learning_rate=0.6,n_estimators=200,random_state=42).fit(X_train,y_train)\n",
    "\n",
    "model_scores_classification(ada4)\n",
    "\n",
    "# lower iterations leads test score to be lower? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4th iteration - use rf3 as a base estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Airbnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression models \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load and Sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bnb = pd.read_csv('./bnb_transformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6307 entries, 0 to 6306\n",
      "Data columns (total 32 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   host_id                         6307 non-null   int64  \n",
      " 1   neighbourhood                   6307 non-null   int64  \n",
      " 2   latitude                        6307 non-null   float64\n",
      " 3   longitude                       6307 non-null   float64\n",
      " 4   room_type                       6307 non-null   int64  \n",
      " 5   price                           6307 non-null   float64\n",
      " 6   minimum_nights                  6307 non-null   float64\n",
      " 7   number_of_reviews               6307 non-null   float64\n",
      " 8   reviews_per_month               6307 non-null   float64\n",
      " 9   calculated_host_listings_count  6307 non-null   float64\n",
      " 10  availability_365                6307 non-null   float64\n",
      " 11  last_review_year                6307 non-null   float64\n",
      " 12  last_review_month               6307 non-null   float64\n",
      " 13  last_review_day                 6307 non-null   float64\n",
      " 14  apartment                       6307 non-null   float64\n",
      " 15  apt                             6307 non-null   float64\n",
      " 16  bed                             6307 non-null   float64\n",
      " 17  bedroom                         6307 non-null   float64\n",
      " 18  br                              6307 non-null   float64\n",
      " 19  central                         6307 non-null   float64\n",
      " 20  city                            6307 non-null   float64\n",
      " 21  condo                           6307 non-null   float64\n",
      " 22  cosy                            6307 non-null   float64\n",
      " 23  cozy                            6307 non-null   float64\n",
      " 24  mins                            6307 non-null   float64\n",
      " 25  mrt                             6307 non-null   float64\n",
      " 26  near                            6307 non-null   float64\n",
      " 27  orchard                         6307 non-null   float64\n",
      " 28  private                         6307 non-null   float64\n",
      " 29  room                            6307 non-null   float64\n",
      " 30  spacious                        6307 non-null   float64\n",
      " 31  studio                          6307 non-null   float64\n",
      "dtypes: float64(29), int64(3)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "df_bnb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_id</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>...</th>\n",
       "      <th>cosy</th>\n",
       "      <th>cozy</th>\n",
       "      <th>mins</th>\n",
       "      <th>mrt</th>\n",
       "      <th>near</th>\n",
       "      <th>orchard</th>\n",
       "      <th>private</th>\n",
       "      <th>room</th>\n",
       "      <th>spacious</th>\n",
       "      <th>studio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>227796</td>\n",
       "      <td>131</td>\n",
       "      <td>1.746376</td>\n",
       "      <td>-2.626110</td>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.729361</td>\n",
       "      <td>1.157713</td>\n",
       "      <td>0.217513</td>\n",
       "      <td>-0.684275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439258</td>\n",
       "      <td>469</td>\n",
       "      <td>-0.904317</td>\n",
       "      <td>-1.710715</td>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.084695</td>\n",
       "      <td>1.157713</td>\n",
       "      <td>0.137405</td>\n",
       "      <td>-0.226308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439258</td>\n",
       "      <td>469</td>\n",
       "      <td>-0.927419</td>\n",
       "      <td>-1.596939</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.406505</td>\n",
       "      <td>0.879358</td>\n",
       "      <td>-0.124190</td>\n",
       "      <td>-0.226308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720567</td>\n",
       "      <td>0.48444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1521514</td>\n",
       "      <td>134</td>\n",
       "      <td>0.463587</td>\n",
       "      <td>-0.512277</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-0.547453</td>\n",
       "      <td>1.647549</td>\n",
       "      <td>1.060556</td>\n",
       "      <td>-0.610410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439258</td>\n",
       "      <td>469</td>\n",
       "      <td>-0.842913</td>\n",
       "      <td>-1.677979</td>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.406505</td>\n",
       "      <td>1.008257</td>\n",
       "      <td>-0.021196</td>\n",
       "      <td>-0.226308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   host_id  neighbourhood  latitude  longitude  room_type  price  \\\n",
       "0   227796            131  1.746376  -2.626110          1   81.0   \n",
       "1  1439258            469 -0.904317  -1.710715          1   44.0   \n",
       "2  1439258            469 -0.927419  -1.596939          1   40.0   \n",
       "3  1521514            134  0.463587  -0.512277          1   65.0   \n",
       "4  1439258            469 -0.842913  -1.677979          1   44.0   \n",
       "\n",
       "   minimum_nights  number_of_reviews  reviews_per_month  \\\n",
       "0        1.729361           1.157713           0.217513   \n",
       "1        1.084695           1.157713           0.137405   \n",
       "2        1.406505           0.879358          -0.124190   \n",
       "3       -0.547453           1.647549           1.060556   \n",
       "4        1.406505           1.008257          -0.021196   \n",
       "\n",
       "   calculated_host_listings_count  ...  cosy  cozy      mins      mrt  near  \\\n",
       "0                       -0.684275  ...   0.0   0.0  0.000000  0.00000   0.0   \n",
       "1                       -0.226308  ...   0.0   0.0  0.000000  0.00000   0.0   \n",
       "2                       -0.226308  ...   0.0   0.0  0.720567  0.48444   0.0   \n",
       "3                       -0.610410  ...   0.0   0.0  1.000000  0.00000   0.0   \n",
       "4                       -0.226308  ...   0.0   0.0  1.000000  0.00000   0.0   \n",
       "\n",
       "   orchard  private      room  spacious  studio  \n",
       "0      0.0      0.0  1.000000       0.0     0.0  \n",
       "1      0.0      0.0  0.641676       0.0     0.0  \n",
       "2      0.0      0.0  0.496085       0.0     0.0  \n",
       "3      0.0      0.0  0.000000       0.0     0.0  \n",
       "4      0.0      0.0  0.000000       0.0     0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bnb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_id                           0\n",
       "neighbourhood                     0\n",
       "latitude                          0\n",
       "longitude                         0\n",
       "room_type                         0\n",
       "price                             0\n",
       "minimum_nights                    0\n",
       "number_of_reviews                 0\n",
       "reviews_per_month                 0\n",
       "calculated_host_listings_count    0\n",
       "availability_365                  0\n",
       "last_review_year                  0\n",
       "last_review_month                 0\n",
       "last_review_day                   0\n",
       "apartment                         0\n",
       "apt                               0\n",
       "bed                               0\n",
       "bedroom                           0\n",
       "br                                0\n",
       "central                           0\n",
       "city                              0\n",
       "condo                             0\n",
       "cosy                              0\n",
       "cozy                              0\n",
       "mins                              0\n",
       "mrt                               0\n",
       "near                              0\n",
       "orchard                           0\n",
       "private                           0\n",
       "room                              0\n",
       "spacious                          0\n",
       "studio                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bnb.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_id</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>...</th>\n",
       "      <th>cosy</th>\n",
       "      <th>cozy</th>\n",
       "      <th>mins</th>\n",
       "      <th>mrt</th>\n",
       "      <th>near</th>\n",
       "      <th>orchard</th>\n",
       "      <th>private</th>\n",
       "      <th>room</th>\n",
       "      <th>spacious</th>\n",
       "      <th>studio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.307000e+03</td>\n",
       "      <td>6307.000000</td>\n",
       "      <td>6.307000e+03</td>\n",
       "      <td>6.307000e+03</td>\n",
       "      <td>6307.000000</td>\n",
       "      <td>6307.000000</td>\n",
       "      <td>6.307000e+03</td>\n",
       "      <td>6.307000e+03</td>\n",
       "      <td>6.307000e+03</td>\n",
       "      <td>6.307000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>6307.000000</td>\n",
       "      <td>6307.000000</td>\n",
       "      <td>6307.000000</td>\n",
       "      <td>6307.000000</td>\n",
       "      <td>6307.000000</td>\n",
       "      <td>6307.000000</td>\n",
       "      <td>6307.000000</td>\n",
       "      <td>6307.000000</td>\n",
       "      <td>6307.000000</td>\n",
       "      <td>6307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.268678e+07</td>\n",
       "      <td>581.983986</td>\n",
       "      <td>1.344935e-14</td>\n",
       "      <td>4.870975e-13</td>\n",
       "      <td>1.537498</td>\n",
       "      <td>156.268432</td>\n",
       "      <td>-2.632603e-15</td>\n",
       "      <td>2.269354e-14</td>\n",
       "      <td>-2.547581e-15</td>\n",
       "      <td>1.496750e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038088</td>\n",
       "      <td>0.038503</td>\n",
       "      <td>0.034565</td>\n",
       "      <td>0.105723</td>\n",
       "      <td>0.085033</td>\n",
       "      <td>0.044024</td>\n",
       "      <td>0.045422</td>\n",
       "      <td>0.119620</td>\n",
       "      <td>0.051807</td>\n",
       "      <td>0.067715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.377692e+07</td>\n",
       "      <td>327.440241</td>\n",
       "      <td>1.000079e+00</td>\n",
       "      <td>1.000079e+00</td>\n",
       "      <td>0.599170</td>\n",
       "      <td>98.686740</td>\n",
       "      <td>1.000079e+00</td>\n",
       "      <td>1.000079e+00</td>\n",
       "      <td>1.000079e+00</td>\n",
       "      <td>1.000079e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161810</td>\n",
       "      <td>0.159995</td>\n",
       "      <td>0.150851</td>\n",
       "      <td>0.232204</td>\n",
       "      <td>0.214786</td>\n",
       "      <td>0.170141</td>\n",
       "      <td>0.178046</td>\n",
       "      <td>0.275969</td>\n",
       "      <td>0.181525</td>\n",
       "      <td>0.215714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.366600e+04</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>-3.632829e+00</td>\n",
       "      <td>-3.501983e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>-1.236524e+00</td>\n",
       "      <td>-1.132311e+00</td>\n",
       "      <td>-1.180403e+00</td>\n",
       "      <td>-6.842753e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.114972e+07</td>\n",
       "      <td>362.000000</td>\n",
       "      <td>-7.690466e-01</td>\n",
       "      <td>-4.677651e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>-5.474529e-01</td>\n",
       "      <td>-1.132311e+00</td>\n",
       "      <td>-1.180403e+00</td>\n",
       "      <td>-6.547290e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.344891e+07</td>\n",
       "      <td>477.000000</td>\n",
       "      <td>1.444091e-01</td>\n",
       "      <td>-6.675572e-02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>-1.463868e-01</td>\n",
       "      <td>-1.756958e-02</td>\n",
       "      <td>6.399646e-02</td>\n",
       "      <td>-4.922244e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.598048e+08</td>\n",
       "      <td>994.000000</td>\n",
       "      <td>6.596528e-01</td>\n",
       "      <td>4.478298e-01</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>8.409538e-01</td>\n",
       "      <td>9.270265e-01</td>\n",
       "      <td>8.235087e-01</td>\n",
       "      <td>2.907525e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.885676e+08</td>\n",
       "      <td>1043.000000</td>\n",
       "      <td>3.781817e+00</td>\n",
       "      <td>2.683822e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>1.729361e+00</td>\n",
       "      <td>1.647549e+00</td>\n",
       "      <td>1.733648e+00</td>\n",
       "      <td>3.348795e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            host_id  neighbourhood      latitude     longitude    room_type  \\\n",
       "count  6.307000e+03    6307.000000  6.307000e+03  6.307000e+03  6307.000000   \n",
       "mean   9.268678e+07     581.983986  1.344935e-14  4.870975e-13     1.537498   \n",
       "std    8.377692e+07     327.440241  1.000079e+00  1.000079e+00     0.599170   \n",
       "min    2.366600e+04     101.000000 -3.632829e+00 -3.501983e+00     0.000000   \n",
       "25%    2.114972e+07     362.000000 -7.690466e-01 -4.677651e-01     1.000000   \n",
       "50%    6.344891e+07     477.000000  1.444091e-01 -6.675572e-02     2.000000   \n",
       "75%    1.598048e+08     994.000000  6.596528e-01  4.478298e-01     2.000000   \n",
       "max    2.885676e+08    1043.000000  3.781817e+00  2.683822e+00     2.000000   \n",
       "\n",
       "             price  minimum_nights  number_of_reviews  reviews_per_month  \\\n",
       "count  6307.000000    6.307000e+03       6.307000e+03       6.307000e+03   \n",
       "mean    156.268432   -2.632603e-15       2.269354e-14      -2.547581e-15   \n",
       "std      98.686740    1.000079e+00       1.000079e+00       1.000079e+00   \n",
       "min      35.000000   -1.236524e+00      -1.132311e+00      -1.180403e+00   \n",
       "25%      81.000000   -5.474529e-01      -1.132311e+00      -1.180403e+00   \n",
       "50%     135.000000   -1.463868e-01      -1.756958e-02       6.399646e-02   \n",
       "75%     208.000000    8.409538e-01       9.270265e-01       8.235087e-01   \n",
       "max     394.000000    1.729361e+00       1.647549e+00       1.733648e+00   \n",
       "\n",
       "       calculated_host_listings_count  ...         cosy         cozy  \\\n",
       "count                    6.307000e+03  ...  6307.000000  6307.000000   \n",
       "mean                     1.496750e-15  ...     0.038088     0.038503   \n",
       "std                      1.000079e+00  ...     0.161810     0.159995   \n",
       "min                     -6.842753e-01  ...     0.000000     0.000000   \n",
       "25%                     -6.547290e-01  ...     0.000000     0.000000   \n",
       "50%                     -4.922244e-01  ...     0.000000     0.000000   \n",
       "75%                      2.907525e-01  ...     0.000000     0.000000   \n",
       "max                      3.348795e+00  ...     1.000000     1.000000   \n",
       "\n",
       "              mins          mrt         near      orchard      private  \\\n",
       "count  6307.000000  6307.000000  6307.000000  6307.000000  6307.000000   \n",
       "mean      0.034565     0.105723     0.085033     0.044024     0.045422   \n",
       "std       0.150851     0.232204     0.214786     0.170141     0.178046   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              room     spacious       studio  \n",
       "count  6307.000000  6307.000000  6307.000000  \n",
       "mean      0.119620     0.051807     0.067715  \n",
       "std       0.275969     0.181525     0.215714  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bnb.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Train and Test Splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_bnb.drop(['price'], axis =1)\n",
    "y = df_bnb['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared (uncentered):</th>      <td>   0.849</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.848</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   795.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 30 Jan 2024</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:43:00</td>     <th>  Log-Likelihood:    </th>          <td> -25086.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4414</td>      <th>  AIC:               </th>          <td>5.023e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4383</td>      <th>  BIC:               </th>          <td>5.043e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    31</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_id</th>                        <td> 4.388e-08</td> <td> 1.45e-08</td> <td>    3.036</td> <td> 0.002</td> <td> 1.55e-08</td> <td> 7.22e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>neighbourhood</th>                  <td>   -0.0139</td> <td>    0.004</td> <td>   -3.523</td> <td> 0.000</td> <td>   -0.022</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>latitude</th>                       <td>   -8.0632</td> <td>    1.172</td> <td>   -6.879</td> <td> 0.000</td> <td>  -10.361</td> <td>   -5.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>longitude</th>                      <td>   -1.2555</td> <td>    1.364</td> <td>   -0.920</td> <td> 0.357</td> <td>   -3.930</td> <td>    1.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>room_type</th>                      <td>  100.8261</td> <td>    2.061</td> <td>   48.912</td> <td> 0.000</td> <td>   96.785</td> <td>  104.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>minimum_nights</th>                 <td>  -20.2104</td> <td>    1.241</td> <td>  -16.283</td> <td> 0.000</td> <td>  -22.644</td> <td>  -17.777</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_reviews</th>              <td>   -8.3875</td> <td>    2.778</td> <td>   -3.019</td> <td> 0.003</td> <td>  -13.834</td> <td>   -2.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reviews_per_month</th>              <td>    0.6697</td> <td>    2.879</td> <td>    0.233</td> <td> 0.816</td> <td>   -4.975</td> <td>    6.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>calculated_host_listings_count</th> <td>   -9.7985</td> <td>    1.431</td> <td>   -6.846</td> <td> 0.000</td> <td>  -12.604</td> <td>   -6.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>availability_365</th>               <td>   15.6010</td> <td>    1.175</td> <td>   13.283</td> <td> 0.000</td> <td>   13.298</td> <td>   17.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_review_year</th>               <td>   -0.0007</td> <td>    0.003</td> <td>   -0.258</td> <td> 0.796</td> <td>   -0.006</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_review_month</th>              <td>   -0.4210</td> <td>    0.552</td> <td>   -0.763</td> <td> 0.446</td> <td>   -1.503</td> <td>    0.661</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_review_day</th>                <td>    0.3367</td> <td>    0.151</td> <td>    2.231</td> <td> 0.026</td> <td>    0.041</td> <td>    0.633</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>apartment</th>                      <td>   15.2260</td> <td>    5.080</td> <td>    2.997</td> <td> 0.003</td> <td>    5.267</td> <td>   25.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>apt</th>                            <td>  -14.5068</td> <td>    6.197</td> <td>   -2.341</td> <td> 0.019</td> <td>  -26.655</td> <td>   -2.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bed</th>                            <td>   10.1944</td> <td>    5.989</td> <td>    1.702</td> <td> 0.089</td> <td>   -1.547</td> <td>   21.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedroom</th>                        <td>   25.0961</td> <td>    5.161</td> <td>    4.863</td> <td> 0.000</td> <td>   14.978</td> <td>   35.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br</th>                             <td>   62.4632</td> <td>    5.223</td> <td>   11.958</td> <td> 0.000</td> <td>   52.223</td> <td>   72.704</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>central</th>                        <td>    5.7609</td> <td>    6.552</td> <td>    0.879</td> <td> 0.379</td> <td>   -7.085</td> <td>   18.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city</th>                           <td>  -13.9327</td> <td>    5.350</td> <td>   -2.604</td> <td> 0.009</td> <td>  -24.421</td> <td>   -3.445</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condo</th>                          <td>   -8.6539</td> <td>    6.647</td> <td>   -1.302</td> <td> 0.193</td> <td>  -21.685</td> <td>    4.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cosy</th>                           <td>  -36.1932</td> <td>    6.551</td> <td>   -5.525</td> <td> 0.000</td> <td>  -49.036</td> <td>  -23.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cozy</th>                           <td>  -41.1451</td> <td>    6.839</td> <td>   -6.016</td> <td> 0.000</td> <td>  -54.553</td> <td>  -27.738</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mins</th>                           <td>  -22.3313</td> <td>    7.248</td> <td>   -3.081</td> <td> 0.002</td> <td>  -36.541</td> <td>   -8.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mrt</th>                            <td>    7.9117</td> <td>    5.047</td> <td>    1.567</td> <td> 0.117</td> <td>   -1.984</td> <td>   17.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>near</th>                           <td>   -4.2160</td> <td>    5.122</td> <td>   -0.823</td> <td> 0.410</td> <td>  -14.257</td> <td>    5.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orchard</th>                        <td>   38.3296</td> <td>    6.484</td> <td>    5.911</td> <td> 0.000</td> <td>   25.617</td> <td>   51.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>private</th>                        <td>   -3.3443</td> <td>    6.198</td> <td>   -0.540</td> <td> 0.590</td> <td>  -15.496</td> <td>    8.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>room</th>                           <td>   -5.1931</td> <td>    4.152</td> <td>   -1.251</td> <td> 0.211</td> <td>  -13.333</td> <td>    2.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spacious</th>                       <td>   31.3568</td> <td>    6.204</td> <td>    5.055</td> <td> 0.000</td> <td>   19.195</td> <td>   43.519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>studio</th>                         <td>  -73.3025</td> <td>    5.586</td> <td>  -13.123</td> <td> 0.000</td> <td>  -84.254</td> <td>  -62.351</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>816.428</td> <th>  Durbin-Watson:     </th> <td>   1.970</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1645.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.104</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.018</td>  <th>  Cond. No.          </th> <td>9.65e+08</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[3] The condition number is large, 9.65e+08. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                  price   R-squared (uncentered):                   0.849\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.848\n",
       "Method:                 Least Squares   F-statistic:                              795.9\n",
       "Date:                Tue, 30 Jan 2024   Prob (F-statistic):                        0.00\n",
       "Time:                        23:43:00   Log-Likelihood:                         -25086.\n",
       "No. Observations:                4414   AIC:                                  5.023e+04\n",
       "Df Residuals:                    4383   BIC:                                  5.043e+04\n",
       "Df Model:                          31                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==================================================================================================\n",
       "                                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------\n",
       "host_id                         4.388e-08   1.45e-08      3.036      0.002    1.55e-08    7.22e-08\n",
       "neighbourhood                     -0.0139      0.004     -3.523      0.000      -0.022      -0.006\n",
       "latitude                          -8.0632      1.172     -6.879      0.000     -10.361      -5.765\n",
       "longitude                         -1.2555      1.364     -0.920      0.357      -3.930       1.419\n",
       "room_type                        100.8261      2.061     48.912      0.000      96.785     104.867\n",
       "minimum_nights                   -20.2104      1.241    -16.283      0.000     -22.644     -17.777\n",
       "number_of_reviews                 -8.3875      2.778     -3.019      0.003     -13.834      -2.941\n",
       "reviews_per_month                  0.6697      2.879      0.233      0.816      -4.975       6.314\n",
       "calculated_host_listings_count    -9.7985      1.431     -6.846      0.000     -12.604      -6.993\n",
       "availability_365                  15.6010      1.175     13.283      0.000      13.298      17.904\n",
       "last_review_year                  -0.0007      0.003     -0.258      0.796      -0.006       0.005\n",
       "last_review_month                 -0.4210      0.552     -0.763      0.446      -1.503       0.661\n",
       "last_review_day                    0.3367      0.151      2.231      0.026       0.041       0.633\n",
       "apartment                         15.2260      5.080      2.997      0.003       5.267      25.185\n",
       "apt                              -14.5068      6.197     -2.341      0.019     -26.655      -2.358\n",
       "bed                               10.1944      5.989      1.702      0.089      -1.547      21.936\n",
       "bedroom                           25.0961      5.161      4.863      0.000      14.978      35.214\n",
       "br                                62.4632      5.223     11.958      0.000      52.223      72.704\n",
       "central                            5.7609      6.552      0.879      0.379      -7.085      18.607\n",
       "city                             -13.9327      5.350     -2.604      0.009     -24.421      -3.445\n",
       "condo                             -8.6539      6.647     -1.302      0.193     -21.685       4.377\n",
       "cosy                             -36.1932      6.551     -5.525      0.000     -49.036     -23.351\n",
       "cozy                             -41.1451      6.839     -6.016      0.000     -54.553     -27.738\n",
       "mins                             -22.3313      7.248     -3.081      0.002     -36.541      -8.121\n",
       "mrt                                7.9117      5.047      1.567      0.117      -1.984      17.807\n",
       "near                              -4.2160      5.122     -0.823      0.410     -14.257       5.825\n",
       "orchard                           38.3296      6.484      5.911      0.000      25.617      51.042\n",
       "private                           -3.3443      6.198     -0.540      0.590     -15.496       8.808\n",
       "room                              -5.1931      4.152     -1.251      0.211     -13.333       2.947\n",
       "spacious                          31.3568      6.204      5.055      0.000      19.195      43.519\n",
       "studio                           -73.3025      5.586    -13.123      0.000     -84.254     -62.351\n",
       "==============================================================================\n",
       "Omnibus:                      816.428   Durbin-Watson:                   1.970\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1645.453\n",
       "Skew:                           1.104   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.018   Cond. No.                     9.65e+08\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[3] The condition number is large, 9.65e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using OLS model to see the p-values and coefficients \n",
    "ols = sm.OLS(y_train, X_train).fit()\n",
    "# Summary statistics from the model\n",
    "ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose which features to drop in train and test \n",
    "\n",
    "columns_to_drop = ['apartment', 'apt', 'bed', 'bedroom', 'br', 'central', 'city', 'condo', 'cosy', 'cozy', \n",
    "                   'mins', 'near', 'orchard', 'room', 'studio','longitude','latitude']\n",
    "\n",
    "X_train = X_train.drop(columns=columns_to_drop)\n",
    "\n",
    "X_test = X_test.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4414 entries, 6206 to 860\n",
      "Data columns (total 14 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   host_id                         4414 non-null   int64  \n",
      " 1   neighbourhood                   4414 non-null   int64  \n",
      " 2   room_type                       4414 non-null   int64  \n",
      " 3   minimum_nights                  4414 non-null   float64\n",
      " 4   number_of_reviews               4414 non-null   float64\n",
      " 5   reviews_per_month               4414 non-null   float64\n",
      " 6   calculated_host_listings_count  4414 non-null   float64\n",
      " 7   availability_365                4414 non-null   float64\n",
      " 8   last_review_year                4414 non-null   float64\n",
      " 9   last_review_month               4414 non-null   float64\n",
      " 10  last_review_day                 4414 non-null   float64\n",
      " 11  mrt                             4414 non-null   float64\n",
      " 12  private                         4414 non-null   float64\n",
      " 13  spacious                        4414 non-null   float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 517.3 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Build the Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "model_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression\n",
    "lr = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "models.append(lr)\n",
    "model_names.append('LinearRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree regressor\n",
    "dtr = DecisionTreeRegressor(random_state=42).fit(X_train,y_train)\n",
    "\n",
    "models.append(dtr)\n",
    "model_names.append('DTree Regressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest regressor \n",
    "rfr = RandomForestRegressor(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "models.append(rfr)\n",
    "model_names.append('Random Forest Regressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVR\n",
    "svr = SVR().fit(X_train, y_train)\n",
    "\n",
    "models.append(svr)\n",
    "model_names.append('SVR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive boosting \n",
    "ada_r = AdaBoostRegressor(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "models.append(ada_r)\n",
    "model_names.append('ADA Boost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB\n",
    "xgb_r = XGBRegressor(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "models.append(xgb_r)\n",
    "model_names.append('XG Boost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multilayer perceptron\n",
    "mlp_r = MLPRegressor(random_state=42).fit(X_train,y_train)\n",
    "\n",
    "models.append(mlp_r)\n",
    "model_names.append('Multilayer Perceptron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Consolidated View of Model Accuracies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Test_RMSE</th>\n",
       "      <th>Train_R2</th>\n",
       "      <th>Test_R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>76.251880</td>\n",
       "      <td>80.042311</td>\n",
       "      <td>0.389106</td>\n",
       "      <td>0.374134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTree Regressor</td>\n",
       "      <td>7.881719</td>\n",
       "      <td>86.985652</td>\n",
       "      <td>0.993473</td>\n",
       "      <td>0.260842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>23.769790</td>\n",
       "      <td>63.447484</td>\n",
       "      <td>0.940637</td>\n",
       "      <td>0.606748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>98.445795</td>\n",
       "      <td>102.874804</td>\n",
       "      <td>-0.018261</td>\n",
       "      <td>-0.033856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADA Boost</td>\n",
       "      <td>76.823480</td>\n",
       "      <td>80.526183</td>\n",
       "      <td>0.379913</td>\n",
       "      <td>0.366544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XG Boost</td>\n",
       "      <td>27.245337</td>\n",
       "      <td>63.935476</td>\n",
       "      <td>0.922008</td>\n",
       "      <td>0.600676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Multilayer Perceptron</td>\n",
       "      <td>130.209932</td>\n",
       "      <td>134.809253</td>\n",
       "      <td>-0.781365</td>\n",
       "      <td>-0.775339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Train_RMSE   Test_RMSE  Train_R2   Test_R2\n",
       "0         LinearRegression   76.251880   80.042311  0.389106  0.374134\n",
       "1          DTree Regressor    7.881719   86.985652  0.993473  0.260842\n",
       "2  Random Forest Regressor   23.769790   63.447484  0.940637  0.606748\n",
       "3                      SVR   98.445795  102.874804 -0.018261 -0.033856\n",
       "4                ADA Boost   76.823480   80.526183  0.379913  0.366544\n",
       "5                 XG Boost   27.245337   63.935476  0.922008  0.600676\n",
       "6    Multilayer Perceptron  130.209932  134.809253 -0.781365 -0.775339"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    # Fit the model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate metrics\n",
    "    train_r2 = model.score(X_train, y_train)\n",
    "    test_r2 = model.score(X_test, y_test)\n",
    "\n",
    "    train_rmse = sqrt(mean_squared_error(y_train, model.predict(X_train)))\n",
    "    test_rmse = sqrt(mean_squared_error(y_test, model.predict(X_test)))\n",
    "\n",
    "    # Append results to the list\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Train_RMSE': train_rmse,\n",
    "        'Test_RMSE': test_rmse,\n",
    "        'Train_R2': train_r2,\n",
    "        'Test_R2': test_r2\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluate and Improve the Model(s)\n",
    "These models will be chosen for further evaluation and tuning  : <mark>Random Forest Regressor</mark>, <mark>SVR</mark>,<mark>XG Boost</mark>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_end_time = time.time()\n",
    "\n",
    "notebook_elapsed_time = notebook_end_time-notebook_start_time\n",
    "\n",
    "minutes, seconds = divmod(notebook_elapsed_time, 60)\n",
    "formatted_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "print(\"Elapsed Time: {}\".format(formatted_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
