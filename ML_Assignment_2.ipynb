{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required packages\n",
    "\n",
    "# tabular data\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tabulate import tabulate\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# metrics \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# classification models \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# statistical models \n",
    "import statsmodels.api as sm\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "# time - test\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. HR Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load and Sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hr = pd.read_csv('./hr_csv_transformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "      <th>...</th>\n",
       "      <th>department_R&amp;D</th>\n",
       "      <th>department_Procurement</th>\n",
       "      <th>department_Finance</th>\n",
       "      <th>department_HR</th>\n",
       "      <th>department_Legal</th>\n",
       "      <th>gender_f</th>\n",
       "      <th>gender_m</th>\n",
       "      <th>recruitment_channel_sourcing</th>\n",
       "      <th>recruitment_channel_other</th>\n",
       "      <th>recruitment_channel_referred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6108</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.103865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.503161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>785</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.677333</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.225465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.321705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.864038</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6108</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.436134</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.864038</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732668</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.740418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   region  education  no_of_trainings       age  previous_year_rating  \\\n",
       "0    6108          1              2.0 -0.103865                   0.0   \n",
       "1     785          1              1.0 -0.677333                  -2.0   \n",
       "2    1234          2              0.0 -0.321705                   1.0   \n",
       "3    6108          1              0.0 -0.436134                   1.0   \n",
       "4    1701          2              0.0  0.732668                  -2.0   \n",
       "\n",
       "   length_of_service  KPIs_met >80%  awards_won?  avg_training_score  \\\n",
       "0          -0.503161              0            0               -0.12   \n",
       "1          -0.225465              0            0                1.04   \n",
       "2          -0.864038              1            0               -0.44   \n",
       "3          -0.864038              0            0               -0.08   \n",
       "4           0.740418              0            0               -0.20   \n",
       "\n",
       "   is_promoted  ...  department_R&D  department_Procurement  \\\n",
       "0            0  ...               0                       0   \n",
       "1            0  ...               0                       0   \n",
       "2            0  ...               0                       0   \n",
       "3            0  ...               0                       0   \n",
       "4            0  ...               0                       0   \n",
       "\n",
       "   department_Finance  department_HR  department_Legal  gender_f  gender_m  \\\n",
       "0                   0              0                 0         0         1   \n",
       "1                   0              0                 0         0         1   \n",
       "2                   0              0                 0         0         1   \n",
       "3                   1              0                 0         0         1   \n",
       "4                   0              0                 0         1         0   \n",
       "\n",
       "   recruitment_channel_sourcing  recruitment_channel_other  \\\n",
       "0                             0                          1   \n",
       "1                             0                          1   \n",
       "2                             0                          1   \n",
       "3                             1                          0   \n",
       "4                             1                          0   \n",
       "\n",
       "   recruitment_channel_referred  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             0  \n",
       "4                             0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9092 entries, 0 to 9091\n",
      "Data columns (total 24 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   region                        9092 non-null   int64  \n",
      " 1   education                     9092 non-null   int64  \n",
      " 2   no_of_trainings               9092 non-null   float64\n",
      " 3   age                           9092 non-null   float64\n",
      " 4   previous_year_rating          9092 non-null   float64\n",
      " 5   length_of_service             9092 non-null   float64\n",
      " 6   KPIs_met >80%                 9092 non-null   int64  \n",
      " 7   awards_won?                   9092 non-null   int64  \n",
      " 8   avg_training_score            9092 non-null   float64\n",
      " 9   is_promoted                   9092 non-null   int64  \n",
      " 10  department_Sales & Marketing  9092 non-null   int64  \n",
      " 11  department_Operations         9092 non-null   int64  \n",
      " 12  department_Technology         9092 non-null   int64  \n",
      " 13  department_Analytics          9092 non-null   int64  \n",
      " 14  department_R&D                9092 non-null   int64  \n",
      " 15  department_Procurement        9092 non-null   int64  \n",
      " 16  department_Finance            9092 non-null   int64  \n",
      " 17  department_HR                 9092 non-null   int64  \n",
      " 18  department_Legal              9092 non-null   int64  \n",
      " 19  gender_f                      9092 non-null   int64  \n",
      " 20  gender_m                      9092 non-null   int64  \n",
      " 21  recruitment_channel_sourcing  9092 non-null   int64  \n",
      " 22  recruitment_channel_other     9092 non-null   int64  \n",
      " 23  recruitment_channel_referred  9092 non-null   int64  \n",
      "dtypes: float64(5), int64(19)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_hr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "      <th>...</th>\n",
       "      <th>department_R&amp;D</th>\n",
       "      <th>department_Procurement</th>\n",
       "      <th>department_Finance</th>\n",
       "      <th>department_HR</th>\n",
       "      <th>department_Legal</th>\n",
       "      <th>gender_f</th>\n",
       "      <th>gender_m</th>\n",
       "      <th>recruitment_channel_sourcing</th>\n",
       "      <th>recruitment_channel_other</th>\n",
       "      <th>recruitment_channel_referred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "      <td>9092.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4584.995381</td>\n",
       "      <td>1.290805</td>\n",
       "      <td>0.231522</td>\n",
       "      <td>0.107887</td>\n",
       "      <td>0.583150</td>\n",
       "      <td>-0.043580</td>\n",
       "      <td>0.512868</td>\n",
       "      <td>0.064452</td>\n",
       "      <td>0.283836</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015178</td>\n",
       "      <td>0.140013</td>\n",
       "      <td>0.044435</td>\n",
       "      <td>0.036846</td>\n",
       "      <td>0.017268</td>\n",
       "      <td>0.315662</td>\n",
       "      <td>0.684338</td>\n",
       "      <td>0.429059</td>\n",
       "      <td>0.545535</td>\n",
       "      <td>0.025407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4079.802512</td>\n",
       "      <td>0.483942</td>\n",
       "      <td>0.559087</td>\n",
       "      <td>0.671022</td>\n",
       "      <td>1.182599</td>\n",
       "      <td>0.699312</td>\n",
       "      <td>0.499862</td>\n",
       "      <td>0.245570</td>\n",
       "      <td>0.579979</td>\n",
       "      <td>0.500027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122268</td>\n",
       "      <td>0.347020</td>\n",
       "      <td>0.206070</td>\n",
       "      <td>0.188393</td>\n",
       "      <td>0.130275</td>\n",
       "      <td>0.464805</td>\n",
       "      <td>0.464805</td>\n",
       "      <td>0.494969</td>\n",
       "      <td>0.497950</td>\n",
       "      <td>0.157366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.690290</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-1.378193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1234.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.436134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.503161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2617.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6108.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.476189</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.496839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11497.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.017907</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.115994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             region    education  no_of_trainings          age  \\\n",
       "count   9092.000000  9092.000000      9092.000000  9092.000000   \n",
       "mean    4584.995381     1.290805         0.231522     0.107887   \n",
       "std     4079.802512     0.483942         0.559087     0.671022   \n",
       "min       31.000000     0.000000         0.000000    -1.690290   \n",
       "25%     1234.000000     1.000000         0.000000    -0.436134   \n",
       "50%     2617.000000     1.000000         0.000000     0.000000   \n",
       "75%     6108.000000     2.000000         0.000000     0.476189   \n",
       "max    11497.000000     2.000000         7.000000     2.017907   \n",
       "\n",
       "       previous_year_rating  length_of_service  KPIs_met >80%  awards_won?  \\\n",
       "count           9092.000000        9092.000000    9092.000000  9092.000000   \n",
       "mean               0.583150          -0.043580       0.512868     0.064452   \n",
       "std                1.182599           0.699312       0.499862     0.245570   \n",
       "min               -2.000000          -1.378193       0.000000     0.000000   \n",
       "25%                0.000000          -0.503161       0.000000     0.000000   \n",
       "50%                0.000000           0.000000       1.000000     0.000000   \n",
       "75%                2.000000           0.496839       1.000000     0.000000   \n",
       "max                2.000000           2.115994       1.000000     1.000000   \n",
       "\n",
       "       avg_training_score  is_promoted  ...  department_R&D  \\\n",
       "count         9092.000000  9092.000000  ...     9092.000000   \n",
       "mean             0.283836     0.500000  ...        0.015178   \n",
       "std              0.579979     0.500027  ...        0.122268   \n",
       "min             -0.760000     0.000000  ...        0.000000   \n",
       "25%             -0.240000     0.000000  ...        0.000000   \n",
       "50%              0.160000     0.500000  ...        0.000000   \n",
       "75%              0.810000     1.000000  ...        0.000000   \n",
       "max              1.560000     1.000000  ...        1.000000   \n",
       "\n",
       "       department_Procurement  department_Finance  department_HR  \\\n",
       "count             9092.000000         9092.000000    9092.000000   \n",
       "mean                 0.140013            0.044435       0.036846   \n",
       "std                  0.347020            0.206070       0.188393   \n",
       "min                  0.000000            0.000000       0.000000   \n",
       "25%                  0.000000            0.000000       0.000000   \n",
       "50%                  0.000000            0.000000       0.000000   \n",
       "75%                  0.000000            0.000000       0.000000   \n",
       "max                  1.000000            1.000000       1.000000   \n",
       "\n",
       "       department_Legal     gender_f     gender_m  \\\n",
       "count       9092.000000  9092.000000  9092.000000   \n",
       "mean           0.017268     0.315662     0.684338   \n",
       "std            0.130275     0.464805     0.464805   \n",
       "min            0.000000     0.000000     0.000000   \n",
       "25%            0.000000     0.000000     0.000000   \n",
       "50%            0.000000     0.000000     1.000000   \n",
       "75%            0.000000     1.000000     1.000000   \n",
       "max            1.000000     1.000000     1.000000   \n",
       "\n",
       "       recruitment_channel_sourcing  recruitment_channel_other  \\\n",
       "count                   9092.000000                9092.000000   \n",
       "mean                       0.429059                   0.545535   \n",
       "std                        0.494969                   0.497950   \n",
       "min                        0.000000                   0.000000   \n",
       "25%                        0.000000                   0.000000   \n",
       "50%                        0.000000                   1.000000   \n",
       "75%                        1.000000                   1.000000   \n",
       "max                        1.000000                   1.000000   \n",
       "\n",
       "       recruitment_channel_referred  \n",
       "count                   9092.000000  \n",
       "mean                       0.025407  \n",
       "std                        0.157366  \n",
       "min                        0.000000  \n",
       "25%                        0.000000  \n",
       "50%                        0.000000  \n",
       "75%                        0.000000  \n",
       "max                        1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4546\n",
       "1    4546\n",
       "Name: is_promoted, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the target class distribution \n",
    "df_hr['is_promoted'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_hr.drop(['is_promoted'], axis =1)\n",
    "y = df_hr['is_promoted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Statistical Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.429350\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "# using statistical models to c\n",
    "\n",
    "# using logit\n",
    "lgsm = sm.Logit(y_train, X_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>is_promoted</td>   <th>  No. Observations:  </th>  <td>  6364</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  6343</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    20</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 28 Jan 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.3806</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:25:04</td>     <th>  Log-Likelihood:    </th> <td> -2732.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -4411.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                  <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region</th>                       <td> 6.851e-06</td> <td> 8.88e-06</td> <td>    0.772</td> <td> 0.440</td> <td>-1.06e-05</td> <td> 2.43e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education</th>                    <td>    0.1445</td> <td>    0.079</td> <td>    1.818</td> <td> 0.069</td> <td>   -0.011</td> <td>    0.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_of_trainings</th>              <td>   -0.0403</td> <td>    0.062</td> <td>   -0.655</td> <td> 0.513</td> <td>   -0.161</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                          <td>   -0.3805</td> <td>    0.073</td> <td>   -5.199</td> <td> 0.000</td> <td>   -0.524</td> <td>   -0.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_year_rating</th>         <td>    0.2490</td> <td>    0.031</td> <td>    8.137</td> <td> 0.000</td> <td>    0.189</td> <td>    0.309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>length_of_service</th>            <td>    0.1946</td> <td>    0.063</td> <td>    3.086</td> <td> 0.002</td> <td>    0.071</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>KPIs_met >80%</th>                <td>    2.6255</td> <td>    0.084</td> <td>   31.276</td> <td> 0.000</td> <td>    2.461</td> <td>    2.790</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>awards_won?</th>                  <td>    1.9333</td> <td>    0.210</td> <td>    9.198</td> <td> 0.000</td> <td>    1.521</td> <td>    2.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_training_score</th>           <td>    7.2899</td> <td>    0.233</td> <td>   31.287</td> <td> 0.000</td> <td>    6.833</td> <td>    7.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Sales & Marketing</th> <td>    4.2095</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Operations</th>        <td>    1.3355</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Technology</th>        <td>   -3.8352</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Analytics</th>         <td>   -5.3134</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_R&D</th>               <td>   -5.6380</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Procurement</th>       <td>   -1.3390</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Finance</th>           <td>    1.3003</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_HR</th>                <td>    3.7919</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Legal</th>             <td>    1.0080</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender_f</th>                     <td>   -2.2522</td> <td>  1.2e+06</td> <td>-1.87e-06</td> <td> 1.000</td> <td>-2.36e+06</td> <td> 2.36e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender_m</th>                     <td>   -2.2282</td> <td>  1.2e+06</td> <td>-1.85e-06</td> <td> 1.000</td> <td>-2.36e+06</td> <td> 2.36e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recruitment_channel_sourcing</th> <td>   -1.5920</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recruitment_channel_other</th>    <td>   -1.4742</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recruitment_channel_referred</th> <td>   -1.4141</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            is_promoted   No. Observations:                 6364\n",
       "Model:                          Logit   Df Residuals:                     6343\n",
       "Method:                           MLE   Df Model:                           20\n",
       "Date:                Sun, 28 Jan 2024   Pseudo R-squ.:                  0.3806\n",
       "Time:                        20:25:04   Log-Likelihood:                -2732.4\n",
       "converged:                       True   LL-Null:                       -4411.0\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "================================================================================================\n",
       "                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------\n",
       "region                        6.851e-06   8.88e-06      0.772      0.440   -1.06e-05    2.43e-05\n",
       "education                        0.1445      0.079      1.818      0.069      -0.011       0.300\n",
       "no_of_trainings                 -0.0403      0.062     -0.655      0.513      -0.161       0.080\n",
       "age                             -0.3805      0.073     -5.199      0.000      -0.524      -0.237\n",
       "previous_year_rating             0.2490      0.031      8.137      0.000       0.189       0.309\n",
       "length_of_service                0.1946      0.063      3.086      0.002       0.071       0.318\n",
       "KPIs_met >80%                    2.6255      0.084     31.276      0.000       2.461       2.790\n",
       "awards_won?                      1.9333      0.210      9.198      0.000       1.521       2.345\n",
       "avg_training_score               7.2899      0.233     31.287      0.000       6.833       7.747\n",
       "department_Sales & Marketing     4.2095        nan        nan        nan         nan         nan\n",
       "department_Operations            1.3355        nan        nan        nan         nan         nan\n",
       "department_Technology           -3.8352        nan        nan        nan         nan         nan\n",
       "department_Analytics            -5.3134        nan        nan        nan         nan         nan\n",
       "department_R&D                  -5.6380        nan        nan        nan         nan         nan\n",
       "department_Procurement          -1.3390        nan        nan        nan         nan         nan\n",
       "department_Finance               1.3003        nan        nan        nan         nan         nan\n",
       "department_HR                    3.7919        nan        nan        nan         nan         nan\n",
       "department_Legal                 1.0080        nan        nan        nan         nan         nan\n",
       "gender_f                        -2.2522    1.2e+06  -1.87e-06      1.000   -2.36e+06    2.36e+06\n",
       "gender_m                        -2.2282    1.2e+06  -1.85e-06      1.000   -2.36e+06    2.36e+06\n",
       "recruitment_channel_sourcing    -1.5920        nan        nan        nan         nan         nan\n",
       "recruitment_channel_other       -1.4742        nan        nan        nan         nan         nan\n",
       "recruitment_channel_referred    -1.4141        nan        nan        nan         nan         nan\n",
       "================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgsm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Build the Model(s) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression(random_state=42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "dtree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Support Vector Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(random_state = 42)\n",
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 MLP Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state = 42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.6 ADA Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(random_state = 42)\n",
    "ada.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.7 XG Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=42, ...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state = 42)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Evaluate and Improve the Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def model_scores_classification(model):\n",
    "    print(f\"Model: {model}\")\n",
    "    \n",
    "    train_pred = model.predict(X_train)\n",
    "    print(f'\\nTraining score: {model.score(X_train, y_train)}')\n",
    "\n",
    "    test_pred = model.predict(X_test)\n",
    "    print(f'Testing score: {model.score(X_test, y_test)}')\n",
    "    \n",
    "    print('\\nTest Report:')\n",
    "    print(classification_report(y_test, test_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, test_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix - Testing')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression(random_state=42)\n",
      "\n",
      "Training score: 0.728786926461345\n",
      "Testing score: 0.7206744868035191\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72      1389\n",
      "           1       0.71      0.74      0.72      1339\n",
      "\n",
      "    accuracy                           0.72      2728\n",
      "   macro avg       0.72      0.72      0.72      2728\n",
      "weighted avg       0.72      0.72      0.72      2728\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_scores_classification(lg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1.2 Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeClassifier(random_state=42)\n",
      "\n",
      "Training score: 1.0\n",
      "Testing score: 0.749266862170088\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      1389\n",
      "           1       0.74      0.75      0.74      1339\n",
      "\n",
      "    accuracy                           0.75      2728\n",
      "   macro avg       0.75      0.75      0.75      2728\n",
      "weighted avg       0.75      0.75      0.75      2728\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predictions\n",
    "model_scores_classification(dtree)\n",
    "\n",
    "# score is overfitted, due to the nature of dtrees? \n",
    "# print the tree the visualise\n",
    "# consider k-folds then gridsearch to get best params to improve the score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1.3 Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier(random_state=42)\n",
      "\n",
      "Training score: 1.0\n",
      "Testing score: 0.7936217008797654\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78      1389\n",
      "           1       0.75      0.87      0.80      1339\n",
      "\n",
      "    accuracy                           0.79      2728\n",
      "   macro avg       0.80      0.79      0.79      2728\n",
      "weighted avg       0.80      0.79      0.79      2728\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predictions\n",
    "model_scores_classification(rf)\n",
    "\n",
    "# similar outcome to dtree\n",
    "# plot the tree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1.4 Support Vector Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVC(random_state=42)\n",
      "\n",
      "Training score: 0.5339409176618479\n",
      "Testing score: 0.5370234604105572\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.71      0.61      1389\n",
      "           1       0.54      0.36      0.43      1339\n",
      "\n",
      "    accuracy                           0.54      2728\n",
      "   macro avg       0.54      0.53      0.52      2728\n",
      "weighted avg       0.54      0.54      0.52      2728\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAGDCAYAAAALVDiWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAb8ElEQVR4nO3deZxVdf348dd7ZlRQkE1AwCVQzNSvaKmZhYL6Tf2Vqa1a3xZcSNNSNGkxLU1b3L65kLmVmntuX80QFUXBLEFQFCzl68qiINtXkG2Yz++PewZHHIYB53I/A6/n4+GjmXPuPedz78S87vmcM/dGSglJkpSvqkoPQJIkNc1YS5KUOWMtSVLmjLUkSZkz1pIkZc5YS5KUOWMtraWIaBsR90XE/Ij4y4fYzjci4sGWHFslRMTwiPh2pcexpiKif0T8u9LjkJpirLXei4ivR8S4iFgQETOKqHymBTb9ZaA70CWl9JW13UhK6aaU0mdbYDzvExEDIiJFxF0rLe9XLB/VzO38IiJuXN3tUkqHpJSuX8vhrmrf/Yuf24KIWFiMe0GD/7ZZi22miNi+wbhHp5Q+2pLjllqasdZ6LSJOBX4H/IpSWLcBfg8c1gKb3xZ4MaVU2wLbKpdZwD4R0aXBsm8DL7bUDqKkLL9LipC2Sym1A3YuFnesX5ZSer0c+5VyY6y13oqIDsA5wIkppbtSSgtTSstSSvellE4vbrNJRPwuIqYX//0uIjYp1g2IiKkRcVpEzCyOygcV684GzgK+VhzhHbPyEWhEfKQ4iqspvv9ORLwcEe9ExCsR8Y0Gy8c0uN8+ETG2mF4fGxH7NFg3KiJ+GRFPFNt5MCK2aOJpWArcAxxZ3L8a+Cpw00rP1SUR8UZE/F9EPB0R/YvlBwM/bfA4n20wjvMi4gngXaBPsezYYv0VEXFHg+3/NiJGRkQ09+e3OhHRISKuLX4u0yLi3OLxERHbR8RjxXP4dkTcVix/vLj7s8Xj+Vr9z7nBdl+NiB9GxMTi/rdFRJsG64cW+5weEceufKQulYOx1vrsU0Ab4O4mbnMGsDewG9AP2Av4WYP1WwIdgF7AMcCwiOiUUvo5paP124ojvGubGkhEbAZcChySUmoP7AM808jtOgP3F7ftAlwM3L/SkfHXgUFAN2Bj4IdN7Ru4AfhW8fVBwCRg+kq3GUvpOegM3Az8JSLapJQeWOlx9mtwn28Cg4H2wGsrbe80YNfihUh/Ss/dt1PLvr/x9UAtsD2wO/BZ4Nhi3S+BB4FOwFbAZQAppX2L9f2Kx3PbKrb9VeBgoDewK/AdWPHi5VTgwGK/+7Xg45FWyVhrfdYFeHs109TfAM5JKc1MKc0CzqYUoXrLivXLUkp/AxYAa3t+sw7YJSLappRmpJQmNXKbzwEvpZT+nFKqTSndAvwLOLTBbf6UUnoxpbQIuJ1SZFcppfR3oHNEfJRStG9o5DY3ppRmF/u8CNiE1T/O61JKk4r7LFtpe+8C/0XpxcaNwPdTSlMb28jaiIjuwCHAKcWMyUzgvylmECj93LYFeqaUFqeUxqxiU6tyaUppekppDnAf7z3HX6X0/E8qHuPZH/axSM1hrLU+mw1sUT8NvQo9ef9R4WvFshXbWCn27wLt1nQgKaWFwNeA44EZEXF/ROzYjPHUj6lXg+/fXIvx/Bk4CRhIIzMNxVT/C8W07zxKswlNTa8DvNHUypTSU8DLQFB6UdGoiJjU4IKx/qvZZ71tgY0oPZfzijFfSWm2AWBosd+niu0f3czt1lvVc9yT9z/uJp8DqaUYa63PngQWA4c3cZvplH7x19uGD04RN9dCYNMG32/ZcGVKaURK6T+BHpSOlq9uxnjqxzRtLcdU78/A94C/FUeEKxSB/BGlo8ZOKaWOwHxKsQNY1dR1k1PaEXEipSP06ZTi2fhGUtq5wQVjo5vxWKAUySXAFimljsV/m6eUdi62+WZK6biUUk/gu8DvW+i88gxK0+r1tm6BbUqrZay13kopzad0EdiwiDg8IjaNiI0i4pCIOL+42S3AzyKia3Gh1lmUpm3XxjPAvhGxTZQubvtJ/YqI6B4RXyjOXS+hNJ2+vJFt/A3YIUp/blYTEV8DdgL+upZjAiCl9Aql86tnNLK6PaVzv7OAmog4C9i8wfq3gI/EGlzxHRE7AOdSmgr/JjA0InZbu9F/UEppBqVz0hdFxOYRURUR20XEfsX+vxIR9VGdS+mFRf3z/RbQZy13fTswKCI+FhGbUvr/i1R2xlrrtZTSxZQuCPoZpRi9QWk6+J7iJucC44CJwHPA+GLZ2uzrIeC2YltP8/7AVlG66Go6MIdSOL/XyDZmA58vbjub0hHp51NKb6/NmFba9piUUmOzBiOA4ZT+nOs1SrMRDad369/wZXZEjF/dforTDjcCv00pPZtSeonSFeV/juJK+xbyLUoX2E2mFOQ7KM1aAOwJ/DMiFgD3AicXL1gAfgFcX0yff3VNdphSGk7p4r9HgSmUZm+g9AJMKpto2YszJWnDEREfA54HNsn87+3VynlkLUlrICKOiIiNI6IT8FvgPkOtcjPWkrRmvkvplMr/UjoPfkJlh6MNgdPgkiRlziNrSZIyZ6wlScpcU+/sVFFtdz/J+XmpAuaOvbzSQ5A2WG1qaPTDbjyyliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJypyxliQpc8ZakqTMGWtJkjJnrCVJylxNpQeg1unEowYw6Iv7EBH86a4nuPzmUey6Qy8uO+NINtlkI2qX13HKr25j3KTXANilb08u/9lRtN+sDXV1ic/81/ksWVpb4UchtU7Lly/nqK9+iW7du3P5769k/rx5DP3hEKZPm0bPXr244KLfsXmHDjw3cSK//MWZAKSUOP7E73PAgf9Z4dFrbRhrrbGdtuvBoC/uQ/9vXsDSZcu5d9j3GD5mEuedcjjnXTWcB5+YzEGf2YnzTjmcg467hOrqKv547rc55swbeO7FaXTusBnLapdX+mFIrdZNf76BPn22Y8HCBQD88Zqr2OuTn+KY4wZz7dVXce01VzHktNPZvm9fbr79Tmpqapg1ayZf+eJh7DdgIDU1/upvbZwG1xrbsfeWPPXcqyxavIzly+sY/fQUDhvYj5Rg883aANChXVtmzJoPwIGf2pHnX5rGcy9OA2DO/IXU1aWKjV9qzd56801GPz6KI7705RXLHn10JF84/HAAvnD44Tz6yMMAtG3bdkWYlyxZQkSs8/GqZZTt5VVE7AgcBvQCEjAduDel9EK59ql1Y9L/TucXJx1K5w6bsWjJUg7+zM6Mn/w6p194B/cNO5FfDzmCqqpg4HcuAqDvNt1ICe4ddiJbdGrHHSOe5uLrH67wo5Bap/N/8yuGnHY6CxcuXLFszuzZdO3aDYCuXbsxZ86cFesmTnyWn//sp8yYPp3zfnO+R9WtVFmOrCPiR8CtQABPAWOLr2+JiB83cb/BETEuIsbVvj2pHENTC/j3K29x0XUP8dcrTuLeYScy8cVp1NYuZ/BX+jP0orvoe8iZDL3wTq74+TcAqKmuZp/d+zDojOs44OiL+cL+/Riw1w4VfhRS6/PYqEfp3LkzO+28S7Pvs+uu/bj73vu5+bY7uPbqK1myZEkZR6hyKddLrGOAnVNKyxoujIiLgUnAbxq7U0rpKuAqgLa7n+Q8acauv+dJrr/nSQDOPulQpr01j3O+/wVOO/8OAO58aAK/P+vrAEybOY/RT09h9rzSkcADYyax+45bM+qpFyszeKmVembCeEaNeoQxox9nyZIlLFy4gJ/86Id07tKFWbNm0rVrN2bNmknnzp0/cN8+221H27ZtmfLSi+y8y39UYPT6MMp1zroO6NnI8h7FOrVyXTu1A2DrLTtx2P79uP2BccyYNZ/+n+gLwIC9dmDK67MAeOjvk9mlby/attmI6uoq+n9ie154+c2KjV1qrU4echoPPfI4wx96hN9eeDF7fnJvfv3bCxkwcH/uveceAO695x4GDjwAgKlT36C2tvRXF9OnT+O1V1+hZ69elRq+PoRyHVmfAoyMiJeAN4pl2wDbAyeVaZ9ah2658Fg6dyxd1X3Kb25n3juLOPGXN3PB6V+mpqaKJUtqOencWwCY984iLr3xEcbcOJSUEiPGTOKBMZ7mkFrK0ccO5vRTT+Geu+5gyx49uPDiSwCYMP5p/njN1WxUU0NUVfHTM39Bp04fPOpW/iKl8sw2R0QVsBelC8wCmAqMTSk16292nAaXKmPu2MsrPQRpg9WmhkYv2S/bZYEppTrgH+XaviRJGwr/zlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKXM2qVkTEZUBa1fqU0g/KMiJJkvQ+q4w1MG6djUKSJK3SKmOdUrp+XQ5EkiQ1rqkjawAioivwI2AnoE398pTS/mUclyRJKjTnArObgBeA3sDZwKvA2DKOSZIkNdCcWHdJKV0LLEspPZZSOhrYu8zjkiRJhdVOgwPLiv+dERGfA6YDW5VvSJIkqaHmxPrciOgAnAZcBmwODCnrqCRJ0gqrjXVK6a/Fl/OBgeUdjiRJWllzrgb/E428OUpx7lqSJJVZc6bB/9rg6zbAEZTOW0uSpHWgOdPgdzb8PiJuAR4u24gkSdL7rM0HefQFtmnpgUiSpMY155z1O7z/nPWblN7RrKw6731AuXchqRHT5y6u9BCkDVafrm0aXd6cafD2LT4aSZLUbKudBo+Ikc1ZJkmSyqOpz7NuA2wKbBERnYAoVm0O9FwHY5MkSTQ9Df5d4BRKYX6a92L9f8Cw8g5LkiTVa+rzrC8BLomI76eULluHY5IkSQ0050+36iKiY/03EdEpIr5XviFJkqSGmhPr41JK8+q/SSnNBY4r24gkSdL7NCfWVRFRf76aiKgGNi7fkCRJUkPNeW/wEcDtEfEHSm+OcjwwvKyjkiRJKzQn1j8CBgMnULoifALQo5yDkiRJ71ntNHhKqQ74B/AysAdwAPBCmcclSZIKTb0pyg7AkcBRwGzgNoCU0sB1MzRJkgRNT4P/CxgNHJpSmgIQEUPWyagkSdIKTU2Df4nSJ2w9GhFXR8QBvPcuZpIkaR1ZZaxTSnenlL4G7AiMAoYA3SPiioj47DoanyRJG7zmXGC2MKV0U0rp88BWwDPAj8s9MEmSVNKcN0VZIaU0J6V0ZUpp/3INSJIkvd8axVqSJK17xlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMmesJUnKnLGWJClzxlqSpMwZa0mSMldT6QGodTpu/+046tMfIQH/mjafU28Yz5LaOgYN6MOgAX2oXZ4Y+fybnHf3JABOOmgHjtxnW+pS4szbJvLYCzMr+wCkVmz58uX84Nij2KJrN84+/3J+fdbpTH39NQAWLHiHdu3aM+y621m2bBmXXXAOL/1rMhFVHH/yUHb9+J4VHr3WhrHWGtuyQxuOHrgdA895mMXL6vjDsXty2B5bMXXOuxzUrwcHnvsIS2vr6NJ+YwD6btmew/bYiv1/OZLuHdpw68mfpv/PH6IuVfiBSK3U//zlJrbZtg/vvrsAgJ+cc8GKdVdfdiGbtmsHwAP33gnAFTfcyby5sznztBO55JqbqapyUrW18SemtVJTFbTZqJrqqqDtxjW8OX8x39q3N8NGvMjS2joAZr+zFICD+vXgf8ZNZWltHW/MfpdXZy1k9490ruTwpVZr1sy3eOrJ0Rx06BEfWJdS4vFHH2TAgYcA8PqrL7PbJz4JQMdOXdisfXte+tekdTpetQxjrTX25vzF/OHhKTx13sFM+M0h/N+iZTz+wkz6dGvHXtt34b6h+3HHkP7027YjAFt2bMP0uYtW3H/G3EVs2bFNhUYvtW5XXno+x5wwhKr44K/v558dT6dOXei19bYA9N5+B54cPYrltbW8OX0qU/79ArNmvrWOR6yWsM5jHRGDmlg3OCLGRcS4hZMfXJfD0hrosOlGHNSvB3ufOYKP/3g4m25czRf32prq6io6bLoxh57/GOfe9Tx/OHYvACLiA9twBlxac/984jE6duxM3x13anT9qIeHs9+BB6/4/qDPHc4W3brzg2O/zpWXXsDHdulHdXX1uhquWlAlzlmfDfypsRUppauAqwB6nXC3v88z1X/Hrrz+9kLmLChNcw9/Zjp79OnMjLmLGD5hOgDPvDaXupTo3G5jZsxdRM9ObVfcv0entrw1b3FFxi61ZpOfe4Z/PDGKsf8Yw7KlS3h34ULOP+cnDD3r1yyvreXvj43k0mtvXXH76poavvuD01d8f+rx36LnVttUYuj6kMoS64iYuKpVQPdy7FPrzrQ5i/h478602aiaxcuW85kdu/Hsa3N5Ydp8Pv3Rrjz50tv06daOjaurmLNgKQ9OnMGwo/fkqpFT6N6hDb27tWPCq3Mq/TCkVmfQ8Scz6PiTAZg4fix33no9Q8/6NQATxv2TrbbtTddu7/2KXbx4EaREm7abMn7sk1RXV7Nt7+0qMnZ9OOU6su4OHATMXWl5AH8v0z61jkx4dS73T5jGiJ8OpLYuMemNedw05lVSSlz0zY8z8swDWFZbxyk3PA3AizPe4b6np/LoWQewvC5xxq3PeiW41MIeG/kAAxpMgQPMnzuHM049gaqqKrps0Y0fnnlehUanDytSavnfmhFxLfCnlNKYRtbdnFL6+uq24TS4VBmjzzmk0kOQNlh9urb54EU+lOnIOqV0TBPrVhtqSZL0Hv90S5KkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXPGWpKkzBlrSZIyZ6wlScqcsZYkKXORUqr0GLQeiojBKaWrKj0OaUPjv731k0fWKpfBlR6AtIHy3956yFhLkpQ5Yy1JUuaMtcrFc2ZSZfhvbz3kBWaSJGXOI2tJkjJnrNWiIuLgiPh3REyJiB9XejzShiIi/hgRMyPi+UqPRS3PWKvFREQ1MAw4BNgJOCoidqrsqKQNxnXAwZUehMrDWKsl7QVMSSm9nFJaCtwKHFbhMUkbhJTS48CcSo9D5WGs1ZJ6AW80+H5qsUyS9CEYa7WkaGSZf24gSR+SsVZLmgps3eD7rYDpFRqLJK03jLVa0ligb0T0joiNgSOBeys8Jklq9Yy1WkxKqRY4CRgBvADcnlKaVNlRSRuGiLgFeBL4aERMjYhjKj0mtRzfwUySpMx5ZC1JUuaMtSRJmTPWkiRlzlhLkpQ5Yy1JUuaMtdRKRcTyiHgmIp6PiL9ExKYfYlvXRcSXi6+vaeoDWCJiQETssxb7eDUitljbMUobMmMttV6LUkq7pZR2AZYCxzdcWXwK2hpLKR2bUprcxE0GAGsca0lrz1hL64fRwPbFUe+jEXEz8FxEVEfEBRExNiImRsR3AaLk8oiYHBH3A93qNxQRoyJij+LrgyNifEQ8GxEjI+IjlF4UDCmO6vtHRNeIuLPYx9iI+HRx3y4R8WBETIiIK2n8veMlNUNNpQcg6cOJiBpKnyH+QLFoL2CXlNIrETEYmJ9S2jMiNgGeiIgHgd2BjwL/AXQHJgN/XGm7XYGrgX2LbXVOKc2JiD8AC1JKFxa3uxn475TSmIjYhtI72H0M+DkwJqV0TkR8Dhhc1idCWo8Za6n1ahsRzxRfjwaupTQ9/VRK6ZVi+WeBXevPRwMdgL7AvsAtKaXlwPSIeKSR7e8NPF6/rZTSqj4r+UBgp4gVB86bR0T7Yh9fLO57f0TMXbuHKclYS63XopTSbg0XFMFc2HAR8P2U0oiVbvf/WP3Hl0YzbgOl02mfSiktamQsvp+x1AI8Zy2t30YAJ0TERgARsUNEbAY8DhxZnNPuAQxs5L5PAvtFRO/ivp2L5e8A7Rvc7kFKH+BCcbvdii8fB75RLDsE6NRSD0ra0Bhraf12DaXz0eMj4nngSkozancDLwHPAVcAj618x5TSLErnme+KiGeB24pV9wFH1F9gBvwA2KO4gG0y712Vfjawb0SMpzQd/3qZHqO03vNTtyRJypxH1pIkZc5YS5KUOWMtSVLmjLUkSZkz1pIkZc5YS5KUOWMtSVLmjLUkSZn7/yWa7wJMvmIVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_scores_classification(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1.5 MLP Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MLPClassifier(random_state=42)\n",
      "\n",
      "Training score: 0.6638906348208674\n",
      "Testing score: 0.6686217008797654\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.84      0.72      1389\n",
      "           1       0.75      0.49      0.59      1339\n",
      "\n",
      "    accuracy                           0.67      2728\n",
      "   macro avg       0.69      0.67      0.66      2728\n",
      "weighted avg       0.69      0.67      0.66      2728\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_scores_classification(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1.6 ADA Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AdaBoostClassifier(random_state=42)\n",
      "\n",
      "Training score: 0.7820553111250785\n",
      "Testing score: 0.7694281524926686\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1389\n",
      "           1       0.75      0.79      0.77      1339\n",
      "\n",
      "    accuracy                           0.77      2728\n",
      "   macro avg       0.77      0.77      0.77      2728\n",
      "weighted avg       0.77      0.77      0.77      2728\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_scores_classification(ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1.7 XG Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=42, ...)\n",
      "\n",
      "Training score: 0.9335323695788812\n",
      "Testing score: 0.7994868035190615\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.75      0.79      1389\n",
      "           1       0.77      0.85      0.81      1339\n",
      "\n",
      "    accuracy                           0.80      2728\n",
      "   macro avg       0.80      0.80      0.80      2728\n",
      "weighted avg       0.80      0.80      0.80      2728\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_scores_classification(xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Model Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2.1 Consolidated View of Baseline Model Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.728787</td>\n",
       "      <td>0.720674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.749267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.793622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.533941</td>\n",
       "      <td>0.537023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP (ANN)</td>\n",
       "      <td>0.663891</td>\n",
       "      <td>0.668622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADA</td>\n",
       "      <td>0.782055</td>\n",
       "      <td>0.769428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.933532</td>\n",
       "      <td>0.799487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Train Score  Test Score\n",
       "0        LogReg     0.728787    0.720674\n",
       "1         DTree     1.000000    0.749267\n",
       "2  RandomForest     1.000000    0.793622\n",
       "3           SVC     0.533941    0.537023\n",
       "4     MLP (ANN)     0.663891    0.668622\n",
       "5           ADA     0.782055    0.769428\n",
       "6           XGB     0.933532    0.799487"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [lg, dtree, rf,svc, mlp, ada,xgb]\n",
    "\n",
    "\n",
    "model_names = ['LogReg', 'DTree', 'RandomForest', 'SVC', 'MLP (ANN)', 'ADA','XGB']\n",
    "\n",
    "scores_table = []\n",
    "for model, name in zip(models, model_names):\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    scores_table.append([name, train_score, test_score])\n",
    "\n",
    "df_scores = pd.DataFrame(scores_table, columns=[\"Model\", \"Train Score\", \"Test Score\"])\n",
    "\n",
    "df_scores\n",
    "\n",
    "# for ada and xgb, create all the other models first before putting in base estimators \n",
    "# choosing models \n",
    "# logreg \n",
    "# random forest \n",
    "# boosting models \n",
    "# bagging classifier \n",
    "# stacking classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty' : ['l1','l2','elasticnet',None],\n",
    "              'C' : [0.2,0.5,0.8,1], # lower C - underfit, higher C - overfit \n",
    "              'solver' : ['lbfgs','saga','sag','liblinear'],\n",
    "              'max_iter' : [1000,1500,2000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=lg, param_grid=param_grid, scoring='accuracy',verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "[CV 1/5] END C=0.2, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=1000, penalty=l1, solver=saga;, score=0.590 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=1000, penalty=l1, solver=saga;, score=0.603 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=1000, penalty=l1, solver=saga;, score=0.597 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=1000, penalty=l1, solver=saga;, score=0.554 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=1000, penalty=l1, solver=saga;, score=0.579 total time=   1.7s\n",
      "[CV 1/5] END C=0.2, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1000, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1000, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1000, penalty=l1, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1000, penalty=l1, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1000, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.768 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.760 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.777 total time=   0.1s\n",
      "[CV 5/5] END C=0.2, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=1000, penalty=l2, solver=saga;, score=0.592 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=1000, penalty=l2, solver=saga;, score=0.603 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=1000, penalty=l2, solver=saga;, score=0.596 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=1000, penalty=l2, solver=saga;, score=0.554 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=1000, penalty=l2, solver=saga;, score=0.579 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=1000, penalty=l2, solver=sag;, score=0.628 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=1000, penalty=l2, solver=sag;, score=0.629 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=1000, penalty=l2, solver=sag;, score=0.641 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=1000, penalty=l2, solver=sag;, score=0.589 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=1000, penalty=l2, solver=sag;, score=0.618 total time=   1.4s\n",
      "[CV 1/5] END C=0.2, max_iter=1000, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1000, penalty=l2, solver=liblinear;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1000, penalty=l2, solver=liblinear;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1000, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1000, penalty=l2, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=1500, penalty=l1, solver=saga;, score=0.616 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=1500, penalty=l1, solver=saga;, score=0.610 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=1500, penalty=l1, solver=saga;, score=0.619 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=1500, penalty=l1, solver=saga;, score=0.569 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=1500, penalty=l1, solver=saga;, score=0.601 total time=   3.1s\n",
      "[CV 1/5] END C=0.2, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1500, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1500, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1500, penalty=l1, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1500, penalty=l1, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1500, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.768 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.760 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.777 total time=   0.1s\n",
      "[CV 5/5] END C=0.2, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=1500, penalty=l2, solver=saga;, score=0.617 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=1500, penalty=l2, solver=saga;, score=0.610 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=1500, penalty=l2, solver=saga;, score=0.620 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=1500, penalty=l2, solver=saga;, score=0.568 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=1500, penalty=l2, solver=saga;, score=0.602 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=1500, penalty=l2, solver=sag;, score=0.663 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=1500, penalty=l2, solver=sag;, score=0.627 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=1500, penalty=l2, solver=sag;, score=0.653 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=1500, penalty=l2, solver=sag;, score=0.612 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=1500, penalty=l2, solver=sag;, score=0.639 total time=   2.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1500, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1500, penalty=l2, solver=liblinear;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1500, penalty=l2, solver=liblinear;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1500, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1500, penalty=l2, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=2000, penalty=l1, solver=saga;, score=0.627 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=2000, penalty=l1, solver=saga;, score=0.630 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=2000, penalty=l1, solver=saga;, score=0.638 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=2000, penalty=l1, solver=saga;, score=0.588 total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=2000, penalty=l1, solver=saga;, score=0.617 total time=   3.4s\n",
      "[CV 1/5] END C=0.2, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=2000, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=2000, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=2000, penalty=l1, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=2000, penalty=l1, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=2000, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.768 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.760 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.777 total time=   0.1s\n",
      "[CV 5/5] END C=0.2, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=2000, penalty=l2, solver=saga;, score=0.628 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=2000, penalty=l2, solver=saga;, score=0.629 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=2000, penalty=l2, solver=saga;, score=0.641 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=2000, penalty=l2, solver=saga;, score=0.589 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=2000, penalty=l2, solver=saga;, score=0.618 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=2000, penalty=l2, solver=sag;, score=0.665 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=2000, penalty=l2, solver=sag;, score=0.625 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=2000, penalty=l2, solver=sag;, score=0.661 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=2000, penalty=l2, solver=sag;, score=0.625 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=2000, penalty=l2, solver=sag;, score=0.659 total time=   2.7s\n",
      "[CV 1/5] END C=0.2, max_iter=2000, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=2000, penalty=l2, solver=liblinear;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=2000, penalty=l2, solver=liblinear;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=2000, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=2000, penalty=l2, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.589 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.602 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.596 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.554 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.579 total time=   1.5s\n",
      "[CV 1/5] END C=0.5, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1000, penalty=l1, solver=liblinear;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1000, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1000, penalty=l1, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1000, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1000, penalty=l1, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.767 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.781 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.1s\n",
      "[CV 5/5] END C=0.5, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=1000, penalty=l2, solver=saga;, score=0.592 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=1000, penalty=l2, solver=saga;, score=0.603 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=1000, penalty=l2, solver=saga;, score=0.596 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=1000, penalty=l2, solver=saga;, score=0.554 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=1000, penalty=l2, solver=saga;, score=0.579 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=1000, penalty=l2, solver=sag;, score=0.628 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=1000, penalty=l2, solver=sag;, score=0.629 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=1000, penalty=l2, solver=sag;, score=0.641 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=1000, penalty=l2, solver=sag;, score=0.589 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=1000, penalty=l2, solver=sag;, score=0.618 total time=   1.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1000, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1000, penalty=l2, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1000, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1000, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1000, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=1500, penalty=l1, solver=saga;, score=0.616 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=1500, penalty=l1, solver=saga;, score=0.610 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=1500, penalty=l1, solver=saga;, score=0.619 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=1500, penalty=l1, solver=saga;, score=0.568 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=1500, penalty=l1, solver=saga;, score=0.602 total time=   2.6s\n",
      "[CV 1/5] END C=0.5, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1500, penalty=l1, solver=liblinear;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1500, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1500, penalty=l1, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1500, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1500, penalty=l1, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.767 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.781 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.1s\n",
      "[CV 5/5] END C=0.5, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=1500, penalty=l2, solver=saga;, score=0.617 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=1500, penalty=l2, solver=saga;, score=0.610 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=1500, penalty=l2, solver=saga;, score=0.620 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=1500, penalty=l2, solver=saga;, score=0.568 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=1500, penalty=l2, solver=saga;, score=0.602 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=1500, penalty=l2, solver=sag;, score=0.663 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=1500, penalty=l2, solver=sag;, score=0.627 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=1500, penalty=l2, solver=sag;, score=0.653 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=1500, penalty=l2, solver=sag;, score=0.612 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=1500, penalty=l2, solver=sag;, score=0.639 total time=   1.6s\n",
      "[CV 1/5] END C=0.5, max_iter=1500, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1500, penalty=l2, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1500, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1500, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1500, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=2000, penalty=l1, solver=saga;, score=0.628 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=2000, penalty=l1, solver=saga;, score=0.629 total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=2000, penalty=l1, solver=saga;, score=0.639 total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=2000, penalty=l1, solver=saga;, score=0.589 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=2000, penalty=l1, solver=saga;, score=0.617 total time=   3.6s\n",
      "[CV 1/5] END C=0.5, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=2000, penalty=l1, solver=liblinear;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=2000, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=2000, penalty=l1, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=2000, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=2000, penalty=l1, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.767 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.781 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.1s\n",
      "[CV 5/5] END C=0.5, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=2000, penalty=l2, solver=saga;, score=0.628 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=2000, penalty=l2, solver=saga;, score=0.629 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=2000, penalty=l2, solver=saga;, score=0.641 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=2000, penalty=l2, solver=saga;, score=0.589 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=2000, penalty=l2, solver=saga;, score=0.618 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=2000, penalty=l2, solver=sag;, score=0.665 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=2000, penalty=l2, solver=sag;, score=0.625 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=2000, penalty=l2, solver=sag;, score=0.661 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=2000, penalty=l2, solver=sag;, score=0.625 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=2000, penalty=l2, solver=sag;, score=0.659 total time=   2.6s\n",
      "[CV 1/5] END C=0.5, max_iter=2000, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=2000, penalty=l2, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=2000, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=2000, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=2000, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=1000, penalty=l1, solver=saga;, score=0.591 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=1000, penalty=l1, solver=saga;, score=0.603 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=1000, penalty=l1, solver=saga;, score=0.596 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=1000, penalty=l1, solver=saga;, score=0.554 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=1000, penalty=l1, solver=saga;, score=0.579 total time=   1.4s\n",
      "[CV 1/5] END C=0.8, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1000, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1000, penalty=l1, solver=liblinear;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1000, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1000, penalty=l1, solver=liblinear;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1000, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.693 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.781 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.707 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.777 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=1000, penalty=l2, solver=saga;, score=0.592 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=1000, penalty=l2, solver=saga;, score=0.603 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=1000, penalty=l2, solver=saga;, score=0.596 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=1000, penalty=l2, solver=saga;, score=0.554 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=1000, penalty=l2, solver=saga;, score=0.579 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=1000, penalty=l2, solver=sag;, score=0.628 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=1000, penalty=l2, solver=sag;, score=0.629 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=1000, penalty=l2, solver=sag;, score=0.641 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=1000, penalty=l2, solver=sag;, score=0.589 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=1000, penalty=l2, solver=sag;, score=0.618 total time=   1.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1000, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1000, penalty=l2, solver=liblinear;, score=0.775 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1000, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1000, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1000, penalty=l2, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=1500, penalty=l1, solver=saga;, score=0.616 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=1500, penalty=l1, solver=saga;, score=0.610 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=1500, penalty=l1, solver=saga;, score=0.620 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=1500, penalty=l1, solver=saga;, score=0.568 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=1500, penalty=l1, solver=saga;, score=0.603 total time=   2.8s\n",
      "[CV 1/5] END C=0.8, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1500, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1500, penalty=l1, solver=liblinear;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1500, penalty=l1, solver=liblinear;, score=0.796 total time=   0.1s\n",
      "[CV 4/5] END C=0.8, max_iter=1500, penalty=l1, solver=liblinear;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1500, penalty=l1, solver=liblinear;, score=0.796 total time=   0.1s\n",
      "[CV 1/5] END C=0.8, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.693 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.781 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.707 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.777 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=1500, penalty=l2, solver=saga;, score=0.617 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=1500, penalty=l2, solver=saga;, score=0.610 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=1500, penalty=l2, solver=saga;, score=0.620 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=1500, penalty=l2, solver=saga;, score=0.568 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=1500, penalty=l2, solver=saga;, score=0.602 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=1500, penalty=l2, solver=sag;, score=0.663 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=1500, penalty=l2, solver=sag;, score=0.627 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=1500, penalty=l2, solver=sag;, score=0.653 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=1500, penalty=l2, solver=sag;, score=0.612 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=1500, penalty=l2, solver=sag;, score=0.639 total time=   1.9s\n",
      "[CV 1/5] END C=0.8, max_iter=1500, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1500, penalty=l2, solver=liblinear;, score=0.775 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1500, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1500, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1500, penalty=l2, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=2000, penalty=l1, solver=saga;, score=0.628 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=2000, penalty=l1, solver=saga;, score=0.629 total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=2000, penalty=l1, solver=saga;, score=0.639 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=2000, penalty=l1, solver=saga;, score=0.589 total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=2000, penalty=l1, solver=saga;, score=0.617 total time=   3.3s\n",
      "[CV 1/5] END C=0.8, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=2000, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=2000, penalty=l1, solver=liblinear;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=2000, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=2000, penalty=l1, solver=liblinear;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=2000, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.693 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.781 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.707 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.777 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=2000, penalty=l2, solver=saga;, score=0.628 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=2000, penalty=l2, solver=saga;, score=0.629 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=2000, penalty=l2, solver=saga;, score=0.641 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=2000, penalty=l2, solver=saga;, score=0.589 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=2000, penalty=l2, solver=saga;, score=0.618 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=2000, penalty=l2, solver=sag;, score=0.665 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=2000, penalty=l2, solver=sag;, score=0.625 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=2000, penalty=l2, solver=sag;, score=0.661 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=2000, penalty=l2, solver=sag;, score=0.625 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=2000, penalty=l2, solver=sag;, score=0.659 total time=   2.1s\n",
      "[CV 1/5] END C=0.8, max_iter=2000, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=2000, penalty=l2, solver=liblinear;, score=0.775 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=2000, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=2000, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=2000, penalty=l2, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=1000, penalty=l1, solver=saga;, score=0.591 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=1000, penalty=l1, solver=saga;, score=0.603 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=1000, penalty=l1, solver=saga;, score=0.596 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=1000, penalty=l1, solver=saga;, score=0.554 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=1000, penalty=l1, solver=saga;, score=0.579 total time=   1.5s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.703 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.767 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.775 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.720 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.592 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.603 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.596 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.554 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.579 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.628 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.629 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.641 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.589 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.618 total time=   1.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.779 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=1500, penalty=l1, solver=saga;, score=0.616 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=1500, penalty=l1, solver=saga;, score=0.610 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=1500, penalty=l1, solver=saga;, score=0.620 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=1500, penalty=l1, solver=saga;, score=0.568 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=1500, penalty=l1, solver=saga;, score=0.603 total time=   2.2s\n",
      "[CV 1/5] END C=1, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1500, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1500, penalty=l1, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1500, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1500, penalty=l1, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1500, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.703 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.767 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.775 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=1500, penalty=l2, solver=lbfgs;, score=0.720 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=1500, penalty=l2, solver=saga;, score=0.617 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=1500, penalty=l2, solver=saga;, score=0.610 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=1500, penalty=l2, solver=saga;, score=0.620 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=1500, penalty=l2, solver=saga;, score=0.568 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=1500, penalty=l2, solver=saga;, score=0.602 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=1500, penalty=l2, solver=sag;, score=0.663 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=1500, penalty=l2, solver=sag;, score=0.627 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=1500, penalty=l2, solver=sag;, score=0.653 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=1500, penalty=l2, solver=sag;, score=0.612 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=1500, penalty=l2, solver=sag;, score=0.639 total time=   1.6s\n",
      "[CV 1/5] END C=1, max_iter=1500, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1500, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1500, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1500, penalty=l2, solver=liblinear;, score=0.779 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1500, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1500, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1500, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1500, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1500, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=2000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=2000, penalty=l1, solver=saga;, score=0.628 total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=2000, penalty=l1, solver=saga;, score=0.629 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=2000, penalty=l1, solver=saga;, score=0.639 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=2000, penalty=l1, solver=saga;, score=0.589 total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=2000, penalty=l1, solver=saga;, score=0.618 total time=   3.0s\n",
      "[CV 1/5] END C=1, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=2000, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=2000, penalty=l1, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=2000, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=2000, penalty=l1, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=2000, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.703 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.767 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.779 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.775 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=2000, penalty=l2, solver=lbfgs;, score=0.720 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=2000, penalty=l2, solver=saga;, score=0.628 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=2000, penalty=l2, solver=saga;, score=0.629 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=2000, penalty=l2, solver=saga;, score=0.641 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=2000, penalty=l2, solver=saga;, score=0.589 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=2000, penalty=l2, solver=saga;, score=0.618 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=2000, penalty=l2, solver=sag;, score=0.665 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=2000, penalty=l2, solver=sag;, score=0.625 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=2000, penalty=l2, solver=sag;, score=0.661 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=2000, penalty=l2, solver=sag;, score=0.625 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "600 fits failed out of a total of 960.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.58437999        nan 0.78708493 0.77247118 0.58469421\n",
      " 0.6209926  0.78174285        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.60292245\n",
      "        nan 0.78708493 0.77247118 0.6033939  0.63874928 0.78174285\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.61989272        nan 0.78708493\n",
      " 0.77247118 0.6209926  0.64676493 0.78174285        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.58390866        nan 0.78645613 0.76131631 0.58469421\n",
      " 0.6209926  0.78582744        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.60292258\n",
      "        nan 0.78645613 0.76131631 0.6033939  0.63874928 0.78582744\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.62052115        nan 0.78645613\n",
      " 0.76131631 0.62114971 0.64676493 0.78582744        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.58437999        nan 0.78771349 0.74576225 0.58469421\n",
      " 0.6209926  0.78567058        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.60323692\n",
      "        nan 0.78771349 0.74576225 0.6033939  0.63874928 0.78567058\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.62052115        nan 0.78771349\n",
      " 0.74576225 0.62114971 0.64676493 0.78567058        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.58437999        nan 0.78708506 0.74873843 0.58469421\n",
      " 0.6209926  0.78551396        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.60323692\n",
      "        nan 0.78708506 0.74873843 0.6033939  0.63874928 0.78551396\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.62067839        nan 0.78708506\n",
      " 0.74873843 0.62114971 0.64676493 0.78551396        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=2000, penalty=l2, solver=sag;, score=0.659 total time=   2.0s\n",
      "[CV 1/5] END C=1, max_iter=2000, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=2000, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=2000, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=2000, penalty=l2, solver=liblinear;, score=0.779 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=2000, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=2000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=2000, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=2000, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=2000, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=2000, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={'C': [0.2, 0.5, 0.8, 1],\n",
       "                         'max_iter': [1000, 1500, 2000],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
       "                         'solver': ['lbfgs', 'saga', 'sag', 'liblinear']},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7877134931104163\n",
      "{'C': 0.8, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lower range of max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty' : ['l1','l2','elasticnet',None],\n",
    "              'C' : [0.2,0.5,0.8,1], # lower C - underfit, higher C - overfit \n",
    "              'solver' : ['lbfgs','saga','sag','liblinear'],\n",
    "              'max_iter' : [100,100,200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=lg, param_grid=param_grid, scoring='accuracy',verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=l1, solver=saga;, score=0.514 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=100, penalty=l1, solver=saga;, score=0.515 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=100, penalty=l1, solver=saga;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=l1, solver=saga;, score=0.506 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=100, penalty=l1, solver=saga;, score=0.509 total time=   0.1s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=l1, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=l1, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=l2, solver=lbfgs;, score=0.701 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=l2, solver=lbfgs;, score=0.753 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=l2, solver=lbfgs;, score=0.731 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=100, penalty=l2, solver=lbfgs;, score=0.722 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=l2, solver=lbfgs;, score=0.742 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=100, penalty=l2, solver=saga;, score=0.514 total time=   0.1s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=l2, solver=saga;, score=0.516 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=100, penalty=l2, solver=saga;, score=0.516 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=l2, solver=saga;, score=0.506 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=100, penalty=l2, solver=saga;, score=0.509 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=l2, solver=sag;, score=0.527 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=100, penalty=l2, solver=sag;, score=0.533 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=l2, solver=sag;, score=0.532 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=100, penalty=l2, solver=sag;, score=0.513 total time=   0.1s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=l2, solver=sag;, score=0.528 total time=   0.1s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=100, penalty=l2, solver=liblinear;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=l2, solver=liblinear;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=l2, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=100, penalty=l1, solver=saga;, score=0.514 total time=   0.1s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=l1, solver=saga;, score=0.515 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=100, penalty=l1, solver=saga;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=l1, solver=saga;, score=0.506 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=100, penalty=l1, solver=saga;, score=0.509 total time=   0.1s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=l1, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=l1, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=l2, solver=lbfgs;, score=0.701 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=l2, solver=lbfgs;, score=0.753 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=l2, solver=lbfgs;, score=0.731 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=100, penalty=l2, solver=lbfgs;, score=0.722 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=l2, solver=lbfgs;, score=0.742 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=100, penalty=l2, solver=saga;, score=0.514 total time=   0.1s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=l2, solver=saga;, score=0.516 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=100, penalty=l2, solver=saga;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=l2, solver=saga;, score=0.506 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=100, penalty=l2, solver=saga;, score=0.509 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=l2, solver=sag;, score=0.527 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=100, penalty=l2, solver=sag;, score=0.533 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=l2, solver=sag;, score=0.532 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=100, penalty=l2, solver=sag;, score=0.513 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=l2, solver=sag;, score=0.528 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=l2, solver=liblinear;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=l2, solver=liblinear;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=l2, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=200, penalty=l1, solver=saga;, score=0.528 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=200, penalty=l1, solver=saga;, score=0.533 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=200, penalty=l1, solver=saga;, score=0.532 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=200, penalty=l1, solver=saga;, score=0.514 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=200, penalty=l1, solver=saga;, score=0.528 total time=   0.2s\n",
      "[CV 1/5] END C=0.2, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=200, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=200, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=200, penalty=l1, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=200, penalty=l1, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=200, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=200, penalty=l2, solver=lbfgs;, score=0.720 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=200, penalty=l2, solver=lbfgs;, score=0.760 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=200, penalty=l2, solver=lbfgs;, score=0.756 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=200, penalty=l2, solver=lbfgs;, score=0.756 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=200, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=200, penalty=l2, solver=saga;, score=0.527 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=200, penalty=l2, solver=saga;, score=0.533 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=200, penalty=l2, solver=saga;, score=0.532 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=200, penalty=l2, solver=saga;, score=0.513 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=200, penalty=l2, solver=saga;, score=0.528 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, max_iter=200, penalty=l2, solver=sag;, score=0.544 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, max_iter=200, penalty=l2, solver=sag;, score=0.554 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, max_iter=200, penalty=l2, solver=sag;, score=0.555 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, max_iter=200, penalty=l2, solver=sag;, score=0.524 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, max_iter=200, penalty=l2, solver=sag;, score=0.546 total time=   0.1s\n",
      "[CV 1/5] END C=0.2, max_iter=200, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=200, penalty=l2, solver=liblinear;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=200, penalty=l2, solver=liblinear;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=200, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=200, penalty=l2, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.2, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.2, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.2, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.2, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.2, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=100, penalty=l1, solver=saga;, score=0.514 total time=   0.1s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=l1, solver=saga;, score=0.515 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=100, penalty=l1, solver=saga;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=l1, solver=saga;, score=0.506 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=100, penalty=l1, solver=saga;, score=0.509 total time=   0.1s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=l1, solver=liblinear;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=l1, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=l1, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=l2, solver=lbfgs;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=l2, solver=lbfgs;, score=0.737 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=100, penalty=l2, solver=lbfgs;, score=0.731 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=l2, solver=lbfgs;, score=0.727 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=l2, solver=lbfgs;, score=0.733 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=100, penalty=l2, solver=saga;, score=0.514 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=l2, solver=saga;, score=0.516 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=100, penalty=l2, solver=saga;, score=0.516 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=l2, solver=saga;, score=0.506 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=100, penalty=l2, solver=saga;, score=0.509 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=l2, solver=sag;, score=0.527 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=100, penalty=l2, solver=sag;, score=0.533 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=l2, solver=sag;, score=0.532 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=100, penalty=l2, solver=sag;, score=0.513 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=l2, solver=sag;, score=0.528 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=l2, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=100, penalty=l1, solver=saga;, score=0.514 total time=   0.1s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=l1, solver=saga;, score=0.515 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=100, penalty=l1, solver=saga;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=l1, solver=saga;, score=0.506 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=100, penalty=l1, solver=saga;, score=0.509 total time=   0.1s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=l1, solver=liblinear;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=l1, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=l1, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=l2, solver=lbfgs;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=l2, solver=lbfgs;, score=0.737 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=l2, solver=lbfgs;, score=0.731 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=100, penalty=l2, solver=lbfgs;, score=0.727 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=l2, solver=lbfgs;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=l2, solver=saga;, score=0.514 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=100, penalty=l2, solver=saga;, score=0.516 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=l2, solver=saga;, score=0.516 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=100, penalty=l2, solver=saga;, score=0.506 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=l2, solver=saga;, score=0.509 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=100, penalty=l2, solver=sag;, score=0.527 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=l2, solver=sag;, score=0.533 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=100, penalty=l2, solver=sag;, score=0.532 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=l2, solver=sag;, score=0.513 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=100, penalty=l2, solver=sag;, score=0.528 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=l2, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=200, penalty=l1, solver=saga;, score=0.527 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=200, penalty=l1, solver=saga;, score=0.533 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=200, penalty=l1, solver=saga;, score=0.532 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=200, penalty=l1, solver=saga;, score=0.513 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=200, penalty=l1, solver=saga;, score=0.528 total time=   0.2s\n",
      "[CV 1/5] END C=0.5, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=200, penalty=l1, solver=liblinear;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=200, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=200, penalty=l1, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=200, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=200, penalty=l1, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=200, penalty=l2, solver=lbfgs;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=200, penalty=l2, solver=lbfgs;, score=0.764 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=200, penalty=l2, solver=lbfgs;, score=0.781 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=200, penalty=l2, solver=lbfgs;, score=0.754 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=200, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=200, penalty=l2, solver=saga;, score=0.527 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=200, penalty=l2, solver=saga;, score=0.533 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=200, penalty=l2, solver=saga;, score=0.532 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=200, penalty=l2, solver=saga;, score=0.513 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=200, penalty=l2, solver=saga;, score=0.528 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, max_iter=200, penalty=l2, solver=sag;, score=0.544 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, max_iter=200, penalty=l2, solver=sag;, score=0.554 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, max_iter=200, penalty=l2, solver=sag;, score=0.555 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, max_iter=200, penalty=l2, solver=sag;, score=0.524 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, max_iter=200, penalty=l2, solver=sag;, score=0.546 total time=   0.1s\n",
      "[CV 1/5] END C=0.5, max_iter=200, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=200, penalty=l2, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=200, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=200, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=200, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=100, penalty=l1, solver=saga;, score=0.514 total time=   0.1s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=l1, solver=saga;, score=0.516 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=100, penalty=l1, solver=saga;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=l1, solver=saga;, score=0.506 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=100, penalty=l1, solver=saga;, score=0.509 total time=   0.1s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=l1, solver=liblinear;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=l1, solver=liblinear;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=100, penalty=l2, solver=lbfgs;, score=0.723 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=l2, solver=lbfgs;, score=0.693 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=l2, solver=lbfgs;, score=0.754 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=l2, solver=lbfgs;, score=0.707 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=l2, solver=lbfgs;, score=0.736 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=100, penalty=l2, solver=saga;, score=0.514 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=l2, solver=saga;, score=0.516 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=100, penalty=l2, solver=saga;, score=0.516 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=l2, solver=saga;, score=0.506 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=100, penalty=l2, solver=saga;, score=0.509 total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=l2, solver=sag;, score=0.527 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=100, penalty=l2, solver=sag;, score=0.533 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=l2, solver=sag;, score=0.532 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=100, penalty=l2, solver=sag;, score=0.513 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=l2, solver=sag;, score=0.528 total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=l2, solver=liblinear;, score=0.775 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=l2, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=100, penalty=l1, solver=saga;, score=0.514 total time=   0.1s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=l1, solver=saga;, score=0.516 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=100, penalty=l1, solver=saga;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=l1, solver=saga;, score=0.506 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=100, penalty=l1, solver=saga;, score=0.509 total time=   0.1s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=l1, solver=liblinear;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=l1, solver=liblinear;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=100, penalty=l2, solver=lbfgs;, score=0.723 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=l2, solver=lbfgs;, score=0.693 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=l2, solver=lbfgs;, score=0.754 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=l2, solver=lbfgs;, score=0.707 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=l2, solver=lbfgs;, score=0.736 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=100, penalty=l2, solver=saga;, score=0.514 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=l2, solver=saga;, score=0.516 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=100, penalty=l2, solver=saga;, score=0.516 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=l2, solver=saga;, score=0.506 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=100, penalty=l2, solver=saga;, score=0.509 total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=l2, solver=sag;, score=0.527 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=100, penalty=l2, solver=sag;, score=0.533 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=l2, solver=sag;, score=0.532 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=100, penalty=l2, solver=sag;, score=0.513 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=l2, solver=sag;, score=0.528 total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=l2, solver=liblinear;, score=0.775 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=l2, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=200, penalty=l1, solver=saga;, score=0.527 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=200, penalty=l1, solver=saga;, score=0.533 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=200, penalty=l1, solver=saga;, score=0.532 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=200, penalty=l1, solver=saga;, score=0.513 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=200, penalty=l1, solver=saga;, score=0.528 total time=   0.2s\n",
      "[CV 1/5] END C=0.8, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=200, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=200, penalty=l1, solver=liblinear;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=200, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=200, penalty=l1, solver=liblinear;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=200, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=200, penalty=l2, solver=lbfgs;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=200, penalty=l2, solver=lbfgs;, score=0.693 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=200, penalty=l2, solver=lbfgs;, score=0.753 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=200, penalty=l2, solver=lbfgs;, score=0.707 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=200, penalty=l2, solver=lbfgs;, score=0.763 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=200, penalty=l2, solver=saga;, score=0.527 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=200, penalty=l2, solver=saga;, score=0.533 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=200, penalty=l2, solver=saga;, score=0.532 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=200, penalty=l2, solver=saga;, score=0.513 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=200, penalty=l2, solver=saga;, score=0.528 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8, max_iter=200, penalty=l2, solver=sag;, score=0.544 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8, max_iter=200, penalty=l2, solver=sag;, score=0.554 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8, max_iter=200, penalty=l2, solver=sag;, score=0.555 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.8, max_iter=200, penalty=l2, solver=sag;, score=0.524 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8, max_iter=200, penalty=l2, solver=sag;, score=0.546 total time=   0.1s\n",
      "[CV 1/5] END C=0.8, max_iter=200, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=200, penalty=l2, solver=liblinear;, score=0.775 total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=200, penalty=l2, solver=liblinear;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=200, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=200, penalty=l2, solver=liblinear;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l1, solver=saga;, score=0.514 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=100, penalty=l1, solver=saga;, score=0.516 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l1, solver=saga;, score=0.516 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=100, penalty=l1, solver=saga;, score=0.506 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=100, penalty=l1, solver=saga;, score=0.509 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.703 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.727 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.720 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=100, penalty=l2, solver=saga;, score=0.514 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l2, solver=saga;, score=0.516 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=100, penalty=l2, solver=saga;, score=0.516 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l2, solver=saga;, score=0.506 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=100, penalty=l2, solver=saga;, score=0.509 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l2, solver=sag;, score=0.527 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=100, penalty=l2, solver=sag;, score=0.533 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l2, solver=sag;, score=0.532 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=100, penalty=l2, solver=sag;, score=0.513 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l2, solver=sag;, score=0.528 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.779 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=100, penalty=l1, solver=saga;, score=0.514 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l1, solver=saga;, score=0.516 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=100, penalty=l1, solver=saga;, score=0.516 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l1, solver=saga;, score=0.506 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=100, penalty=l1, solver=saga;, score=0.509 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.703 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.727 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.720 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=100, penalty=l2, solver=saga;, score=0.514 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l2, solver=saga;, score=0.516 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=100, penalty=l2, solver=saga;, score=0.516 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l2, solver=saga;, score=0.506 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=100, penalty=l2, solver=saga;, score=0.509 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l2, solver=sag;, score=0.527 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=100, penalty=l2, solver=sag;, score=0.533 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l2, solver=sag;, score=0.532 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=100, penalty=l2, solver=sag;, score=0.513 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l2, solver=sag;, score=0.528 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.779 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=200, penalty=l1, solver=saga;, score=0.527 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=200, penalty=l1, solver=saga;, score=0.533 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=200, penalty=l1, solver=saga;, score=0.532 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=200, penalty=l1, solver=saga;, score=0.513 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=200, penalty=l1, solver=saga;, score=0.528 total time=   0.3s\n",
      "[CV 1/5] END C=1, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=200, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=200, penalty=l1, solver=liblinear;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=200, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=200, penalty=l1, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=200, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=200, penalty=l2, solver=lbfgs;, score=0.703 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=200, penalty=l2, solver=lbfgs;, score=0.751 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=200, penalty=l2, solver=lbfgs;, score=0.780 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=200, penalty=l2, solver=lbfgs;, score=0.738 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=200, penalty=l2, solver=lbfgs;, score=0.720 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=200, penalty=l2, solver=saga;, score=0.527 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=200, penalty=l2, solver=saga;, score=0.533 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=200, penalty=l2, solver=saga;, score=0.532 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=200, penalty=l2, solver=saga;, score=0.513 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=200, penalty=l2, solver=saga;, score=0.528 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, max_iter=200, penalty=l2, solver=sag;, score=0.544 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=200, penalty=l2, solver=sag;, score=0.554 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, max_iter=200, penalty=l2, solver=sag;, score=0.555 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, max_iter=200, penalty=l2, solver=sag;, score=0.524 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "600 fits failed out of a total of 960.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, max_iter=200, penalty=l2, solver=sag;, score=0.546 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=200, penalty=l2, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=200, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=200, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=200, penalty=l2, solver=liblinear;, score=0.779 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=200, penalty=l2, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=200, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=200, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=200, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=200, penalty=None, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=200, penalty=None, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=200, penalty=None, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=200, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.51209889        nan 0.78708493 0.72973168 0.512256\n",
      " 0.52655578 0.78174285        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.51209889\n",
      "        nan 0.78708493 0.72973168 0.512256   0.52655578 0.78174285\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.52686999        nan 0.78708493\n",
      " 0.75534702 0.52655578 0.5446263  0.78174285        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.51209889        nan 0.78645613 0.72611681 0.512256\n",
      " 0.52655578 0.78582744        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.51209889\n",
      "        nan 0.78645613 0.72611681 0.512256   0.52655578 0.78582744\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.52655578        nan 0.78645613\n",
      " 0.75581749 0.52655578 0.5446263  0.78582744        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.512256          nan 0.78771349 0.72266078 0.512256\n",
      " 0.52655578 0.78567058        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.512256\n",
      "        nan 0.78771349 0.72266078 0.512256   0.52655578 0.78567058\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.52655578        nan 0.78771349\n",
      " 0.73743324 0.52655578 0.5446263  0.78567058        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.512256          nan 0.78708506 0.72800002 0.512256\n",
      " 0.52655578 0.78551396        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.512256\n",
      "        nan 0.78708506 0.72800002 0.512256   0.52655578 0.78551396\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.52655578        nan 0.78708506\n",
      " 0.73836923 0.52655578 0.5446263  0.78551396        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={'C': [0.2, 0.5, 0.8, 1], 'max_iter': [100, 100, 200],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
       "                         'solver': ['lbfgs', 'saga', 'sag', 'liblinear']},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7877134931104163\n",
      "{'C': 0.8, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.662755489349365\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "\n",
    "elapsed = end-start \n",
    "\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Model after GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lg2 for improved model from GS\n",
    "lg2 = LogisticRegression(C = 0.8,max_iter = 1000,penalty = 'l1',solver = 'liblinear',random_state=42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression(C=0.8, max_iter=1000, penalty='l1', random_state=42,\n",
      "                   solver='liblinear')\n",
      "\n",
      "Training score: 0.7910119421747329\n",
      "Testing score: 0.7738269794721407\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1389\n",
      "           1       0.75      0.81      0.78      1339\n",
      "\n",
      "    accuracy                           0.77      2728\n",
      "   macro avg       0.78      0.77      0.77      2728\n",
      "weighted avg       0.78      0.77      0.77      2728\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_scores_classification(lg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_iter vs. accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_iter_values = [500, 1000, 2000, 3000, 4000, 5000]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for max_iter_val in max_iter_values:\n",
    "    lg2 = LogisticRegression(C=0.8, max_iter=max_iter_val, penalty='l1', solver='liblinear', random_state=42)\n",
    "    \n",
    "    # Calculate training score\n",
    "    train_score = np.mean(cross_val_score(lg2, X_train, y_train, cv=5))\n",
    "    train_scores.append(train_score)\n",
    "\n",
    "    # Calculate test score\n",
    "    test_score = np.mean(cross_val_score(lg2, X_test, y_test, cv=5))  # Assuming X_test and y_test are your test data\n",
    "    test_scores.append(test_score)\n",
    "\n",
    "plt.plot(max_iter_values, train_scores, marker='o', label='Train Accuracy')\n",
    "plt.plot(max_iter_values, test_scores, marker='o', label='Test Accuracy')\n",
    "plt.title('Max_iter vs. Accuracy')\n",
    "plt.xlabel('max_iter')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.4 Decision Tree Classifier  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'criterion' : ['gini','entropy'], # measures quality of the split\n",
    "              'splitter' : ['best','random'], # best split of each node\n",
    "              'max_depth' : [1000,3000,5000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=dtree, param_grid=param_grid, scoring='accuracy',verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END criterion=gini, max_depth=1000, splitter=best;, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=1000, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=1000, splitter=best;, score=0.760 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=1000, splitter=best;, score=0.764 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=1000, splitter=best;, score=0.767 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=1000, splitter=random;, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=1000, splitter=random;, score=0.767 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=1000, splitter=random;, score=0.745 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=1000, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=1000, splitter=random;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=3000, splitter=best;, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=3000, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=3000, splitter=best;, score=0.760 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=3000, splitter=best;, score=0.764 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=3000, splitter=best;, score=0.767 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=3000, splitter=random;, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=3000, splitter=random;, score=0.767 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=3000, splitter=random;, score=0.745 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=3000, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=3000, splitter=random;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5000, splitter=best;, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5000, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5000, splitter=best;, score=0.760 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5000, splitter=best;, score=0.764 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5000, splitter=best;, score=0.767 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5000, splitter=random;, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5000, splitter=random;, score=0.767 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5000, splitter=random;, score=0.745 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5000, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5000, splitter=random;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=1000, splitter=best;, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=1000, splitter=best;, score=0.751 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=1000, splitter=best;, score=0.758 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=1000, splitter=best;, score=0.779 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=1000, splitter=best;, score=0.784 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=1000, splitter=random;, score=0.759 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=1000, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=1000, splitter=random;, score=0.742 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=1000, splitter=random;, score=0.768 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=1000, splitter=random;, score=0.748 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3000, splitter=best;, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3000, splitter=best;, score=0.751 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3000, splitter=best;, score=0.758 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3000, splitter=best;, score=0.779 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3000, splitter=best;, score=0.784 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3000, splitter=random;, score=0.759 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3000, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3000, splitter=random;, score=0.742 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3000, splitter=random;, score=0.768 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3000, splitter=random;, score=0.748 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5000, splitter=best;, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5000, splitter=best;, score=0.751 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5000, splitter=best;, score=0.758 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5000, splitter=best;, score=0.779 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5000, splitter=best;, score=0.784 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5000, splitter=random;, score=0.759 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5000, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5000, splitter=random;, score=0.742 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5000, splitter=random;, score=0.768 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5000, splitter=random;, score=0.748 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [1000, 3000, 5000],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7660304485516806\n",
      "{'criterion': 'entropy', 'max_depth': 1000, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Model after GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtree2 as the new model \n",
    "dtree2 = DecisionTreeClassifier(criterion = 'entropy',max_depth = 1000,splitter='best').fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeClassifier(criterion='entropy', max_depth=1000)\n",
      "\n",
      "Training score: 1.0\n",
      "Testing score: 0.7576979472140762\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76      1389\n",
      "           1       0.75      0.76      0.76      1339\n",
      "\n",
      "    accuracy                           0.76      2728\n",
      "   macro avg       0.76      0.76      0.76      2728\n",
      "weighted avg       0.76      0.76      0.76      2728\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate accuracy \n",
    "model_scores_classification(dtree2)\n",
    "\n",
    "# improved the overfitted model, and test data increased in accuracy\n",
    "# overfitting can be handled by bagging classifier, but we would like to try boosting first  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualise the tree for feature importances? \n",
    "# plt.figure(figsize=(25,10))\n",
    "# tree.plot_tree(dtree2,\n",
    "#               feature_names = list(df_hr.drop(['is_promoted'], axis=1)),\n",
    "#                 class_names = ['0','1'],\n",
    "#                 rounded = True,\n",
    "#                 filled= True)\n",
    "# plt.savefig('tree1.png',format='png')\n",
    "# plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_depth vs. accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAt7ElEQVR4nO3de5hU1Zn+/e9tc1aEcPAEaJNoMCpHOx6TqMEDJkFFjcLoxMMkDvkNGs0rBmJinOSXdxx1xtEkr45J0MRBUCEgiSc8ETPEKI2gAkpERGkJiBAQDwg0z/vH3o1FU9VdG7q6obg/11VX11577bXWUw319F6ram9FBGZmZsXao6UHYGZmuxYnDjMzy8SJw8zMMnHiMDOzTJw4zMwsEycOMzPLxInDrAlIqpQUklq19FjMSs2Jw0pO0hJJGyR1q1c+N32zrWzi/urexN9PHysk/UHSKU3YxxJJJzdVe01J0sVp/Oe19FisPDlxWHN5AxhRtyGpL9C+xH12joi9gP7A48AUSReXuM+dwUXA6vRns/HZ1u7DicOayz3AN3K2LwJ+m1tB0lclzZH0nqSlkq7P2Xe+pMWS9k63T5e0XFL3xjqOiOURcStwPfDvkvZI2zhA0mRJKyW9IemKnP6ulzRJ0n2S1kl6QVL/dN89wIHA79MzmmtyurtA0luS3pV0bb7xSDomHXtFTtkwSS+lz4+SVJ2+Disk/WdjMea0cxBwAnAZcJqkfXP2VUj6vqTX05hmS+qV7jtc0uOSVqd9fj8tv1vS/81p40RJNTnbSyR9Lx37B5JaSRqT08cCScPqjfFbkl7J2T9I0mhJk+vV+5mk/yo2dmtGEeGHHyV9AEuAk4GFwOeACmApcBAQQGVa70SgL8kfNP2AFcBZOe2MB+4GugLLgK8V6K8ybbdVvfJPp+WfS/uYDVwHtEn3LQZOS+teD2wEzgVaA1eTnDW1zo0pT5+/JDmT6g98DHyuwBhfB07J2X4AGJM+fxb4x/T5XsAxGV7rHwLPp89fBr6bs290WtYHUDrGrkBH4G/A/wO0S7ePTo+5G/i/OW2cCNTU+93OBXoB7dOyrwMHpK/x+cAHwP45+94GPp+O4eD038H+ab3Oab1WwDvAkS3979ePbR8+47DmVHfWcQrwKskbyBYRMSMiXo6IzRHxEjCB5K/nOv8CfBmYAfw+Iv6Qsf9l6c8uJG9c3SPixxGxISIWk7zpD8+pPzsiJkXERuA/Sd5Uj2mkj3+NiI8i4kXgRZI353wmkE7dSeoIfCUtgyRhHSypW0S8HxF/yRDjN4B70+f3svV01TeBH0TEwki8GBGrgK8ByyPiPyJifUSsi4jnMvR5W0QsjYiPACLigYhYlv4e7wNeA47KGcONETErHcOiiHgzIv4GPEOSWACGAO9GxOwM47Bm4sRhzeke4B+Ai6k3TQUg6WhJT6dTR2uBkcCWBfWIWEPyl/kRwH9sR/890p+rSf7KPUDSmroH8H1g35z6S3P63gzUkPwl3ZDlOc8/JDljyOde4GxJbYGzgRci4s103z8BnwVelTRL0tcajQyQdDzQG5iY00dfSQPS7V4kZzr1FSov1tLcDUnfSD/4UPe6HsEnv8eG+voNcGH6/EKSfy+2E3LisGaTvjG+QfLX9e/yVLkXmAb0iohOwB0k0xkApG+Al5L8ZX7bdgxhGMn0x0KSN7s3IqJzzqNjRHwlp36vnL73AHryyVnLDl1WOiIWAG8Cp5Mk03tz9r0WESOAfYB/ByZJ2rOIZi8ieb3mSloO1J011K0tLQU+k+e4QuWQTB91yNneL184dU/SNZZfAqOArhHRGZjHJ7/HhvqaCvSTdATJWdD4AvWshTlxWHP7J+DLEfFBnn0dgdURsV7SUSRvqABIagf8D8lZwSVAD0n/p5gOJe0raRTwI2BsevbwPPBeurDbPl04PkLS53MOPVLS2emnha4kWbOomzZaQbIusiPuBa4AvkRyJlU33gsldU/HuSYtrm0kxnbAeSSL4gNyHpeTLNi3An4F/ETSIUr0k9QV+AOwn6QrJbWV1FHS0WnTc4GvSOoiaT+S16Ehe5IkkpXpuC4hOeOo8yvgaklHpmM4OE02RMR6YFL6ujwfEW810pe1lJZeZPGj/B/UW0jOKW/F1ovj55L8Fb6O5M3s58D/pPtuAR7NObY/yZTTIXnarUzbfZ/kL+Z3gIeBIfXqHUBy9rIc+DtJUjg53Xc9yZvYfel45gCDco49E3iL5I39avIsyJOsxXyzgdflQGAz8FC98v9Jx/w+MJ+tPyDwPvDFPG0NJ1ngbl2vvB3wLslf8BXAD0jO+tYBs4Ceab0jgCfT12E5nyzUt0tfg/eAl4Cr2HZx/OR6ff40/d28S7I29Mfc14FkCnJhGss8YGDOvi+kr+MlLf3v1o/CD6W/LDPLoeSjwAdHxIWN1bWmI+lAkg9O7BcR77X0eCw/T1WZ2U4hXUf6LjDRSWPn5m96mlmLSxf/V5BMVQ5p4eFYIzxVZWZmmXiqyszMMtktpqq6desWlZWVLT0MM7NdyuzZs9+NiG2uB7dbJI7Kykqqq6tbehhmZrsUSW/mK/dUlZmZZeLEYWZmmThxmJlZJk4cZmaWiROHmZllslt8qmp7TJ3zNjc9tpBlaz7igM7tGX1aH84a2KPxA91fi/ZV7v2Vc2zNrZxjg9LGV9LEIWkIcCvJVTl/FRE31Ns/GrggZyyfI7kr22pJnUkuwXwEydUyL42IZ9PjLie53v8mkiuL5t7zeYdNnfM2Y3/3Mh9tTK5k/faajxj7u5cBSvIPq5z7K+fYmru/co6tuZVzbFD6+Ep2yRFJFcBfSW4TWkNyCecRkdzAJl/9ocBVEfHldPs3wJ8i4leS2gAdImKNpJOAa4GvRsTHkvaJiHcaGktVVVVk+R7H8Tc8xdtrPtqmvE3FHgw8sHPR7RRrzltr2FC7uSz7K+fYmru/co6tuZVzbFA4vh6d2zNzzJeLbkfS7Iioql9eyjWOo4BFEbE4IjaQ3M7yzAbqjyC957KkvUlubvNrgEjuCb0mrfdt4IaI+Djd12DS2B7L8iQNIO8voikUarcc+ivn2Jq7v3KOrbmVc2xQOI5C721ZlXKqqgdb34u4Bjg6X0VJHUiuiDkqLfo0yR3E7pLUH5gNfCeSu8Z9FviipJ8C64GrI2JWnjYvI7kbGgceeGCmgR/QuX3eM44endtz3z8fm6mtYhQ6wymH/so5tubur5xja27lHBsUju+Azu2bpP1SnnEoT1mhebGhwMyIWJ1utwIGAbdHxECSu7iNydn3KeAYYDRwv6Rt+oqIOyOiKiKqunff5lIrDRp9Wh/at67Yqqx96wpGn9YnUzvur7xja+7+yjm25lbOsUHp4yvlGUcN0CtnuyewrEDd4aTTVDnH1kTEc+n2JD5JHDXA7yJZnHle0magG+k9jptC3eJRc33iopz7K+fYmru/co6tuZVzbFD6+Eq5ON6KZHF8MPA2yeL4P0TE/Hr1OpHcA7lXOhVVV/4nkvsUL0xv47lnRIyWNBI4ICKuk/RZkvskHxgNBJJ1cdzMzAovjpfsjCMiNkkaBTxG8nHccRExP33jJyLuSKsOA6bnJo3U5cD49BNVi4FL0vJxwDhJ84ANwEUNJQ0zM2tau8UdAH3GYWaWXUt8HNfMzMqQE4eZmWXixGFmZpk4cZiZWSZOHGZmlokTh5mZZeLEYWZmmThxmJlZJk4cZmaWiROHmZll4sRhZmaZOHGYmVkmThxmZpaJE4eZmWXixGFmZpk4cZiZWSZOHGZmlokTh5mZZVLSxCFpiKSFkhZJGpNn/2hJc9PHPEm1krqk+zpLmiTpVUmvSDq23rFXSwpJ3UoZg5mZba1kiUNSBfAL4HTgMGCEpMNy60TETRExICIGAGOBP0bE6nT3rcCjEXEo0B94JaftXsApwFulGr+ZmeVXyjOOo4BFEbE4IjYAE4EzG6g/ApgAIGlv4EvArwEiYkNErMmpewtwDRAlGLeZmTWglImjB7A0Z7smLduGpA7AEGByWvRpYCVwl6Q5kn4lac+07hnA2xHxYslGbmZmBZUycShPWaEzhKHAzJxpqlbAIOD2iBgIfACMSRPMtcB1jXYuXSapWlL1ypUrs4/ezMzyKmXiqAF65Wz3BJYVqDucdJoq59iaiHgu3Z5Ekkg+A/QGXpS0JG3zBUn71W8wIu6MiKqIqOrevfsOBWJmZp8oZeKYBRwiqbekNiTJYVr9SpI6AScAD9aVRcRyYKmkPmnRYGBBRLwcEftERGVEVJIkmEFpfTMzawatStVwRGySNAp4DKgAxkXEfEkj0/13pFWHAdMj4oN6TVwOjE+TzmLgklKN1czMiqeI8v9gUlVVVVRXV7f0MMzMdimSZkdEVf1yf3PczMwyceIwM7NMnDjMzCwTJw4zM8vEicPMzDJx4jAzs0ycOMzMLBMnDjMzy8SJw8zMMnHiMDOzTJw4zMwsEycOMzPLxInDzMwyceIwM7NMnDjMzCwTJw4zM8vEicPMzDJx4jAzs0ycOMzMLJOSJg5JQyQtlLRI0pg8+0dLmps+5kmqldQl3ddZ0iRJr0p6RdKxaflNadlLkqZI6lzKGMzMbGslSxySKoBfAKcDhwEjJB2WWyciboqIARExABgL/DEiVqe7bwUejYhDgf7AK2n548AREdEP+Gt6nJmZNZNSnnEcBSyKiMURsQGYCJzZQP0RwAQASXsDXwJ+DRARGyJiTfp8ekRsSo/5C9CzNMM3M7N8Spk4egBLc7Zr0rJtSOoADAEmp0WfBlYCd0maI+lXkvbMc+ilwCMF2rxMUrWk6pUrV25vDGZmVk8pE4fylEWBukOBmTnTVK2AQcDtETEQ+ADYao1E0rXAJmB8vgYj4s6IqIqIqu7du2/P+M3MLI9SJo4aoFfOdk9gWYG6w0mnqXKOrYmI59LtSSSJBABJFwFfAy6IiELJyMzMSqCUiWMWcIik3pLakCSHafUrSeoEnAA8WFcWEcuBpZL6pEWDgQVp/SHA94AzIuLDEo7fzMzyaFWqhiNik6RRwGNABTAuIuZLGpnuvyOtOgyYHhEf1GvicmB8mnQWA5ek5T8H2gKPSwL4S0SMLFUcZma2Ne0OMz1VVVVRXV3d0sMwM9ulSJodEVX1y/3NcTMzy8SJw8zMMnHiMDOzTJw4zMwsEycOMzPLxInDzMwyceIwM7NMnDjMzCwTJw4zM8vEicPMzDJx4jAzs0ycOMzMLBMnDjMzy8SJw8zMMnHiMDOzTJw4zMwsEycOMzPLpNHEIelrkpxgzMwMKO6MYzjwmqQbJX2u1AMyM7OdW6OJIyIuBAYCrwN3SXpW0mWSOjZ2rKQhkhZKWiRpTJ79oyXNTR/zJNVK6pLu6yxpkqRXJb0i6di0vIukxyW9lv78VOaozcxsuxU1BRUR7wGTgYnA/sAw4AVJlxc6RlIF8AvgdOAwYISkw+q1e1NEDIiIAcBY4I8RsTrdfSvwaEQcCvQHXknLxwBPRsQhwJPptpmZNZNWjVWQNBS4FPgMcA9wVES8I6kDyZv5zwocehSwKCIWp+1MBM4EFhSoPwKYkNbdG/gScDFARGwANqT1zgROTJ//BpgBfK+xOMys+WzcuJGamhrWr1/f0kOxIrRr146ePXvSunXrouo3mjiArwO3RMQzuYUR8aGkSxs4rgewNGe7Bjg6X8U0CQ0BRqVFnwZWkkyN9QdmA9+JiA+AfSPib+kY/iZpnwJtXgZcBnDggQc2HKGZNamamho6duxIZWUlklp6ONaAiGDVqlXU1NTQu3fvoo4pZqrqR8DzdRuS2kuqTDt8soHj8v1riQJ1hwIzc6apWgGDgNsjYiDwARmnpCLizoioioiq7t27ZznUzHbQ+vXr6dq1q5PGLkASXbt2zXR2WEzieADYnLNdm5Y1pgbolbPdE1hWoO5w0mmqnGNrIuK5dHsSSSIBWCFpf4D05ztFjMXMmpmTxq4j6++qmMTRKl1jALasN7Qp4rhZwCGSektqQ5IcptWvJKkTcALwYE4fy4GlkvqkRYP5ZG1kGnBR+vyi3OPMzABWrVrFgAEDGDBgAPvttx89evTYsr1hw4YGj62uruaKK67I3OecOXOQxGOPPba9w95lFLPGsVLSGRExDUDSmcC7jR0UEZskjQIeAyqAcRExX9LIdP8dadVhwPR0/SLX5cD4NOksBi5Jy28A7pf0T8BbJGswZrYLmzrnbW56bCHL1nzEAZ3bM/q0Ppw1sMd2t9e1a1fmzp0LwPXXX89ee+3F1VdfvWX/pk2baNUq/9tfVVUVVVVVmfucMGECX/jCF5gwYQKnnXbado27GLW1tVRUVJSs/WIUkzhGkryB/5xk3WIp8I1iGo+Ih4GH65XdUW/7buDuPMfOBbb57UXEKpIzEDMrA1PnvM3Y373MRxtrAXh7zUeM/d3LADuUPOq7+OKL6dKlC3PmzGHQoEGcf/75XHnllXz00Ue0b9+eu+66iz59+jBjxgxuvvlm/vCHP3D99dfz1ltvsXjxYt566y2uvPLKvGcjEcGkSZN4/PHH+eIXv8j69etp164dADfeeCP33HMPe+yxB6effjo33HADixYtYuTIkaxcuZKKigoeeOABli5duqVfgFGjRlFVVcXFF19MZWUll156KdOnT2fUqFGsW7eOO++8kw0bNnDwwQdzzz330KFDB1asWMHIkSNZvHgxALfffjuPPPII3bp14zvf+Q4A1157Lfvuu+92nVXVaTRxRMTrwDGS9gIUEeu2uzcz2+386+/ns2DZewX3z3lrDRtqN29V9tHGWq6Z9BITnn8r7zGHHbA3Pxp6eOax/PWvf+WJJ56goqKC9957j2eeeYZWrVrxxBNP8P3vf5/Jkydvc8yrr77K008/zbp16+jTpw/f/va3t/nY6syZM+nduzef+cxnOPHEE3n44Yc5++yzeeSRR5g6dSrPPfccHTp0YPXq5PM/F1xwAWPGjGHYsGGsX7+ezZs3s3Tp0m36ztWuXTv+93//F0im4r71rW8B8IMf/IBf//rXXH755VxxxRWccMIJTJkyhdraWt5//30OOOAAzj77bL7zne+wefNmJk6cyPPPP99QV40q5owDSV8FDgfa1S2iRMSPd6hnMzPYJmk0Vr4jvv71r2+Z5lm7di0XXXQRr732GpLYuHFj3mO++tWv0rZtW9q2bcs+++zDihUr6Nmz51Z1JkyYwPDhwwEYPnw499xzD2effTZPPPEEl1xyCR06dACgS5curFu3jrfffpthw4YBbDkzacz555+/5fm8efP4wQ9+wJo1a3j//fe3TI099dRT/Pa3vwWgoqKCTp060alTJ7p27cqcOXNYsWIFAwcOpGvXrsW+ZHkV8wXAO4AOwEnAr4Bzyfl4rplZQxo7Mzj+hqd4e81H25T36Nye+/752CYdy5577rnl+Q9/+ENOOukkpkyZwpIlSzjxxBPzHtO2bdstzysqKti0adNW+2tra5k8eTLTpk3jpz/96ZbvRaxbt46I2OYTSxH5v5XQqlUrNm/+JFnW/3hs7tgvvvhipk6dSv/+/bn77ruZMWNGg3F/85vf5O6772b58uVcemlDX78rTjGfqjouIr4B/D0i/hU4lq0/Zmtmtt1Gn9aH9q23Xuxt37qC0af1KXBE01i7di09eiRrKHffffd2t/PEE0/Qv39/li5dypIlS3jzzTc555xzmDp1Kqeeeirjxo3jww8/BGD16tXsvffe9OzZk6lTpwLw8ccf8+GHH3LQQQexYMECPv74Y9auXcuTTxb+mty6devYf//92bhxI+PHj99SPnjwYG6//XYgSWjvvZdMEQ4bNoxHH32UWbNmNcnCfTGJoy7tfSjpAGAjUNzXC83MGnHWwB7829l96dG5PSI50/i3s/s26cJ4Ptdccw1jx47l+OOPp7a2drvbmTBhwpZppzrnnHMO9957L0OGDOGMM86gqqqKAQMGcPPNNwNwzz33cNttt9GvXz+OO+44li9fTq9evTjvvPPo168fF1xwAQMHDizY509+8hOOPvpoTjnlFA499NAt5bfeeitPP/00ffv25cgjj2T+/PkAtGnThpNOOonzzjuvST6RpUKnTVsqSD8kuR7VYJKLFgbwy4i4bod7byZVVVVRXV3d0sMw22288sorfO5zvgvDzmLz5s0MGjSIBx54gEMOOSRvnXy/M0mzI2KbT7c2eMaR3sDpyYhYExGTgYOAQ3elpGFmtjtbsGABBx98MIMHDy6YNLJqcHE8IjZL+g+SdQ0i4mPg4ybp2czMSu6www7b8r2OplLMGsd0SefIF54xMzOK+x7Hd4E9gU2S1pN8ezwiYu+SjszMzHZKxXxzvNFbxJqZ2e6jmC8Afilfef0bO5mZ2e6hmKmq0TnP25HcEnY28OWSjMjMbAetWrWKwYOTa6EuX76ciooK6m7o9vzzz9OmTcN3hpgxYwZt2rThuOOOK1jnzDPP5J133uHZZ59tuoHvIoqZqhqauy2pF3BjyUZkZrufl+6HJ38Ma2ugU08YfB30O2+7m2vssuqNmTFjBnvttVfBxLFmzRpeeOEF9tprL954442ib7maVUOXf29JxXyqqr4a4IimHoiZ7aZeuh9+fwWsXQpE8vP3VyTlTWj27NmccMIJHHnkkZx22mn87W9/A+C2227jsMMOo1+/fgwfPpwlS5Zwxx13cMsttzBgwAD+9Kc/bdPW5MmTGTp0KMOHD2fixIlbyhctWsTJJ59M//79GTRoEK+//jqQXFq9b9++9O/fnzFjkrtgn3jiidR9Mfndd9+lsrISSC5/8vWvf52hQ4dy6qmn8v777zN48GAGDRpE3759efDBT+5d99vf/pZ+/frRv39//vEf/5F169bRu3fvLRdsfO+996isrCx4AcftVcwax8/45F7hewADgBebdBRmVr4eGQPLXy68v2YW1Nb7etjGj+DBUTD7N/mP2a8vnH5D0UOICC6//HIefPBBunfvzn333ce1117LuHHjuOGGG3jjjTdo27Yta9asoXPnzowcObLBs5QJEybwox/9iH333Zdzzz2XsWPHAvkvl17o0uoNefbZZ3nppZfo0qULmzZtYsqUKey99968++67HHPMMZxxxhksWLCAn/70p8ycOZNu3bqxevVqOnbsyIknnshDDz3EWWedxcSJEznnnHO2uQz8jirmHCj3Wh2bgAkRMbNJR2Fmu6/6SaOx8u3w8ccfM2/ePE455ZSk6dpa9t9/f4At14Y666yzOOussxpta8WKFSxatIgvfOELSKJVq1bMmzePgw46KO/l0vNdWr0xp5xyypZ6EcH3v/99nnnmGfbYYw/efvttVqxYwVNPPcW5555Lt27dtmr3m9/8JjfeeCNnnXUWd911F7/85S8zvFLFKSZxTALWR0QtgKQKSR0i4sMmH42ZlZ/GzgxuOSKdpqqnUy+45KEmGUJEcPjhh+ddyH7ooYd45plnmDZtGj/5yU+2XBiwkPvuu4+///3vW9Y13nvvPSZOnMg111xTsO9835/OvYx6Q5dQHz9+PCtXrmT27Nm0bt2ayspK1q9fX7Dd448/niVLlvDHP/6R2tpajjii6VcWilnjeBJon7PdHniiyUdiZrunwddB6/Zbl7Vun5Q3kbZt27Jy5cotiWPjxo3Mnz9/y533TjrpJG688cYtN0bq2LEj69blv9nphAkTePTRR1myZAlLlixh9uzZTJw4seDl0vNdWh2gsrKS2bNnAzBp0qSCY1+7di377LMPrVu35umnn+bNN98Ekkuo33///axatWqrdgG+8Y1vMGLECC655JIdeNUKKyZxtIuI9+s20ucdimlc0hBJCyUtkjQmz/7Rkuamj3mSaiV1SfctkfRyuq8655gBkv5SVy7pqGLGYmY7qX7nwdDbkjMMlPwcetsOfaqqvj322INJkybxve99j/79+zNgwAD+/Oc/U1tby4UXXkjfvn0ZOHAgV111FZ07d2bo0KFMmTJlm8XxJUuW8NZbb3HMMcdsKevduzd77703zz33XN7LpRe6tPrVV1/N7bffznHHHce7775bcOwXXHAB1dXVVFVVMX78+C2XUT/88MO59tprOeGEE+jfvz/f/e53tzrm73//OyNGjGiy13ArEdHgA5gJDMrZPhJ4tojjKoDXgU8DbUgW1A9roP5Q4Kmc7SVAtzz1pgOnp8+/AsxobCxHHnlkmFnzWbBgQUsPYbf2wAMPxIUXXpjpmHy/M6A68rynFrPGcSXwgKRl6fb+wPmFq29xFLAoIhYDSJoInAksKFB/BDChiHYDqLtOVidgWQN1zcx2K5dffjmPPPIIDz/8cMn6KOYLgLMkHQr0IbnA4asRUcyHgnsAuSteNcDR+SpK6gAMAUbldk1yZd4A/jsi7kzLrwQek3QzyVRb3m/oSLoMuAzgwAMPLGK4Zma7vp/97Gcl76PRNQ5J/wLsGRHzIuJlYC9J/6eItvNdhr3Q7QaHAjMjIvcDzsdHxCDgdOBfcq6Z9W3gqojoBVwF/DpfgxFxZ0RURURV3aUGzMxsxxWzOP6tiFhTtxERfwe+VcRxNUCvnO2eFJ5WGk69aaqIWJb+fAeYQjL1BXAR8Lv0+QM55Wa2E4lGbkttO4+sv6tiEsceuTdxklRBstjdmFnAIZJ6S2pDkhym1a8kqRNwAvBgTtmekjrWPQdOBealu5el9SG50OJrRYzFzJpRu3btWLVqlZPHLiAiWLVq1ZYvLBajmMXxx4D7Jd1BMtU0EnikiMFskjQqPb4CGBcR8yWNTPffkVYdBkyPiA9yDt8XmJLmq1bAvRHxaLrvW8CtkloB60nXMcxs59GzZ09qampYuXJlSw/FitCuXTt69uxZdH019heBpD1I3pxPJlm3mAPsHxH/sgPjbFZVVVVRdzExMzMrjqTZEVFVv7zRqaqI2Az8BVgMVAGDgVeafIRmZrZLKDhVJemzJOsSI4BVwH0AEXFS8wzNzMx2Rg2tcbwK/AkYGhGLACRd1SyjMjOznVZDU1XnAMuBpyX9UtJg8n83w8zMdiMFE0dETImI84FDgRkkX7bbV9Ltkk5tpvGZmdlOppjF8Q8iYnxEfI3kS3xzgW2udGtmZruHTPccj4jVEfHfEfHlUg3IzMx2bpkSh5mZmROHmZll4sRhZmaZOHGYmVkmThxmZpaJE4eZmWXixGFmZpk4cZiZWSZOHGZmlokTh5mZZeLEYWZmmThxmJlZJiVNHJKGSFooaZGkba6oK2m0pLnpY56kWkld0n1LJL2c7quud9zlabvzJd1YyhjMzGxrDd0BcIdIqgB+AZwC1ACzJE2LiAV1dSLiJuCmtP5Q4KqIWJ3TzEkR8W69dk8CzgT6RcTHkvYpVQxmZratUp5xHAUsiojFEbEBmEjyhl/ICGBCEe1+G7ghIj4GiIh3dnikZmZWtFImjh7A0pztmrRsG5I6AEOAyTnFAUyXNFvSZTnlnwW+KOk5SX+U9PkCbV4mqVpS9cqVK3coEDMz+0TJpqrIf3/yKFB3KDCz3jTV8RGxLJ2KelzSqxHxDMmYPwUcA3weuF/SpyNiq7Yj4k7gToCqqqpC/ZqZWUalPOOoAXrlbPcElhWoO5x601QRsSz9+Q4whWTqq67d30XieWAz0K0Jx21mZg0oZeKYBRwiqbekNiTJYVr9SpI6AScAD+aU7SmpY91z4FRgXrp7KvDldN9ngTbAVgvoZmZWOiWbqoqITZJGAY8BFcC4iJgvaWS6/4606jBgekR8kHP4vsAUSXVjvDciHk33jQPGSZoHbAAuqj9NZWZmpaPd4T23qqoqqqurG69oZmZbSJodEVX1y/3NcTMzy8SJw8zMMnHiMDOzTJw4zMwsEycOMzPLxInDzMwyceIwM7NMnDjMzCwTJw4zM8vEicPMzDJx4jAzs0ycOMzMLBMnDjMzy8SJw8zMMnHiMDOzTJw4zMwsEycOMzPLxInDzMwyceIwM7NMSpo4JA2RtFDSIklj8uwfLWlu+pgnqVZSl3TfEkkvp/u2uWG4pKslhaRupYzBzMy21qpUDUuqAH4BnALUALMkTYuIBXV1IuIm4Ka0/lDgqohYndPMSRHxbp62e6XtvlWq8ZuZWX6lPOM4ClgUEYsjYgMwETizgfojgAlFtn0LcA0QOzZEMzPLqpSJowewNGe7Ji3bhqQOwBBgck5xANMlzZZ0WU7dM4C3I+LFhjqXdJmkaknVK1eu3N4YzMysnpJNVQHKU1boDGEoMLPeNNXxEbFM0j7A45JeBaqBa4FTG+s8Iu4E7gSoqqrymYmZWRMp5RlHDdArZ7snsKxA3eHUm6aKiGXpz3eAKSRTX58BegMvSlqStvmCpP2adORmZlZQKRPHLOAQSb0ltSFJDtPqV5LUCTgBeDCnbE9JHeuek5xhzIuIlyNin4iojIhKkuQ0KCKWlzAOMzPLUbKpqojYJGkU8BhQAYyLiPmSRqb770irDgOmR8QHOYfvC0yRVDfGeyPi0VKN1czMiqeI8p/+r6qqiurqbb4KYmZmDZA0OyKq6pf7m+NmZpaJE4eZmWXixGFmZpk4cZiZWSZOHGZmlokTh5mZZeLEYWZmmThxmJlZJk4cZmaWiROHmZll4sRhZmaZOHGYmVkmThxmZpaJE4eZmWXixGFmZpk4cZiZWSZOHGZmlokTh5mZZVLSxCFpiKSFkhZJGpNn/2hJc9PHPEm1krqk+5ZIejndV51zzE2SXpX0kqQpkjqXMgYzM9tayRKHpArgF8DpwGHACEmH5daJiJsiYkBEDADGAn+MiNU5VU5K9+fe8/Zx4IiI6Af8NT3OzMyaSSnPOI4CFkXE4ojYAEwEzmyg/ghgQmONRsT0iNiUbv4F6LnDIzUzs6KVMnH0AJbmbNekZduQ1AEYAkzOKQ5guqTZki4r0MelwCNNMNZtvXQ/3HIEXN85+fnS/SXpZrfor5xja+7+yjm25lbOsUFJ42vVZC1tS3nKokDdocDMetNUx0fEMkn7AI9LejUintnSuHQtsAkYn7fzJNlcBnDggQdmG/lL98Pvr4CNHyXba5cm2wD9zsvW1u7eXznH1tz9lXNsza2cY4OSx6eIQu/lO9iwdCxwfUSclm6PBYiIf8tTdwrwQETcW6Ct64H3I+LmdPsiYCQwOCI+bGwsVVVVUV1d3Vi1T9xyRPJC11fRFnp+vvh2ilUzC2o/Ls/+yjm25u6vnGNrbuUcGxSOr1MvuGpe0c1Iml1vjRko7VTVLOAQSb0ltQGGA9PyDKwTcALwYE7ZnpI61j0HTgXmpdtDgO8BZxSTNLbL2pr85fl+EU2hULvl0F85x9bc/ZVzbM2tnGODwnEUem/LqGRTVRGxSdIo4DGgAhgXEfMljUz335FWHQZMj4gPcg7fF5giqW6M90bEo+m+nwNtSaavAP4SESObdPCdeuY/4+jUCy55qEm7Agqf4ZRDf+UcW3P3V86xNbdyjg0aiK9pPktU0u9xRMTDEfHZiPhMRPw0LbsjJ2kQEXdHxPB6xy2OiP7p4/C6Y9N9B0dEr7qP8TZ50gAYfB20br91Wev2SXkplHN/5Rxbc/dXzrE1t3KODUoen785nk+/82DobclfHyj5OfS20i2alXN/5Rxbc/dXzrE1t3KODUoeX8kWx3cmmRfHzcysRRbHzcysDDlxmJlZJk4cZmaWiROHmZll4sRhZmaZ7BafqpK0EnizpcdRpG7Auy09iBIp59igvONzbLuuHYnvoIjoXr9wt0gcuxJJ1fk+/lYOyjk2KO/4HNuuqxTxearKzMwyceIwM7NMnDh2Pne29ABKqJxjg/KOz7Htupo8Pq9xmJlZJj7jMDOzTJw4zMwsEyeOEpM0TtI7kubllHWR9Lik19Kfn8rZN1bSIkkLJZ2WU36kpJfTfbcpvYtVS5LUS9LTkl6RNF/Sd9LyXT4+Se0kPS/pxTS2f03Ld/nYckmqkDRH0h/S7bKIT9KSdExzJVWnZWURG4CkzpImSXo1/f93bLPGFxF+lPABfAkYBMzLKbsRGJM+HwP8e/r8MOBFkjsc9gZeByrSfc8DxwICHgFO3wli2x8YlD7vCPw1jWGXjy8dx17p89bAc8Ax5RBbvTi/C9wL/KHM/m0uAbrVKyuL2NJx/Qb4Zvq8DdC5OeNr8Rdgd3gAlWydOBYC+6fP9wcWps/HAmNz6j2W/lL3B17NKR8B/HdLx5UnzgeBU8otPqAD8AJwdDnFBvQEngS+zCeJoyziI3/iKJfY9gbeIP1wU0vE56mqlrFvRPwNIP25T1reA8i9UXBNWtYjfV6/fKchqRIYSPKXeVnEl07jzAXeAR6PiLKJLfVfwDXA5pyycokvgOmSZku6LC0rl9g+DawE7kqnGX8laU+aMT4njp1LvvnFaKB8pyBpL2AycGVEvNdQ1TxlO218EVEbEQNI/jI/StIRDVTfpWKT9DXgnYiYXewhecp22viA4yNiEHA68C+SvtRA3V0ttlYk09+3R8RA4AOSqalCmjw+J46WsULS/gDpz3fS8hqgV069nsCytLxnnvIWJ6k1SdIYHxG/S4vLJj6AiFgDzACGUD6xHQ+cIWkJMBH4sqT/oUzii4hl6c93gCnAUZRJbCTjqknPgAEmkSSSZovPiaNlTAMuSp9fRLI2UFc+XFJbSb2BQ4Dn09POdZKOST/18I2cY1pMOpZfA69ExH/m7Nrl45PUXVLn9Hl74GTgVcogNoCIGBsRPSOiEhgOPBURF1IG8UnaU1LHuufAqcA8yiA2gIhYDiyV1CctGgwsoDnja+mFnnJ/ABOAvwEbSTL8PwFdSRYlX0t/dsmpfy3Jpx4WkvMJB6CK5B//68DPqbcw1kKxfYHk1PYlYG76+Eo5xAf0A+aksc0DrkvLd/nY8sR6Ip8sju/y8ZGsAbyYPuYD15ZLbDnjGgBUp/8+pwKfas74fMkRMzPLxFNVZmaWiROHmZll4sRhZmaZOHGYmVkmThxmZpaJE4dZHpJC0j05260kray7iuwOtn2ipLXp5SIWSnom/Sb39rZXKekfcrYvlvTzHR2nWSFOHGb5fQAckX75D5KLN77dhO3/KSIGRkQf4Arg55IGb2dblcA/NFbJrKk4cZgV9gjw1fT5CJIvcwIg6ShJf07PGv5c9y1eSd+VNC593lfSPEkdGuokIuYCPwZGpcd1lzRZ0qz0cXxafr2keyQ9ld5z4VtpEzcAX1Ry74mr0rIDJD2a1ruxSV4Ns5QTh1lhE0ku1dCO5Jvkz+XsexX4UiQXmbsO+H/T8v8CDpY0DLgL+OeI+LCIvl4ADk2f3wrcEhGfB84BfpVTrx9JMjsWuE7SASQXuPtTRAyIiFvSegOA84G+wPmScq9VZLZDWrX0AMx2VhHxUnq5+BHAw/V2dwJ+I+kQksuutE6P2SzpYpJLQfx3RMwssrvcK5WeDByWczO2veuuvQQ8GBEfAR9Jeprk4n1r8rT3ZESsBZC0ADiIrS+tbbbdnDjMGjYNuJnkek5dc8p/AjwdEcPS5DIjZ98hwPvAARn6GQi8kj7fAzg2TRBbpImk/jWCCl0z6OOc57X4/7o1IU9VmTVsHPDjiHi5XnknPlksv7iuUFInkqmmLwFdJZ3bWAeS+gE/BH6RFk0nXe9I9w/IqX6mkvuhdyVJZrOAdSS37jVrFk4cZg2IiJqIuDXPrhuBf5M0E6jIKb8F+P8i4q8kV0K+QdI+eY7/Yt3HcUkSxhUR8WS67wqgStJL6TTTyJzjngceAv4C/CSS+068BGyS9GLO4rhZyfjquGa7CEnXA+9HxM0tPRbbvfmMw8zMMvEZh5mZZeIzDjMzy8SJw8zMMnHiMDOzTJw4zMwsEycOMzPL5P8HbPyZIv1YFD8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_depth_values = [500, 1000, 1500, 2000, 2500, 3000,3500,4000,5000,6000]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for max_depth_val in max_depth_values:\n",
    "    dtree2 = DecisionTreeClassifier(criterion='entropy', max_depth=max_depth_val, splitter='best', random_state=42)\n",
    "    \n",
    "    # Calculate training score\n",
    "    train_score = np.mean(cross_val_score(dtree2, X_train, y_train, cv=5))\n",
    "    train_scores.append(train_score)\n",
    "\n",
    "    # Calculate test score\n",
    "    test_score = np.mean(cross_val_score(dtree2, X_test, y_test, cv=5))  # Assuming X_test and y_test are your test data\n",
    "    test_scores.append(test_score)\n",
    "\n",
    "plt.plot(max_depth_values, train_scores, marker='o', label='Train Accuracy')\n",
    "plt.plot(max_depth_values, test_scores, marker='o', label='Test Accuracy')\n",
    "plt.title('Max Depth vs. Accuracy')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.5 Random Forest Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators' : [100,300,500,1000], # number of trees \n",
    "              'criterion' : ['gini','entropy','log_loss'], # function that measures quality of split\n",
    "              'max_depth' : [100,300,500]} # max depth of the tree, expands till less samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy',verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5] END criterion=gini, max_depth=100, n_estimators=100;, score=0.798 total time=   0.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=100, n_estimators=100;, score=0.790 total time=   0.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=100, n_estimators=100;, score=0.800 total time=   0.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=100, n_estimators=100;, score=0.804 total time=   0.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=100, n_estimators=100;, score=0.804 total time=   0.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=100, n_estimators=300;, score=0.795 total time=   1.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=100, n_estimators=300;, score=0.802 total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=100, n_estimators=300;, score=0.796 total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=100, n_estimators=300;, score=0.815 total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=100, n_estimators=300;, score=0.812 total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=100, n_estimators=500;, score=0.797 total time=   2.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=100, n_estimators=500;, score=0.804 total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=100, n_estimators=500;, score=0.801 total time=   1.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=100, n_estimators=500;, score=0.815 total time=   1.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=100, n_estimators=500;, score=0.811 total time=   2.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=100, n_estimators=1000;, score=0.797 total time=   4.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=100, n_estimators=1000;, score=0.801 total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=100, n_estimators=1000;, score=0.800 total time=   4.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=100, n_estimators=1000;, score=0.815 total time=   4.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=100, n_estimators=1000;, score=0.812 total time=   4.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=300, n_estimators=100;, score=0.798 total time=   0.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=300, n_estimators=100;, score=0.790 total time=   0.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=300, n_estimators=100;, score=0.800 total time=   0.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=300, n_estimators=100;, score=0.804 total time=   0.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=300, n_estimators=100;, score=0.804 total time=   0.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=300, n_estimators=300;, score=0.795 total time=   1.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=300, n_estimators=300;, score=0.802 total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=300, n_estimators=300;, score=0.796 total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=300, n_estimators=300;, score=0.815 total time=   1.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=300, n_estimators=300;, score=0.812 total time=   1.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=300, n_estimators=500;, score=0.797 total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=300, n_estimators=500;, score=0.804 total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=300, n_estimators=500;, score=0.801 total time=   1.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=300, n_estimators=500;, score=0.815 total time=   2.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=300, n_estimators=500;, score=0.811 total time=   2.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=300, n_estimators=1000;, score=0.797 total time=   4.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=300, n_estimators=1000;, score=0.801 total time=   4.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=300, n_estimators=1000;, score=0.800 total time=   4.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=300, n_estimators=1000;, score=0.815 total time=   4.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=300, n_estimators=1000;, score=0.812 total time=   3.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=500, n_estimators=100;, score=0.798 total time=   0.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=500, n_estimators=100;, score=0.790 total time=   0.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=500, n_estimators=100;, score=0.800 total time=   0.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=500, n_estimators=100;, score=0.804 total time=   0.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=500, n_estimators=100;, score=0.804 total time=   0.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=500, n_estimators=300;, score=0.795 total time=   1.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=500, n_estimators=300;, score=0.802 total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=500, n_estimators=300;, score=0.796 total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=500, n_estimators=300;, score=0.815 total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=500, n_estimators=300;, score=0.812 total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=500, n_estimators=500;, score=0.797 total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=500, n_estimators=500;, score=0.804 total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=500, n_estimators=500;, score=0.801 total time=   1.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=500, n_estimators=500;, score=0.815 total time=   2.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=500, n_estimators=500;, score=0.811 total time=   1.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=500, n_estimators=1000;, score=0.797 total time=   4.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=500, n_estimators=1000;, score=0.801 total time=   4.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=500, n_estimators=1000;, score=0.800 total time=   4.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=500, n_estimators=1000;, score=0.815 total time=   5.5s\n",
      "[CV 5/5] END criterion=gini, max_depth=500, n_estimators=1000;, score=0.812 total time=   5.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=100, n_estimators=100;, score=0.794 total time=   0.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=100, n_estimators=100;, score=0.800 total time=   0.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=100, n_estimators=100;, score=0.786 total time=   0.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=100, n_estimators=100;, score=0.818 total time=   0.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=100, n_estimators=100;, score=0.807 total time=   0.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=100, n_estimators=300;, score=0.794 total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=100, n_estimators=300;, score=0.798 total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=100, n_estimators=300;, score=0.800 total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=100, n_estimators=300;, score=0.815 total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=100, n_estimators=300;, score=0.812 total time=   1.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=100, n_estimators=500;, score=0.793 total time=   2.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=100, n_estimators=500;, score=0.797 total time=   3.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=100, n_estimators=500;, score=0.797 total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=100, n_estimators=500;, score=0.811 total time=   2.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=100, n_estimators=500;, score=0.811 total time=   2.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=100, n_estimators=1000;, score=0.799 total time=   4.7s\n",
      "[CV 2/5] END criterion=entropy, max_depth=100, n_estimators=1000;, score=0.800 total time=   4.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=100, n_estimators=1000;, score=0.800 total time=   5.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=100, n_estimators=1000;, score=0.814 total time=   6.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=100, n_estimators=1000;, score=0.811 total time=   6.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=300, n_estimators=100;, score=0.794 total time=   0.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=300, n_estimators=100;, score=0.800 total time=   0.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=300, n_estimators=100;, score=0.786 total time=   0.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=300, n_estimators=100;, score=0.818 total time=   0.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=300, n_estimators=100;, score=0.807 total time=   0.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=300, n_estimators=300;, score=0.794 total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=entropy, max_depth=300, n_estimators=300;, score=0.798 total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=300, n_estimators=300;, score=0.800 total time=   1.8s\n",
      "[CV 4/5] END criterion=entropy, max_depth=300, n_estimators=300;, score=0.815 total time=   1.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=300, n_estimators=300;, score=0.812 total time=   1.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=300, n_estimators=500;, score=0.793 total time=   2.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=300, n_estimators=500;, score=0.797 total time=   2.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=300, n_estimators=500;, score=0.797 total time=   2.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=300, n_estimators=500;, score=0.811 total time=   2.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=300, n_estimators=500;, score=0.811 total time=   2.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=300, n_estimators=1000;, score=0.799 total time=   5.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=300, n_estimators=1000;, score=0.800 total time=   6.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=300, n_estimators=1000;, score=0.800 total time=   6.7s\n",
      "[CV 4/5] END criterion=entropy, max_depth=300, n_estimators=1000;, score=0.814 total time=   6.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=300, n_estimators=1000;, score=0.811 total time=   7.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=500, n_estimators=100;, score=0.794 total time=   0.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=500, n_estimators=100;, score=0.800 total time=   0.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=500, n_estimators=100;, score=0.786 total time=   0.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=500, n_estimators=100;, score=0.818 total time=   0.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=500, n_estimators=100;, score=0.807 total time=   0.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=500, n_estimators=300;, score=0.794 total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=500, n_estimators=300;, score=0.798 total time=   1.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=500, n_estimators=300;, score=0.800 total time=   1.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=500, n_estimators=300;, score=0.815 total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=500, n_estimators=300;, score=0.812 total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=500, n_estimators=500;, score=0.793 total time=   2.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=500, n_estimators=500;, score=0.797 total time=   2.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=500, n_estimators=500;, score=0.797 total time=   2.7s\n",
      "[CV 4/5] END criterion=entropy, max_depth=500, n_estimators=500;, score=0.811 total time=   2.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=500, n_estimators=500;, score=0.811 total time=   2.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=500, n_estimators=1000;, score=0.799 total time=   5.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=500, n_estimators=1000;, score=0.800 total time=   5.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=500, n_estimators=1000;, score=0.800 total time=   5.7s\n",
      "[CV 4/5] END criterion=entropy, max_depth=500, n_estimators=1000;, score=0.814 total time=   6.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=500, n_estimators=1000;, score=0.811 total time=   7.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=100, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=100, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=100, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=100, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=100, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=100, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=100, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=100, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=100, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=100, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=100, n_estimators=500;, score=nan total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=100, n_estimators=500;, score=nan total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=100, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=100, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=100, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=100, n_estimators=1000;, score=nan total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=100, n_estimators=1000;, score=nan total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=100, n_estimators=1000;, score=nan total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=100, n_estimators=1000;, score=nan total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=100, n_estimators=1000;, score=nan total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=300, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=300, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=300, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=300, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=300, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=300, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=300, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=300, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=300, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=300, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=300, n_estimators=500;, score=nan total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=300, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=300, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=300, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=300, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=300, n_estimators=1000;, score=nan total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=300, n_estimators=1000;, score=nan total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=300, n_estimators=1000;, score=nan total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=300, n_estimators=1000;, score=nan total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=300, n_estimators=1000;, score=nan total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=500, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=500, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=500, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=500, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=500, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=500, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=500, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=500, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=500, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=500, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=500, n_estimators=500;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=log_loss, max_depth=500, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=500, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=500, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=500, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=500, n_estimators=1000;, score=nan total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=500, n_estimators=1000;, score=nan total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=500, n_estimators=1000;, score=nan total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=500, n_estimators=1000;, score=nan total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=500, n_estimators=1000;, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.79934081 0.80389821 0.80562629 0.80515508 0.79934081 0.80389821\n",
      " 0.80562629 0.80515508 0.79934081 0.80389821 0.80562629 0.80515508\n",
      " 0.80091227 0.80389821 0.80201265 0.80499785 0.80091227 0.80389821\n",
      " 0.80201265 0.80499785 0.80091227 0.80389821 0.80201265 0.80499785\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_depth': [100, 300, 500],\n",
       "                         'n_estimators': [100, 300, 500, 1000]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8056262876283924\n",
      "{'criterion': 'gini', 'max_depth': 100, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Model from GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(criterion = 'gini', max_depth = 100,n_estimators = 500,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=100, n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier(max_depth=100, n_estimators=500, random_state=42)\n",
      "\n",
      "Training score: 1.0\n",
      "Testing score: 0.7969208211143695\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.72      0.78      1389\n",
      "           1       0.75      0.88      0.81      1339\n",
      "\n",
      "    accuracy                           0.80      2728\n",
      "   macro avg       0.80      0.80      0.80      2728\n",
      "weighted avg       0.81      0.80      0.80      2728\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_scores_classification(rf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.5 SVC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C' : [0.2,0.6,1,2], #compare the C accuracy as it goes? instead of just using gridsearch which may not be too efficient\n",
    "              'kernel' : ['linear','poly','rbf','sigmoid'],\n",
    "              'gamma' : ['scale','auto'],# compare accuracy against gamma number also instead of just gridsearch \n",
    "              'max_iter' : [1000,3000,5000]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=svc, param_grid=param_grid, scoring='accuracy',verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, gamma=scale, kernel=linear, max_iter=1000;, score=0.467 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, gamma=scale, kernel=linear, max_iter=1000;, score=0.540 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, gamma=scale, kernel=linear, max_iter=1000;, score=0.581 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, gamma=scale, kernel=linear, max_iter=1000;, score=0.566 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, gamma=scale, kernel=linear, max_iter=1000;, score=0.512 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, gamma=scale, kernel=linear, max_iter=3000;, score=0.519 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, gamma=scale, kernel=linear, max_iter=3000;, score=0.532 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, gamma=scale, kernel=linear, max_iter=3000;, score=0.514 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, gamma=scale, kernel=linear, max_iter=3000;, score=0.599 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, gamma=scale, kernel=linear, max_iter=3000;, score=0.516 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, gamma=scale, kernel=linear, max_iter=5000;, score=0.539 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, gamma=scale, kernel=linear, max_iter=5000;, score=0.537 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, gamma=scale, kernel=linear, max_iter=5000;, score=0.558 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, gamma=scale, kernel=linear, max_iter=5000;, score=0.600 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, gamma=scale, kernel=linear, max_iter=5000;, score=0.502 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, gamma=scale, kernel=poly, max_iter=1000;, score=0.544 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, gamma=scale, kernel=poly, max_iter=1000;, score=0.527 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, gamma=scale, kernel=poly, max_iter=1000;, score=0.516 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, gamma=scale, kernel=poly, max_iter=1000;, score=0.526 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, gamma=scale, kernel=poly, max_iter=1000;, score=0.535 total time=   0.4s\n",
      "[CV 1/5] END C=0.2, gamma=scale, kernel=poly, max_iter=3000;, score=0.507 total time=   1.4s\n",
      "[CV 2/5] END C=0.2, gamma=scale, kernel=poly, max_iter=3000;, score=0.504 total time=   1.5s\n",
      "[CV 3/5] END C=0.2, gamma=scale, kernel=poly, max_iter=3000;, score=0.519 total time=   1.4s\n",
      "[CV 4/5] END C=0.2, gamma=scale, kernel=poly, max_iter=3000;, score=0.526 total time=   1.4s\n",
      "[CV 5/5] END C=0.2, gamma=scale, kernel=poly, max_iter=3000;, score=0.516 total time=   1.8s\n",
      "[CV 1/5] END C=0.2, gamma=scale, kernel=poly, max_iter=5000;, score=0.507 total time=   1.9s\n",
      "[CV 2/5] END C=0.2, gamma=scale, kernel=poly, max_iter=5000;, score=0.504 total time=   1.6s\n",
      "[CV 3/5] END C=0.2, gamma=scale, kernel=poly, max_iter=5000;, score=0.519 total time=   1.2s\n",
      "[CV 4/5] END C=0.2, gamma=scale, kernel=poly, max_iter=5000;, score=0.526 total time=   1.2s\n",
      "[CV 5/5] END C=0.2, gamma=scale, kernel=poly, max_iter=5000;, score=0.516 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, gamma=scale, kernel=rbf, max_iter=1000;, score=0.544 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, gamma=scale, kernel=rbf, max_iter=1000;, score=0.563 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, gamma=scale, kernel=rbf, max_iter=1000;, score=0.466 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, gamma=scale, kernel=rbf, max_iter=1000;, score=0.526 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, gamma=scale, kernel=rbf, max_iter=1000;, score=0.486 total time=   0.6s\n",
      "[CV 1/5] END C=0.2, gamma=scale, kernel=rbf, max_iter=3000;, score=0.530 total time=   2.2s\n",
      "[CV 2/5] END C=0.2, gamma=scale, kernel=rbf, max_iter=3000;, score=0.531 total time=   2.2s\n",
      "[CV 3/5] END C=0.2, gamma=scale, kernel=rbf, max_iter=3000;, score=0.553 total time=   2.4s\n",
      "[CV 4/5] END C=0.2, gamma=scale, kernel=rbf, max_iter=3000;, score=0.528 total time=   2.3s\n",
      "[CV 5/5] END C=0.2, gamma=scale, kernel=rbf, max_iter=3000;, score=0.526 total time=   2.2s\n",
      "[CV 1/5] END C=0.2, gamma=scale, kernel=rbf, max_iter=5000;, score=0.530 total time=   2.4s\n",
      "[CV 2/5] END C=0.2, gamma=scale, kernel=rbf, max_iter=5000;, score=0.531 total time=   2.4s\n",
      "[CV 3/5] END C=0.2, gamma=scale, kernel=rbf, max_iter=5000;, score=0.553 total time=   2.3s\n",
      "[CV 4/5] END C=0.2, gamma=scale, kernel=rbf, max_iter=5000;, score=0.528 total time=   2.1s\n",
      "[CV 5/5] END C=0.2, gamma=scale, kernel=rbf, max_iter=5000;, score=0.526 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.463 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.520 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.546 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.527 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.458 total time=   0.6s\n",
      "[CV 1/5] END C=0.2, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.494 total time=   1.3s\n",
      "[CV 2/5] END C=0.2, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.520 total time=   1.2s\n",
      "[CV 3/5] END C=0.2, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.546 total time=   0.9s\n",
      "[CV 4/5] END C=0.2, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.527 total time=   1.0s\n",
      "[CV 5/5] END C=0.2, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.488 total time=   1.2s\n",
      "[CV 1/5] END C=0.2, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.494 total time=   1.4s\n",
      "[CV 2/5] END C=0.2, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.520 total time=   1.3s\n",
      "[CV 3/5] END C=0.2, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.546 total time=   1.2s\n",
      "[CV 4/5] END C=0.2, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.527 total time=   1.1s\n",
      "[CV 5/5] END C=0.2, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.488 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, gamma=auto, kernel=linear, max_iter=1000;, score=0.467 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, gamma=auto, kernel=linear, max_iter=1000;, score=0.540 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, gamma=auto, kernel=linear, max_iter=1000;, score=0.581 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, gamma=auto, kernel=linear, max_iter=1000;, score=0.566 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, gamma=auto, kernel=linear, max_iter=1000;, score=0.512 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, gamma=auto, kernel=linear, max_iter=3000;, score=0.519 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, gamma=auto, kernel=linear, max_iter=3000;, score=0.532 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, gamma=auto, kernel=linear, max_iter=3000;, score=0.514 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, gamma=auto, kernel=linear, max_iter=3000;, score=0.599 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, gamma=auto, kernel=linear, max_iter=3000;, score=0.516 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, gamma=auto, kernel=linear, max_iter=5000;, score=0.539 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, gamma=auto, kernel=linear, max_iter=5000;, score=0.537 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, gamma=auto, kernel=linear, max_iter=5000;, score=0.558 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, gamma=auto, kernel=linear, max_iter=5000;, score=0.600 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, gamma=auto, kernel=linear, max_iter=5000;, score=0.502 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, gamma=auto, kernel=poly, max_iter=1000;, score=0.608 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, gamma=auto, kernel=poly, max_iter=1000;, score=0.537 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, gamma=auto, kernel=poly, max_iter=1000;, score=0.554 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, gamma=auto, kernel=poly, max_iter=1000;, score=0.474 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, gamma=auto, kernel=poly, max_iter=1000;, score=0.656 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, gamma=auto, kernel=poly, max_iter=3000;, score=0.554 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, gamma=auto, kernel=poly, max_iter=3000;, score=0.537 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, gamma=auto, kernel=poly, max_iter=3000;, score=0.636 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, gamma=auto, kernel=poly, max_iter=3000;, score=0.570 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, gamma=auto, kernel=poly, max_iter=3000;, score=0.563 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, gamma=auto, kernel=poly, max_iter=5000;, score=0.554 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, gamma=auto, kernel=poly, max_iter=5000;, score=0.537 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, gamma=auto, kernel=poly, max_iter=5000;, score=0.636 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, gamma=auto, kernel=poly, max_iter=5000;, score=0.570 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, gamma=auto, kernel=poly, max_iter=5000;, score=0.564 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, gamma=auto, kernel=rbf, max_iter=1000;, score=0.661 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, gamma=auto, kernel=rbf, max_iter=1000;, score=0.597 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, gamma=auto, kernel=rbf, max_iter=1000;, score=0.597 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, gamma=auto, kernel=rbf, max_iter=1000;, score=0.641 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, gamma=auto, kernel=rbf, max_iter=1000;, score=0.585 total time=   1.3s\n",
      "[CV 1/5] END C=0.2, gamma=auto, kernel=rbf, max_iter=3000;, score=0.663 total time=   3.3s\n",
      "[CV 2/5] END C=0.2, gamma=auto, kernel=rbf, max_iter=3000;, score=0.662 total time=   3.3s\n",
      "[CV 3/5] END C=0.2, gamma=auto, kernel=rbf, max_iter=3000;, score=0.698 total time=   3.2s\n",
      "[CV 4/5] END C=0.2, gamma=auto, kernel=rbf, max_iter=3000;, score=0.648 total time=   3.1s\n",
      "[CV 5/5] END C=0.2, gamma=auto, kernel=rbf, max_iter=3000;, score=0.667 total time=   3.3s\n",
      "[CV 1/5] END C=0.2, gamma=auto, kernel=rbf, max_iter=5000;, score=0.663 total time=   3.4s\n",
      "[CV 2/5] END C=0.2, gamma=auto, kernel=rbf, max_iter=5000;, score=0.662 total time=   3.5s\n",
      "[CV 3/5] END C=0.2, gamma=auto, kernel=rbf, max_iter=5000;, score=0.698 total time=   3.5s\n",
      "[CV 4/5] END C=0.2, gamma=auto, kernel=rbf, max_iter=5000;, score=0.648 total time=   3.8s\n",
      "[CV 5/5] END C=0.2, gamma=auto, kernel=rbf, max_iter=5000;, score=0.667 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.2, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.2, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.2, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.2, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.4s\n",
      "[CV 1/5] END C=0.2, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.4s\n",
      "[CV 2/5] END C=0.2, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.4s\n",
      "[CV 3/5] END C=0.2, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.2s\n",
      "[CV 4/5] END C=0.2, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.3s\n",
      "[CV 5/5] END C=0.2, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.3s\n",
      "[CV 1/5] END C=0.2, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.2s\n",
      "[CV 2/5] END C=0.2, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.2s\n",
      "[CV 3/5] END C=0.2, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.3s\n",
      "[CV 4/5] END C=0.2, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.3s\n",
      "[CV 5/5] END C=0.2, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6, gamma=scale, kernel=linear, max_iter=1000;, score=0.509 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.6, gamma=scale, kernel=linear, max_iter=1000;, score=0.541 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.6, gamma=scale, kernel=linear, max_iter=1000;, score=0.524 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.6, gamma=scale, kernel=linear, max_iter=1000;, score=0.515 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.6, gamma=scale, kernel=linear, max_iter=1000;, score=0.514 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6, gamma=scale, kernel=linear, max_iter=3000;, score=0.533 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.6, gamma=scale, kernel=linear, max_iter=3000;, score=0.543 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.6, gamma=scale, kernel=linear, max_iter=3000;, score=0.643 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.6, gamma=scale, kernel=linear, max_iter=3000;, score=0.515 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.6, gamma=scale, kernel=linear, max_iter=3000;, score=0.514 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6, gamma=scale, kernel=linear, max_iter=5000;, score=0.485 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.6, gamma=scale, kernel=linear, max_iter=5000;, score=0.548 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.6, gamma=scale, kernel=linear, max_iter=5000;, score=0.643 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.6, gamma=scale, kernel=linear, max_iter=5000;, score=0.515 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.6, gamma=scale, kernel=linear, max_iter=5000;, score=0.514 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6, gamma=scale, kernel=poly, max_iter=1000;, score=0.551 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.6, gamma=scale, kernel=poly, max_iter=1000;, score=0.537 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.6, gamma=scale, kernel=poly, max_iter=1000;, score=0.521 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.6, gamma=scale, kernel=poly, max_iter=1000;, score=0.527 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.6, gamma=scale, kernel=poly, max_iter=1000;, score=0.532 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6, gamma=scale, kernel=poly, max_iter=3000;, score=0.507 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.6, gamma=scale, kernel=poly, max_iter=3000;, score=0.496 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.6, gamma=scale, kernel=poly, max_iter=3000;, score=0.496 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.6, gamma=scale, kernel=poly, max_iter=3000;, score=0.526 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.6, gamma=scale, kernel=poly, max_iter=3000;, score=0.516 total time=   1.6s\n",
      "[CV 1/5] END C=0.6, gamma=scale, kernel=poly, max_iter=5000;, score=0.507 total time=   1.6s\n",
      "[CV 2/5] END C=0.6, gamma=scale, kernel=poly, max_iter=5000;, score=0.504 total time=   1.4s\n",
      "[CV 3/5] END C=0.6, gamma=scale, kernel=poly, max_iter=5000;, score=0.519 total time=   1.3s\n",
      "[CV 4/5] END C=0.6, gamma=scale, kernel=poly, max_iter=5000;, score=0.526 total time=   1.3s\n",
      "[CV 5/5] END C=0.6, gamma=scale, kernel=poly, max_iter=5000;, score=0.516 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6, gamma=scale, kernel=rbf, max_iter=1000;, score=0.467 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.6, gamma=scale, kernel=rbf, max_iter=1000;, score=0.519 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.6, gamma=scale, kernel=rbf, max_iter=1000;, score=0.555 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.6, gamma=scale, kernel=rbf, max_iter=1000;, score=0.499 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.6, gamma=scale, kernel=rbf, max_iter=1000;, score=0.517 total time=   0.8s\n",
      "[CV 1/5] END C=0.6, gamma=scale, kernel=rbf, max_iter=3000;, score=0.530 total time=   2.2s\n",
      "[CV 2/5] END C=0.6, gamma=scale, kernel=rbf, max_iter=3000;, score=0.531 total time=   2.3s\n",
      "[CV 3/5] END C=0.6, gamma=scale, kernel=rbf, max_iter=3000;, score=0.553 total time=   2.0s\n",
      "[CV 4/5] END C=0.6, gamma=scale, kernel=rbf, max_iter=3000;, score=0.528 total time=   1.9s\n",
      "[CV 5/5] END C=0.6, gamma=scale, kernel=rbf, max_iter=3000;, score=0.526 total time=   1.9s\n",
      "[CV 1/5] END C=0.6, gamma=scale, kernel=rbf, max_iter=5000;, score=0.530 total time=   1.9s\n",
      "[CV 2/5] END C=0.6, gamma=scale, kernel=rbf, max_iter=5000;, score=0.531 total time=   1.9s\n",
      "[CV 3/5] END C=0.6, gamma=scale, kernel=rbf, max_iter=5000;, score=0.553 total time=   1.9s\n",
      "[CV 4/5] END C=0.6, gamma=scale, kernel=rbf, max_iter=5000;, score=0.528 total time=   1.9s\n",
      "[CV 5/5] END C=0.6, gamma=scale, kernel=rbf, max_iter=5000;, score=0.526 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.463 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.6, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.521 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.6, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.546 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.6, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.527 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.6, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.458 total time=   0.5s\n",
      "[CV 1/5] END C=0.6, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.494 total time=   1.1s\n",
      "[CV 2/5] END C=0.6, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.520 total time=   0.9s\n",
      "[CV 3/5] END C=0.6, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.546 total time=   1.0s\n",
      "[CV 4/5] END C=0.6, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.527 total time=   1.0s\n",
      "[CV 5/5] END C=0.6, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.488 total time=   1.1s\n",
      "[CV 1/5] END C=0.6, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.494 total time=   1.2s\n",
      "[CV 2/5] END C=0.6, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.520 total time=   1.1s\n",
      "[CV 3/5] END C=0.6, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.546 total time=   1.0s\n",
      "[CV 4/5] END C=0.6, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.527 total time=   1.0s\n",
      "[CV 5/5] END C=0.6, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.488 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6, gamma=auto, kernel=linear, max_iter=1000;, score=0.509 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.6, gamma=auto, kernel=linear, max_iter=1000;, score=0.541 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.6, gamma=auto, kernel=linear, max_iter=1000;, score=0.524 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.6, gamma=auto, kernel=linear, max_iter=1000;, score=0.515 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.6, gamma=auto, kernel=linear, max_iter=1000;, score=0.514 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6, gamma=auto, kernel=linear, max_iter=3000;, score=0.533 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.6, gamma=auto, kernel=linear, max_iter=3000;, score=0.543 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.6, gamma=auto, kernel=linear, max_iter=3000;, score=0.643 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.6, gamma=auto, kernel=linear, max_iter=3000;, score=0.515 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.6, gamma=auto, kernel=linear, max_iter=3000;, score=0.514 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6, gamma=auto, kernel=linear, max_iter=5000;, score=0.485 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.6, gamma=auto, kernel=linear, max_iter=5000;, score=0.548 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.6, gamma=auto, kernel=linear, max_iter=5000;, score=0.643 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.6, gamma=auto, kernel=linear, max_iter=5000;, score=0.515 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.6, gamma=auto, kernel=linear, max_iter=5000;, score=0.514 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6, gamma=auto, kernel=poly, max_iter=1000;, score=0.581 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.6, gamma=auto, kernel=poly, max_iter=1000;, score=0.504 total time=   0.3s\n",
      "[CV 3/5] END C=0.6, gamma=auto, kernel=poly, max_iter=1000;, score=0.536 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.6, gamma=auto, kernel=poly, max_iter=1000;, score=0.547 total time=   0.2s\n",
      "[CV 5/5] END C=0.6, gamma=auto, kernel=poly, max_iter=1000;, score=0.539 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6, gamma=auto, kernel=poly, max_iter=3000;, score=0.550 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.6, gamma=auto, kernel=poly, max_iter=3000;, score=0.612 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.6, gamma=auto, kernel=poly, max_iter=3000;, score=0.536 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.6, gamma=auto, kernel=poly, max_iter=3000;, score=0.584 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.6, gamma=auto, kernel=poly, max_iter=3000;, score=0.539 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6, gamma=auto, kernel=poly, max_iter=5000;, score=0.550 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.6, gamma=auto, kernel=poly, max_iter=5000;, score=0.612 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.6, gamma=auto, kernel=poly, max_iter=5000;, score=0.536 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.6, gamma=auto, kernel=poly, max_iter=5000;, score=0.593 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.6, gamma=auto, kernel=poly, max_iter=5000;, score=0.539 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6, gamma=auto, kernel=rbf, max_iter=1000;, score=0.639 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.6, gamma=auto, kernel=rbf, max_iter=1000;, score=0.603 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.6, gamma=auto, kernel=rbf, max_iter=1000;, score=0.645 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.6, gamma=auto, kernel=rbf, max_iter=1000;, score=0.657 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.6, gamma=auto, kernel=rbf, max_iter=1000;, score=0.641 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6, gamma=auto, kernel=rbf, max_iter=3000;, score=0.698 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.6, gamma=auto, kernel=rbf, max_iter=3000;, score=0.707 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.6, gamma=auto, kernel=rbf, max_iter=3000;, score=0.723 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.6, gamma=auto, kernel=rbf, max_iter=3000;, score=0.698 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.6, gamma=auto, kernel=rbf, max_iter=3000;, score=0.726 total time=   2.9s\n",
      "[CV 1/5] END C=0.6, gamma=auto, kernel=rbf, max_iter=5000;, score=0.697 total time=   4.1s\n",
      "[CV 2/5] END C=0.6, gamma=auto, kernel=rbf, max_iter=5000;, score=0.707 total time=   3.3s\n",
      "[CV 3/5] END C=0.6, gamma=auto, kernel=rbf, max_iter=5000;, score=0.723 total time=   3.5s\n",
      "[CV 4/5] END C=0.6, gamma=auto, kernel=rbf, max_iter=5000;, score=0.698 total time=   3.0s\n",
      "[CV 5/5] END C=0.6, gamma=auto, kernel=rbf, max_iter=5000;, score=0.726 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.6, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.6, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.6, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.6, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.4s\n",
      "[CV 1/5] END C=0.6, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.2s\n",
      "[CV 2/5] END C=0.6, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.3s\n",
      "[CV 3/5] END C=0.6, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.2s\n",
      "[CV 4/5] END C=0.6, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.2s\n",
      "[CV 5/5] END C=0.6, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.1s\n",
      "[CV 1/5] END C=0.6, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.1s\n",
      "[CV 2/5] END C=0.6, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.1s\n",
      "[CV 3/5] END C=0.6, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.1s\n",
      "[CV 4/5] END C=0.6, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.1s\n",
      "[CV 5/5] END C=0.6, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, gamma=scale, kernel=linear, max_iter=1000;, score=0.522 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, gamma=scale, kernel=linear, max_iter=1000;, score=0.508 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, gamma=scale, kernel=linear, max_iter=1000;, score=0.592 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, gamma=scale, kernel=linear, max_iter=1000;, score=0.522 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, gamma=scale, kernel=linear, max_iter=1000;, score=0.496 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, gamma=scale, kernel=linear, max_iter=3000;, score=0.522 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, gamma=scale, kernel=linear, max_iter=3000;, score=0.507 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, gamma=scale, kernel=linear, max_iter=3000;, score=0.601 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, gamma=scale, kernel=linear, max_iter=3000;, score=0.522 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, gamma=scale, kernel=linear, max_iter=3000;, score=0.561 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, gamma=scale, kernel=linear, max_iter=5000;, score=0.522 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, gamma=scale, kernel=linear, max_iter=5000;, score=0.542 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, gamma=scale, kernel=linear, max_iter=5000;, score=0.592 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, gamma=scale, kernel=linear, max_iter=5000;, score=0.522 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, gamma=scale, kernel=linear, max_iter=5000;, score=0.552 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, gamma=scale, kernel=poly, max_iter=1000;, score=0.540 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, gamma=scale, kernel=poly, max_iter=1000;, score=0.534 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, gamma=scale, kernel=poly, max_iter=1000;, score=0.519 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, gamma=scale, kernel=poly, max_iter=1000;, score=0.530 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, gamma=scale, kernel=poly, max_iter=1000;, score=0.535 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, gamma=scale, kernel=poly, max_iter=3000;, score=0.507 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, gamma=scale, kernel=poly, max_iter=3000;, score=0.504 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, gamma=scale, kernel=poly, max_iter=3000;, score=0.519 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, gamma=scale, kernel=poly, max_iter=3000;, score=0.526 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, gamma=scale, kernel=poly, max_iter=3000;, score=0.540 total time=   1.4s\n",
      "[CV 1/5] END C=1, gamma=scale, kernel=poly, max_iter=5000;, score=0.507 total time=   1.6s\n",
      "[CV 2/5] END C=1, gamma=scale, kernel=poly, max_iter=5000;, score=0.504 total time=   1.5s\n",
      "[CV 3/5] END C=1, gamma=scale, kernel=poly, max_iter=5000;, score=0.519 total time=   1.4s\n",
      "[CV 4/5] END C=1, gamma=scale, kernel=poly, max_iter=5000;, score=0.526 total time=   1.2s\n",
      "[CV 5/5] END C=1, gamma=scale, kernel=poly, max_iter=5000;, score=0.516 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, gamma=scale, kernel=rbf, max_iter=1000;, score=0.532 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, gamma=scale, kernel=rbf, max_iter=1000;, score=0.521 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, gamma=scale, kernel=rbf, max_iter=1000;, score=0.466 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, gamma=scale, kernel=rbf, max_iter=1000;, score=0.507 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, gamma=scale, kernel=rbf, max_iter=1000;, score=0.486 total time=   0.8s\n",
      "[CV 1/5] END C=1, gamma=scale, kernel=rbf, max_iter=3000;, score=0.530 total time=   1.9s\n",
      "[CV 2/5] END C=1, gamma=scale, kernel=rbf, max_iter=3000;, score=0.531 total time=   1.8s\n",
      "[CV 3/5] END C=1, gamma=scale, kernel=rbf, max_iter=3000;, score=0.553 total time=   2.0s\n",
      "[CV 4/5] END C=1, gamma=scale, kernel=rbf, max_iter=3000;, score=0.528 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, gamma=scale, kernel=rbf, max_iter=3000;, score=0.528 total time=   1.9s\n",
      "[CV 1/5] END C=1, gamma=scale, kernel=rbf, max_iter=5000;, score=0.530 total time=   1.9s\n",
      "[CV 2/5] END C=1, gamma=scale, kernel=rbf, max_iter=5000;, score=0.531 total time=   2.0s\n",
      "[CV 3/5] END C=1, gamma=scale, kernel=rbf, max_iter=5000;, score=0.553 total time=   2.3s\n",
      "[CV 4/5] END C=1, gamma=scale, kernel=rbf, max_iter=5000;, score=0.528 total time=   1.9s\n",
      "[CV 5/5] END C=1, gamma=scale, kernel=rbf, max_iter=5000;, score=0.526 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.463 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.521 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.546 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.527 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.458 total time=   0.6s\n",
      "[CV 1/5] END C=1, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.494 total time=   1.3s\n",
      "[CV 2/5] END C=1, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.520 total time=   1.0s\n",
      "[CV 3/5] END C=1, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.546 total time=   1.0s\n",
      "[CV 4/5] END C=1, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.527 total time=   0.9s\n",
      "[CV 5/5] END C=1, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.488 total time=   1.0s\n",
      "[CV 1/5] END C=1, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.494 total time=   1.0s\n",
      "[CV 2/5] END C=1, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.520 total time=   0.9s\n",
      "[CV 3/5] END C=1, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.546 total time=   0.9s\n",
      "[CV 4/5] END C=1, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.527 total time=   0.9s\n",
      "[CV 5/5] END C=1, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.488 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, gamma=auto, kernel=linear, max_iter=1000;, score=0.522 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, gamma=auto, kernel=linear, max_iter=1000;, score=0.508 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, gamma=auto, kernel=linear, max_iter=1000;, score=0.592 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, gamma=auto, kernel=linear, max_iter=1000;, score=0.522 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, gamma=auto, kernel=linear, max_iter=1000;, score=0.496 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, gamma=auto, kernel=linear, max_iter=3000;, score=0.522 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, gamma=auto, kernel=linear, max_iter=3000;, score=0.507 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, gamma=auto, kernel=linear, max_iter=3000;, score=0.601 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, gamma=auto, kernel=linear, max_iter=3000;, score=0.522 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, gamma=auto, kernel=linear, max_iter=3000;, score=0.561 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, gamma=auto, kernel=linear, max_iter=5000;, score=0.522 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, gamma=auto, kernel=linear, max_iter=5000;, score=0.542 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, gamma=auto, kernel=linear, max_iter=5000;, score=0.592 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, gamma=auto, kernel=linear, max_iter=5000;, score=0.522 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, gamma=auto, kernel=linear, max_iter=5000;, score=0.552 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, gamma=auto, kernel=poly, max_iter=1000;, score=0.583 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, gamma=auto, kernel=poly, max_iter=1000;, score=0.537 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, gamma=auto, kernel=poly, max_iter=1000;, score=0.698 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, gamma=auto, kernel=poly, max_iter=1000;, score=0.526 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, gamma=auto, kernel=poly, max_iter=1000;, score=0.605 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, gamma=auto, kernel=poly, max_iter=3000;, score=0.583 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, gamma=auto, kernel=poly, max_iter=3000;, score=0.537 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, gamma=auto, kernel=poly, max_iter=3000;, score=0.633 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, gamma=auto, kernel=poly, max_iter=3000;, score=0.617 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, gamma=auto, kernel=poly, max_iter=3000;, score=0.538 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, gamma=auto, kernel=poly, max_iter=5000;, score=0.583 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, gamma=auto, kernel=poly, max_iter=5000;, score=0.537 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, gamma=auto, kernel=poly, max_iter=5000;, score=0.633 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, gamma=auto, kernel=poly, max_iter=5000;, score=0.583 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, gamma=auto, kernel=poly, max_iter=5000;, score=0.538 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, gamma=auto, kernel=rbf, max_iter=1000;, score=0.640 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, gamma=auto, kernel=rbf, max_iter=1000;, score=0.654 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, gamma=auto, kernel=rbf, max_iter=1000;, score=0.658 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, gamma=auto, kernel=rbf, max_iter=1000;, score=0.658 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, gamma=auto, kernel=rbf, max_iter=1000;, score=0.664 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, gamma=auto, kernel=rbf, max_iter=3000;, score=0.714 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, gamma=auto, kernel=rbf, max_iter=3000;, score=0.732 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, gamma=auto, kernel=rbf, max_iter=3000;, score=0.724 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, gamma=auto, kernel=rbf, max_iter=3000;, score=0.720 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, gamma=auto, kernel=rbf, max_iter=3000;, score=0.746 total time=   4.3s\n",
      "[CV 1/5] END C=1, gamma=auto, kernel=rbf, max_iter=5000;, score=0.714 total time=   3.1s\n",
      "[CV 2/5] END C=1, gamma=auto, kernel=rbf, max_iter=5000;, score=0.732 total time=   2.7s\n",
      "[CV 3/5] END C=1, gamma=auto, kernel=rbf, max_iter=5000;, score=0.724 total time=   2.8s\n",
      "[CV 4/5] END C=1, gamma=auto, kernel=rbf, max_iter=5000;, score=0.721 total time=   2.7s\n",
      "[CV 5/5] END C=1, gamma=auto, kernel=rbf, max_iter=5000;, score=0.746 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.4s\n",
      "[CV 1/5] END C=1, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.1s\n",
      "[CV 2/5] END C=1, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.2s\n",
      "[CV 3/5] END C=1, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.4s\n",
      "[CV 4/5] END C=1, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.4s\n",
      "[CV 5/5] END C=1, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.5s\n",
      "[CV 1/5] END C=1, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.4s\n",
      "[CV 2/5] END C=1, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.2s\n",
      "[CV 3/5] END C=1, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.4s\n",
      "[CV 4/5] END C=1, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.4s\n",
      "[CV 5/5] END C=1, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2, gamma=scale, kernel=linear, max_iter=1000;, score=0.498 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2, gamma=scale, kernel=linear, max_iter=1000;, score=0.511 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2, gamma=scale, kernel=linear, max_iter=1000;, score=0.609 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2, gamma=scale, kernel=linear, max_iter=1000;, score=0.549 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=scale, kernel=linear, max_iter=1000;, score=0.514 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2, gamma=scale, kernel=linear, max_iter=3000;, score=0.534 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2, gamma=scale, kernel=linear, max_iter=3000;, score=0.541 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2, gamma=scale, kernel=linear, max_iter=3000;, score=0.539 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2, gamma=scale, kernel=linear, max_iter=3000;, score=0.555 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=scale, kernel=linear, max_iter=3000;, score=0.530 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2, gamma=scale, kernel=linear, max_iter=5000;, score=0.528 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2, gamma=scale, kernel=linear, max_iter=5000;, score=0.547 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2, gamma=scale, kernel=linear, max_iter=5000;, score=0.544 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2, gamma=scale, kernel=linear, max_iter=5000;, score=0.535 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=scale, kernel=linear, max_iter=5000;, score=0.530 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2, gamma=scale, kernel=poly, max_iter=1000;, score=0.540 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2, gamma=scale, kernel=poly, max_iter=1000;, score=0.534 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2, gamma=scale, kernel=poly, max_iter=1000;, score=0.519 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2, gamma=scale, kernel=poly, max_iter=1000;, score=0.530 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=scale, kernel=poly, max_iter=1000;, score=0.535 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2, gamma=scale, kernel=poly, max_iter=3000;, score=0.507 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2, gamma=scale, kernel=poly, max_iter=3000;, score=0.504 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2, gamma=scale, kernel=poly, max_iter=3000;, score=0.519 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2, gamma=scale, kernel=poly, max_iter=3000;, score=0.504 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=scale, kernel=poly, max_iter=3000;, score=0.516 total time=   1.4s\n",
      "[CV 1/5] END C=2, gamma=scale, kernel=poly, max_iter=5000;, score=0.507 total time=   1.4s\n",
      "[CV 2/5] END C=2, gamma=scale, kernel=poly, max_iter=5000;, score=0.504 total time=   1.3s\n",
      "[CV 3/5] END C=2, gamma=scale, kernel=poly, max_iter=5000;, score=0.519 total time=   1.6s\n",
      "[CV 4/5] END C=2, gamma=scale, kernel=poly, max_iter=5000;, score=0.526 total time=   1.4s\n",
      "[CV 5/5] END C=2, gamma=scale, kernel=poly, max_iter=5000;, score=0.516 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2, gamma=scale, kernel=rbf, max_iter=1000;, score=0.532 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2, gamma=scale, kernel=rbf, max_iter=1000;, score=0.521 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2, gamma=scale, kernel=rbf, max_iter=1000;, score=0.466 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2, gamma=scale, kernel=rbf, max_iter=1000;, score=0.507 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=scale, kernel=rbf, max_iter=1000;, score=0.486 total time=   0.7s\n",
      "[CV 1/5] END C=2, gamma=scale, kernel=rbf, max_iter=3000;, score=0.530 total time=   2.0s\n",
      "[CV 2/5] END C=2, gamma=scale, kernel=rbf, max_iter=3000;, score=0.531 total time=   2.0s\n",
      "[CV 3/5] END C=2, gamma=scale, kernel=rbf, max_iter=3000;, score=0.553 total time=   1.9s\n",
      "[CV 4/5] END C=2, gamma=scale, kernel=rbf, max_iter=3000;, score=0.522 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=scale, kernel=rbf, max_iter=3000;, score=0.526 total time=   1.9s\n",
      "[CV 1/5] END C=2, gamma=scale, kernel=rbf, max_iter=5000;, score=0.530 total time=   1.9s\n",
      "[CV 2/5] END C=2, gamma=scale, kernel=rbf, max_iter=5000;, score=0.531 total time=   1.9s\n",
      "[CV 3/5] END C=2, gamma=scale, kernel=rbf, max_iter=5000;, score=0.553 total time=   1.9s\n",
      "[CV 4/5] END C=2, gamma=scale, kernel=rbf, max_iter=5000;, score=0.522 total time=   1.9s\n",
      "[CV 5/5] END C=2, gamma=scale, kernel=rbf, max_iter=5000;, score=0.526 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.463 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.521 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.540 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.527 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=scale, kernel=sigmoid, max_iter=1000;, score=0.458 total time=   0.5s\n",
      "[CV 1/5] END C=2, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.494 total time=   1.1s\n",
      "[CV 2/5] END C=2, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.520 total time=   1.0s\n",
      "[CV 3/5] END C=2, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.546 total time=   0.9s\n",
      "[CV 4/5] END C=2, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.527 total time=   1.0s\n",
      "[CV 5/5] END C=2, gamma=scale, kernel=sigmoid, max_iter=3000;, score=0.488 total time=   1.1s\n",
      "[CV 1/5] END C=2, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.494 total time=   1.1s\n",
      "[CV 2/5] END C=2, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.520 total time=   1.0s\n",
      "[CV 3/5] END C=2, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.546 total time=   1.0s\n",
      "[CV 4/5] END C=2, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.527 total time=   1.0s\n",
      "[CV 5/5] END C=2, gamma=scale, kernel=sigmoid, max_iter=5000;, score=0.488 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2, gamma=auto, kernel=linear, max_iter=1000;, score=0.498 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2, gamma=auto, kernel=linear, max_iter=1000;, score=0.511 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2, gamma=auto, kernel=linear, max_iter=1000;, score=0.609 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2, gamma=auto, kernel=linear, max_iter=1000;, score=0.549 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=auto, kernel=linear, max_iter=1000;, score=0.514 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2, gamma=auto, kernel=linear, max_iter=3000;, score=0.534 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2, gamma=auto, kernel=linear, max_iter=3000;, score=0.541 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2, gamma=auto, kernel=linear, max_iter=3000;, score=0.539 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2, gamma=auto, kernel=linear, max_iter=3000;, score=0.555 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=auto, kernel=linear, max_iter=3000;, score=0.530 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2, gamma=auto, kernel=linear, max_iter=5000;, score=0.528 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2, gamma=auto, kernel=linear, max_iter=5000;, score=0.547 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2, gamma=auto, kernel=linear, max_iter=5000;, score=0.544 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2, gamma=auto, kernel=linear, max_iter=5000;, score=0.535 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=auto, kernel=linear, max_iter=5000;, score=0.530 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2, gamma=auto, kernel=poly, max_iter=1000;, score=0.535 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2, gamma=auto, kernel=poly, max_iter=1000;, score=0.504 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2, gamma=auto, kernel=poly, max_iter=1000;, score=0.670 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2, gamma=auto, kernel=poly, max_iter=1000;, score=0.607 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=auto, kernel=poly, max_iter=1000;, score=0.584 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2, gamma=auto, kernel=poly, max_iter=3000;, score=0.604 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2, gamma=auto, kernel=poly, max_iter=3000;, score=0.604 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2, gamma=auto, kernel=poly, max_iter=3000;, score=0.549 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2, gamma=auto, kernel=poly, max_iter=3000;, score=0.505 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=auto, kernel=poly, max_iter=3000;, score=0.545 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2, gamma=auto, kernel=poly, max_iter=5000;, score=0.604 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2, gamma=auto, kernel=poly, max_iter=5000;, score=0.604 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2, gamma=auto, kernel=poly, max_iter=5000;, score=0.549 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2, gamma=auto, kernel=poly, max_iter=5000;, score=0.526 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=auto, kernel=poly, max_iter=5000;, score=0.545 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2, gamma=auto, kernel=rbf, max_iter=1000;, score=0.623 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2, gamma=auto, kernel=rbf, max_iter=1000;, score=0.652 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2, gamma=auto, kernel=rbf, max_iter=1000;, score=0.661 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2, gamma=auto, kernel=rbf, max_iter=1000;, score=0.622 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=auto, kernel=rbf, max_iter=1000;, score=0.638 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2, gamma=auto, kernel=rbf, max_iter=3000;, score=0.720 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2, gamma=auto, kernel=rbf, max_iter=3000;, score=0.740 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2, gamma=auto, kernel=rbf, max_iter=3000;, score=0.747 total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2, gamma=auto, kernel=rbf, max_iter=3000;, score=0.742 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=auto, kernel=rbf, max_iter=3000;, score=0.767 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2, gamma=auto, kernel=rbf, max_iter=5000;, score=0.723 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2, gamma=auto, kernel=rbf, max_iter=5000;, score=0.739 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2, gamma=auto, kernel=rbf, max_iter=5000;, score=0.749 total time=   2.6s\n",
      "[CV 4/5] END C=2, gamma=auto, kernel=rbf, max_iter=5000;, score=0.742 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=auto, kernel=rbf, max_iter=5000;, score=0.765 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2, gamma=auto, kernel=sigmoid, max_iter=1000;, score=0.504 total time=   0.4s\n",
      "[CV 1/5] END C=2, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.3s\n",
      "[CV 2/5] END C=2, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.6s\n",
      "[CV 3/5] END C=2, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.4s\n",
      "[CV 4/5] END C=2, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.3s\n",
      "[CV 5/5] END C=2, gamma=auto, kernel=sigmoid, max_iter=3000;, score=0.504 total time=   1.2s\n",
      "[CV 1/5] END C=2, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.1s\n",
      "[CV 2/5] END C=2, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.3s\n",
      "[CV 3/5] END C=2, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.2s\n",
      "[CV 4/5] END C=2, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.3s\n",
      "[CV 5/5] END C=2, gamma=auto, kernel=sigmoid, max_iter=5000;, score=0.504 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(random_state=42),\n",
       "             param_grid={'C': [0.2, 0.6, 1, 2], 'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
       "                         'max_iter': [1000, 3000, 5000]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7437179791212755\n",
      "{'C': 2, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 5000}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.6 MLP Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'hidden_layer_sizes' : [(100,),(200,),(300,)],\n",
    "              'activation' : ['identity','tanh','relu'],\n",
    "              'solver' : ['lbfgs','sgd','adam'],\n",
    "              'max_iter' : [200,600,1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=mlp, param_grid=param_grid, scoring='accuracy',verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=200, solver=lbfgs;, score=0.496 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=200, solver=lbfgs;, score=0.496 total time=   0.1s\n",
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=200, solver=lbfgs;, score=0.496 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=200, solver=lbfgs;, score=0.496 total time=   0.1s\n",
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=200, solver=lbfgs;, score=0.496 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=200, solver=sgd;, score=0.496 total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=200, solver=sgd;, score=0.496 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=200, solver=sgd;, score=0.496 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=200, solver=sgd;, score=0.496 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=200, solver=sgd;, score=0.496 total time=   3.0s\n",
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=200, solver=adam;, score=0.587 total time=   0.4s\n",
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=200, solver=adam;, score=0.623 total time=   0.3s\n",
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=200, solver=adam;, score=0.716 total time=   0.7s\n",
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=200, solver=adam;, score=0.566 total time=   0.2s\n",
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=200, solver=adam;, score=0.705 total time=   0.3s\n",
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=600, solver=lbfgs;, score=0.496 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=600, solver=lbfgs;, score=0.496 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=600, solver=lbfgs;, score=0.496 total time=   0.1s\n",
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=600, solver=lbfgs;, score=0.496 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=600, solver=lbfgs;, score=0.496 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=600, solver=sgd;, score=0.496 total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=600, solver=sgd;, score=0.496 total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=600, solver=sgd;, score=0.496 total time=  10.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=600, solver=sgd;, score=0.496 total time=  10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=600, solver=sgd;, score=0.496 total time=  11.1s\n",
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=600, solver=adam;, score=0.587 total time=   0.4s\n",
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=600, solver=adam;, score=0.623 total time=   0.2s\n",
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=600, solver=adam;, score=0.716 total time=   0.6s\n",
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=600, solver=adam;, score=0.566 total time=   0.2s\n",
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=600, solver=adam;, score=0.705 total time=   0.3s\n",
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=1000, solver=lbfgs;, score=0.496 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=1000, solver=lbfgs;, score=0.496 total time=   0.1s\n",
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=1000, solver=lbfgs;, score=0.496 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=1000, solver=lbfgs;, score=0.496 total time=   0.1s\n",
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=1000, solver=lbfgs;, score=0.496 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=1000, solver=sgd;, score=0.496 total time=  17.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=1000, solver=sgd;, score=0.496 total time=  17.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=1000, solver=sgd;, score=0.496 total time=  18.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=1000, solver=sgd;, score=0.496 total time=  19.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=1000, solver=sgd;, score=0.496 total time=  18.2s\n",
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=1000, solver=adam;, score=0.587 total time=   0.4s\n",
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=1000, solver=adam;, score=0.623 total time=   0.3s\n",
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=1000, solver=adam;, score=0.716 total time=   0.7s\n",
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=1000, solver=adam;, score=0.566 total time=   0.2s\n",
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(100,), max_iter=1000, solver=adam;, score=0.705 total time=   0.3s\n",
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=200, solver=lbfgs;, score=0.699 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=200, solver=lbfgs;, score=0.672 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=200, solver=lbfgs;, score=0.700 total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=200, solver=lbfgs;, score=0.720 total time=   4.2s\n",
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=200, solver=lbfgs;, score=0.693 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=200, solver=sgd;, score=0.496 total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=200, solver=sgd;, score=0.496 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=200, solver=sgd;, score=0.496 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=200, solver=sgd;, score=0.496 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=200, solver=sgd;, score=0.496 total time=   5.0s\n",
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=200, solver=adam;, score=0.683 total time=   0.7s\n",
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=200, solver=adam;, score=0.640 total time=   0.6s\n",
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=200, solver=adam;, score=0.518 total time=   0.8s\n",
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=200, solver=adam;, score=0.600 total time=   1.2s\n",
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=200, solver=adam;, score=0.531 total time=   0.7s\n",
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=600, solver=lbfgs;, score=0.699 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=600, solver=lbfgs;, score=0.733 total time=  12.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=600, solver=lbfgs;, score=0.734 total time=  13.0s\n",
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=600, solver=lbfgs;, score=0.722 total time=   9.5s\n",
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=600, solver=lbfgs;, score=0.693 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=600, solver=sgd;, score=0.496 total time=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=600, solver=sgd;, score=0.496 total time=  14.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=600, solver=sgd;, score=0.496 total time=  15.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=600, solver=sgd;, score=0.496 total time=  14.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=600, solver=sgd;, score=0.496 total time=  14.3s\n",
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=600, solver=adam;, score=0.683 total time=   0.5s\n",
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=600, solver=adam;, score=0.640 total time=   0.5s\n",
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=600, solver=adam;, score=0.518 total time=   0.6s\n",
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=600, solver=adam;, score=0.600 total time=   0.9s\n",
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=600, solver=adam;, score=0.531 total time=   0.7s\n",
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=1000, solver=lbfgs;, score=0.699 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=1000, solver=lbfgs;, score=0.770 total time=  21.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=1000, solver=lbfgs;, score=0.769 total time=  18.7s\n",
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=1000, solver=lbfgs;, score=0.722 total time=   8.9s\n",
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=1000, solver=lbfgs;, score=0.693 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=1000, solver=sgd;, score=0.496 total time=  22.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=1000, solver=sgd;, score=0.496 total time=  25.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=1000, solver=sgd;, score=0.496 total time=  25.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=1000, solver=sgd;, score=0.496 total time=  27.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=1000, solver=sgd;, score=0.496 total time=  24.2s\n",
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=1000, solver=adam;, score=0.683 total time=   0.6s\n",
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=1000, solver=adam;, score=0.640 total time=   0.6s\n",
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=1000, solver=adam;, score=0.518 total time=   0.8s\n",
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=1000, solver=adam;, score=0.600 total time=   0.9s\n",
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(200,), max_iter=1000, solver=adam;, score=0.531 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=200, solver=lbfgs;, score=0.712 total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=200, solver=lbfgs;, score=0.681 total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=200, solver=lbfgs;, score=0.720 total time=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=200, solver=lbfgs;, score=0.705 total time=   6.5s\n",
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=200, solver=lbfgs;, score=0.741 total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=200, solver=sgd;, score=0.496 total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=200, solver=sgd;, score=0.496 total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=200, solver=sgd;, score=0.496 total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=200, solver=sgd;, score=0.496 total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=200, solver=sgd;, score=0.496 total time=   7.2s\n",
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=200, solver=adam;, score=0.709 total time=   1.2s\n",
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=200, solver=adam;, score=0.632 total time=   0.5s\n",
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=200, solver=adam;, score=0.522 total time=   1.1s\n",
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=200, solver=adam;, score=0.570 total time=   0.6s\n",
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=200, solver=adam;, score=0.535 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=600, solver=lbfgs;, score=0.706 total time=  19.9s\n",
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=600, solver=lbfgs;, score=0.740 total time=  12.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=600, solver=lbfgs;, score=0.724 total time=  21.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=600, solver=lbfgs;, score=0.732 total time=  21.1s\n",
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=600, solver=lbfgs;, score=0.741 total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=600, solver=sgd;, score=0.496 total time=  20.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=600, solver=sgd;, score=0.496 total time=  19.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=600, solver=sgd;, score=0.496 total time=  18.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=600, solver=sgd;, score=0.496 total time=  16.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=600, solver=sgd;, score=0.496 total time=  14.3s\n",
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=600, solver=adam;, score=0.709 total time=   0.9s\n",
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=600, solver=adam;, score=0.632 total time=   0.3s\n",
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=600, solver=adam;, score=0.522 total time=   0.8s\n",
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=600, solver=adam;, score=0.570 total time=   0.4s\n",
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=600, solver=adam;, score=0.535 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=1000, solver=lbfgs;, score=0.767 total time=  27.3s\n",
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=1000, solver=lbfgs;, score=0.740 total time=  12.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=1000, solver=lbfgs;, score=0.782 total time=  37.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=1000, solver=lbfgs;, score=0.749 total time=  36.7s\n",
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=1000, solver=lbfgs;, score=0.741 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=1000, solver=sgd;, score=0.496 total time=  33.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=1000, solver=sgd;, score=0.496 total time=  32.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=1000, solver=sgd;, score=0.496 total time=  30.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=1000, solver=sgd;, score=0.496 total time=  30.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=1000, solver=sgd;, score=0.496 total time=  28.9s\n",
      "[CV 1/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=1000, solver=adam;, score=0.709 total time=   1.0s\n",
      "[CV 2/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=1000, solver=adam;, score=0.632 total time=   0.4s\n",
      "[CV 3/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=1000, solver=adam;, score=0.522 total time=   1.1s\n",
      "[CV 4/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=1000, solver=adam;, score=0.570 total time=   0.5s\n",
      "[CV 5/5] END activation=identity, hidden_layer_sizes=(300,), max_iter=1000, solver=adam;, score=0.535 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=200, solver=lbfgs;, score=0.746 total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=200, solver=lbfgs;, score=0.716 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=200, solver=lbfgs;, score=0.731 total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=200, solver=lbfgs;, score=0.753 total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=200, solver=lbfgs;, score=0.749 total time=   6.4s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=200, solver=sgd;, score=0.504 total time=   0.3s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=200, solver=sgd;, score=0.504 total time=   0.6s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=200, solver=sgd;, score=0.506 total time=   0.4s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=200, solver=sgd;, score=0.505 total time=   0.5s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=200, solver=sgd;, score=0.505 total time=   0.5s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=200, solver=adam;, score=0.496 total time=   0.3s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=200, solver=adam;, score=0.513 total time=   0.4s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=200, solver=adam;, score=0.531 total time=   0.3s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=200, solver=adam;, score=0.522 total time=   0.3s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=200, solver=adam;, score=0.564 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=600, solver=lbfgs;, score=0.783 total time=  12.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=600, solver=lbfgs;, score=0.749 total time=  14.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=600, solver=lbfgs;, score=0.781 total time=  14.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=600, solver=lbfgs;, score=0.793 total time=  15.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=600, solver=lbfgs;, score=0.793 total time=  15.0s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=600, solver=sgd;, score=0.504 total time=   0.3s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=600, solver=sgd;, score=0.504 total time=   0.6s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=600, solver=sgd;, score=0.506 total time=   0.5s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=600, solver=sgd;, score=0.505 total time=   0.5s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=600, solver=sgd;, score=0.505 total time=   0.6s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=600, solver=adam;, score=0.496 total time=   0.5s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=600, solver=adam;, score=0.513 total time=   0.6s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=600, solver=adam;, score=0.531 total time=   0.4s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=600, solver=adam;, score=0.522 total time=   0.4s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=600, solver=adam;, score=0.564 total time=   0.7s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=1000, solver=lbfgs;, score=0.784 total time=  19.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=1000, solver=lbfgs;, score=0.749 total time=  21.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=1000, solver=lbfgs;, score=0.788 total time=  22.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=1000, solver=lbfgs;, score=0.803 total time=  22.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=1000, solver=lbfgs;, score=0.796 total time=  23.3s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=1000, solver=sgd;, score=0.504 total time=   0.3s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=1000, solver=sgd;, score=0.504 total time=   0.5s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=1000, solver=sgd;, score=0.506 total time=   0.4s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=1000, solver=sgd;, score=0.505 total time=   0.5s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=1000, solver=sgd;, score=0.505 total time=   0.6s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=1000, solver=adam;, score=0.496 total time=   0.5s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=1000, solver=adam;, score=0.513 total time=   0.5s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=1000, solver=adam;, score=0.531 total time=   0.4s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=1000, solver=adam;, score=0.522 total time=   0.4s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(100,), max_iter=1000, solver=adam;, score=0.564 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=200, solver=lbfgs;, score=0.679 total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=200, solver=lbfgs;, score=0.646 total time=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=200, solver=lbfgs;, score=0.682 total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=200, solver=lbfgs;, score=0.716 total time=  10.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=200, solver=lbfgs;, score=0.685 total time=  11.1s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=200, solver=sgd;, score=0.496 total time=   0.5s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=200, solver=sgd;, score=0.496 total time=   0.5s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=200, solver=sgd;, score=0.495 total time=   0.7s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=200, solver=sgd;, score=0.495 total time=   0.7s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=200, solver=sgd;, score=0.506 total time=   0.6s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=200, solver=adam;, score=0.496 total time=   1.7s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=200, solver=adam;, score=0.508 total time=   2.3s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=200, solver=adam;, score=0.496 total time=   0.9s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=200, solver=adam;, score=0.496 total time=   0.8s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=200, solver=adam;, score=0.496 total time=   1.3s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=600, solver=lbfgs;, score=0.745 total time=  25.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=600, solver=lbfgs;, score=0.758 total time=  29.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=600, solver=lbfgs;, score=0.741 total time=  30.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=600, solver=lbfgs;, score=0.777 total time=  27.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=600, solver=lbfgs;, score=0.753 total time=  32.1s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=600, solver=sgd;, score=0.496 total time=   0.7s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=600, solver=sgd;, score=0.496 total time=   0.5s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=600, solver=sgd;, score=0.495 total time=   1.0s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=600, solver=sgd;, score=0.495 total time=   0.8s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=600, solver=sgd;, score=0.506 total time=   0.5s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=600, solver=adam;, score=0.496 total time=   1.7s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=600, solver=adam;, score=0.508 total time=   2.0s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=600, solver=adam;, score=0.496 total time=   0.8s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=600, solver=adam;, score=0.496 total time=   0.9s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=600, solver=adam;, score=0.496 total time=   1.4s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=1000, solver=lbfgs;, score=0.745 total time=  29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=1000, solver=lbfgs;, score=0.781 total time=  43.8s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=1000, solver=lbfgs;, score=0.782 total time=  40.3s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=1000, solver=lbfgs;, score=0.795 total time=  29.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=1000, solver=lbfgs;, score=0.790 total time=  42.1s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=1000, solver=sgd;, score=0.496 total time=   0.6s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=1000, solver=sgd;, score=0.496 total time=   0.5s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=1000, solver=sgd;, score=0.495 total time=   0.9s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=1000, solver=sgd;, score=0.495 total time=   0.7s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=1000, solver=sgd;, score=0.506 total time=   0.6s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=1000, solver=adam;, score=0.496 total time=   1.6s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=1000, solver=adam;, score=0.508 total time=   2.2s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=1000, solver=adam;, score=0.496 total time=   0.8s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=1000, solver=adam;, score=0.496 total time=   0.8s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(200,), max_iter=1000, solver=adam;, score=0.496 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=200, solver=lbfgs;, score=0.630 total time=  14.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=200, solver=lbfgs;, score=0.630 total time=  15.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=200, solver=lbfgs;, score=0.680 total time=  14.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=200, solver=lbfgs;, score=0.601 total time=  14.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=200, solver=lbfgs;, score=0.669 total time=  17.2s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=200, solver=sgd;, score=0.504 total time=   1.2s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=200, solver=sgd;, score=0.503 total time=   0.7s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=200, solver=sgd;, score=0.504 total time=   1.3s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=200, solver=sgd;, score=0.504 total time=   1.1s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=200, solver=sgd;, score=0.494 total time=   0.6s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=200, solver=adam;, score=0.512 total time=   2.0s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=200, solver=adam;, score=0.536 total time=   1.2s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=200, solver=adam;, score=0.499 total time=   1.6s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=200, solver=adam;, score=0.511 total time=   1.5s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=200, solver=adam;, score=0.505 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=600, solver=lbfgs;, score=0.688 total time=  43.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=600, solver=lbfgs;, score=0.694 total time=  47.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=600, solver=lbfgs;, score=0.741 total time=  46.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=600, solver=lbfgs;, score=0.733 total time=  44.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=600, solver=lbfgs;, score=0.774 total time=  45.4s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=600, solver=sgd;, score=0.504 total time=   0.9s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=600, solver=sgd;, score=0.503 total time=   0.7s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=600, solver=sgd;, score=0.504 total time=   1.2s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=600, solver=sgd;, score=0.504 total time=   1.6s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=600, solver=sgd;, score=0.494 total time=   1.0s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=600, solver=adam;, score=0.512 total time=   2.7s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=600, solver=adam;, score=0.536 total time=   1.2s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=600, solver=adam;, score=0.499 total time=   1.5s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=600, solver=adam;, score=0.511 total time=   1.6s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=600, solver=adam;, score=0.505 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=1000, solver=lbfgs;, score=0.742 total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=1000, solver=lbfgs;, score=0.760 total time= 1.2min\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=1000, solver=lbfgs;, score=0.764 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=1000, solver=lbfgs;, score=0.786 total time= 1.1min\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=1000, solver=lbfgs;, score=0.783 total time=  55.1s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=1000, solver=sgd;, score=0.504 total time=   0.9s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=1000, solver=sgd;, score=0.503 total time=   0.7s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=1000, solver=sgd;, score=0.504 total time=   1.1s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=1000, solver=sgd;, score=0.504 total time=   1.1s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=1000, solver=sgd;, score=0.494 total time=   0.8s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=1000, solver=adam;, score=0.512 total time=   1.8s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=1000, solver=adam;, score=0.536 total time=   1.3s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=1000, solver=adam;, score=0.499 total time=   1.6s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=1000, solver=adam;, score=0.511 total time=   1.5s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(300,), max_iter=1000, solver=adam;, score=0.505 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=200, solver=lbfgs;, score=0.695 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=200, solver=lbfgs;, score=0.639 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=200, solver=lbfgs;, score=0.722 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=200, solver=lbfgs;, score=0.708 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=200, solver=lbfgs;, score=0.704 total time=   5.0s\n",
      "[CV 1/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=200, solver=sgd;, score=0.504 total time=   0.4s\n",
      "[CV 2/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=200, solver=sgd;, score=0.504 total time=   0.4s\n",
      "[CV 3/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=200, solver=sgd;, score=0.504 total time=   0.4s\n",
      "[CV 4/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=200, solver=sgd;, score=0.504 total time=   0.4s\n",
      "[CV 5/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=200, solver=sgd;, score=0.504 total time=   0.4s\n",
      "[CV 1/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=200, solver=adam;, score=0.622 total time=   0.8s\n",
      "[CV 2/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=200, solver=adam;, score=0.647 total time=   0.7s\n",
      "[CV 3/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=200, solver=adam;, score=0.748 total time=   0.9s\n",
      "[CV 4/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=200, solver=adam;, score=0.675 total time=   1.2s\n",
      "[CV 5/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=200, solver=adam;, score=0.641 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=600, solver=lbfgs;, score=0.706 total time=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=600, solver=lbfgs;, score=0.687 total time=  12.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=600, solver=lbfgs;, score=0.765 total time=  13.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=600, solver=lbfgs;, score=0.719 total time=  14.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=600, solver=lbfgs;, score=0.744 total time=  13.5s\n",
      "[CV 1/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=600, solver=sgd;, score=0.504 total time=   0.5s\n",
      "[CV 2/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=600, solver=sgd;, score=0.504 total time=   0.5s\n",
      "[CV 3/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=600, solver=sgd;, score=0.504 total time=   0.5s\n",
      "[CV 4/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=600, solver=sgd;, score=0.504 total time=   0.5s\n",
      "[CV 5/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=600, solver=sgd;, score=0.504 total time=   0.6s\n",
      "[CV 1/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=600, solver=adam;, score=0.622 total time=   1.1s\n",
      "[CV 2/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=600, solver=adam;, score=0.647 total time=   0.9s\n",
      "[CV 3/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=600, solver=adam;, score=0.748 total time=   1.2s\n",
      "[CV 4/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=600, solver=adam;, score=0.675 total time=   1.2s\n",
      "[CV 5/5] END activation=relu, hidden_layer_sizes=(100,), max_iter=600, solver=adam;, score=0.641 total time=   0.7s\n"
     ]
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "# use these parameters for model improvement later "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Model from GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp2 = MLPClassifier(activation = 'tanh',hidden_layer_sizes = (100,),max_iter = 1000,solver = 'lbfgs',random_state=42).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores_classification(mlp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.7 Consolidated View of Improved Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lg2, dtree2, rf2,svc2, mlp2]\n",
    "\n",
    "\n",
    "model_names = ['LogReg', 'DTree', 'RandomForest', 'SVC', 'MLP (ANN)']\n",
    "\n",
    "scores_table = []\n",
    "for model, name in zip(models, model_names):\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    scores_table.append([name, train_score, test_score])\n",
    "\n",
    "df_scores = pd.DataFrame(scores_table, columns=[\"Improved Model\", \"Train Score\", \"Test Score\"])\n",
    "\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.8 Ensemble Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.8.1 ADA Boost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimising the boosting model so it can be used for models later? use the best model out of improved baseline models \n",
    "\n",
    "param_grid = {'base_estimator' : []\n",
    "              'n_estimators': [50, 100, 200, 300, 400],  # number of estimators till terminated\n",
    "              'learning_rate': [1.0, 3.0, 5.0],  # according to docs, there will be tradeoffs\n",
    "              'algorithm': ['SAMME', 'SAMME.R']}  # learning algorithm type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=ada, param_grid=param_grid, scoring='accuracy',verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "# use these parameters for model improvement later "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.8.2 XG Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Airbnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load and Sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bnb = pd.read_csv(\"./bnb_transformed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bnb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bnb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Train and Test Splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_bnb.drop(['price'], axis =1)\n",
    "y = df_bnb['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2  Statistical Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using OLS to see features \n",
    "lm2 = sm.OLS(y_train, X_train).fit()\n",
    "# Summary statistics from the model\n",
    "lm2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Build the Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluate and Improve the Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
